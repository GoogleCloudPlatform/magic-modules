[{"id":0,"href":"/magic-modules/get-started/generate-providers/","title":"Generate the providers","section":"Get started","content":" Generate google and google-beta providers # This quickstart guides you through setting up your development environment, making a change to magic-modules, generating provider changes to the google and google-beta Terraform providers, and running tests related to the change.\nBefore you begin # Install the gcloud CLI. In the Google Cloud console, on the project selector page, select or create a Google Cloud project. Note: If you don\u0026rsquo;t already have a project to use for testing changes to the Terraform providers, create a project instead of selecting an existing poject. After you finish these steps, you can delete the project, removing all resources associated with the project. Go to project selector Make sure that billing is enabled for your Google Cloud project. Learn how to check if billing is enabled on a project. Set up your development environment # If you are familiar with Docker or Podman, you may want to use the experimental container-based environment instead of this section. Install git\nInstall rbenv, ensuring you follow both steps 1 and 2.\nUse rbenv to install ruby 3.1.0\nrbenv install 3.1.0 Install go\nInstall goimports\ngo install golang.org/x/tools/cmd/goimports@latest Install terraform\nClone the magic-modules repository\ncd ~ git clone https://github.com/GoogleCloudPlatform/magic-modules.git Run the following command from the root of your cloned magic-modules repository.\ncd magic-modules ./scripts/doctor Expected output if everything is installed properly:\nCheck for ruby in path... found! Check for go in path... found! Check for goimports in path... found! Check for git in path... found! Check for terraform in path... found! Check for make in path... found! Generate a provider change # In your cloned magic-modules repository, edit mmv1/products/pubsub/Topic.yaml to change the description for the schemaSettings field:\n- !ruby/object:Api::Type::NestedObject name: \u0026#39;schemaSettings\u0026#39; description: | UPDATED_DESCRIPTION Clone the google and google-beta provider repositories with the following commands:\ngit clone https://github.com/hashicorp/terraform-provider-google.git $GOPATH/src/github.com/hashicorp/terraform-provider-google git clone https://github.com/hashicorp/terraform-provider-google-beta.git $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta Generate changes for the google provider\nmake provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; PRODUCT=pubsub Generate changes for the google-beta provider\nmake provider VERSION=beta OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google-beta\u0026#34; PRODUCT=pubsub Confirm that the expected changes were generated\ncd $GOPATH/src/github.com/hashicorp/terraform-provider-google git diff -U0 cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta git diff -U0 In both cases, the changes should include:\ndiff --git a/google-beta/resource_pubsub_topic.go b/google-beta/resource_pubsub_topic.go --- a/google-beta/resource_pubsub_topic.go +++ b/google-beta/resource_pubsub_topic.go @@ -115 +115 @@ and is not a valid configuration.`, - Description: `Settings for validating messages published against a schema.`, + Description: `UPDATED_DESCRIPTION`, diff --git a/website/docs/r/pubsub_topic.html.markdown b/website/docs/r/pubsub_topic.html.markdown --- a/website/docs/r/pubsub_topic.html.markdown +++ b/website/docs/r/pubsub_topic.html.markdown @@ -146 +146 @@ The following arguments are supported: - Settings for validating messages published against a schema. + UPDATED_DESCRIPTION Note: There may be additional changes present due to specifying a PRODUCT= value or due to the magic-modules repository being out of sync with the provider repositories. This is okay as long as tests in the following section pass. Test changes # Set up application default credentials for Terraform\ngcloud auth application-default login export GOOGLE_USE_DEFAULT_CREDENTIALS=TRUE Set required environment variables\nexport GOOGLE_PROJECT=PROJECT_ID export GOOGLE_REGION=us-central1 export GOOGLE_ZONE=us-central1-a Replace PROJECT_ID with the ID of your Google Cloud project.\nEnable required APIs\ngcloud config set project $GOOGLE_PROJECT gcloud services enable pubsub.googleapis.com gcloud services enable cloudkms.googleapis.com Run all linters\ncd $GOPATH/src/github.com/hashicorp/terraform-provider-google make lint cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta make lint Run all unit tests\ncd $GOPATH/src/github.com/hashicorp/terraform-provider-google make test cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta make test Run acceptance tests for Pub/Sub Topic\ncd $GOPATH/src/github.com/hashicorp/terraform-provider-google make testacc TEST=./google TESTARGS=\u0026#39;-run=TestAccPubsubTopic\u0026#39; cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta make testacc TEST=./google-beta TESTARGS=\u0026#39;-run=TestAccPubsubTopic\u0026#39; Troubleshoot # Too many open files # If you are getting “Too many open files” ulimit needs to be raised.\nMac OS ulimit -n 8192 Cleanup # Optional: Revoke credentials from the gcloud CLI. gcloud auth revoke What\u0026rsquo;s next # Learn about Magic Modules Learn about the contribution process Learn about make commands "},{"id":1,"href":"/magic-modules/get-started/","title":"Get started","section":"Overview","content":""},{"id":2,"href":"/magic-modules/reference/make-commands/","title":"make commands","section":"Reference","content":" make commands reference # magic-modules # make / make provider # Generates the code for the downstream google and google-beta providers.\nNote: Generation works best if the downstream provider has a commit checked out corresponding to the latest main branch commit that is present in your magic-modules working branch. This can generally be identified based on matching commit messages. Examples:\nmake provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; make provider VERSION=beta OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google-beta\u0026#34; # Only generate a specific product (plus all common files) make provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; PRODUCT=pubsub # Only generate only a specific resources for a product make provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; PRODUCT=pubsub RESOURCE=Topic # Only generate common files, including all third_party code make provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; PRODUCT=doesnotexist Arguments # OUTPUT_PATH: Required. The location you are generating provider code into. VERSION: Required. The version of the provider you are building into. Valid values are ga and beta. PRODUCT: Limits generations to the specified folder within mmv1/products or tpgtools/api. Handwritten files from mmv1/third_party/terraform are always generated into the downstream regardless of this setting, so you can provide a non-existant product name to generate only handwritten code. Required if RESOURCE is specified. RESOURCE: Limits generation to the specified resource within a particular product. For mmv1 resources, matches the resource\u0026rsquo;s name field (set in its configuration file).For tpgtools resources, matches the terraform resource name. ENGINE: Modifies make provider to only generate code using the specified engine. Valid values are mmv1 or tpgtools. (Providing tpgtools will still generate any prerequisite mmv1 files required for tpgtools.) Cleaning up old files # Magic Modules will only generate on top of whatever is in the downstream repository. This means that, from time to time, you may end up with stale files or changes in your downstream that cause compilation or tests to fail.\nYou can clean up by running the following command in your downstream repositories:\ngit checkout -- . \u0026amp;\u0026amp; git clean -f google/ google-beta/ website/ Container-based environment # This approach is in beta and still collecting feedback. Please file an issue if you encounter challenges. ./scripts/make-in-container.sh runs make with the provided arguments inside a container with all necessary dependencies preinstalled. It uses Docker if available and Podman otherwise. Like make, this script must be run in the root of a magic-modules repository clone.\nIf you run into any problems, please file an issue.\nBefore you begin # Ensure that GOPATH is set on your host machine.\nprintenv | grep GOPATH If not, add export GOPATH=$HOME/go to your terminal\u0026rsquo;s startup script and restart your terminal.\nClone the google and google-beta provider repositories with the following commands:\ngit clone https://github.com/hashicorp/terraform-provider-google.git $GOPATH/src/github.com/hashicorp/terraform-provider-google git clone https://github.com/hashicorp/terraform-provider-google-beta.git $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta Example # To build the google provider, run the following command in the root of a magic-modules repository clone:\n./scripts/make-in-container.sh \\ terraform VERSION=ga \\ OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; "},{"id":3,"href":"/magic-modules/contribute/release-notes/","title":"Write release notes","section":"Contribute","content":" Write release notes # This guide explains best practices for composing accurate, end-user focused release notes for Magic Modules pull requests.\nEvery pull request must have at least one release note block in the opening comment. Release note blocks have the following format:\n```release-note:TYPE CONTENT ``` Replace TYPE with the correct release note type, and CONTENT with a release note written according to the guidelines in the following sections.\nGeneral guidelines # Do Don\u0026rsquo;t Only have one CONTENT line per release note block. Use multiple blocks if there are multiple related changes in a single PR. Don\u0026rsquo;t add multiple lines to a single release note block. Avoid combining multiple distinct types of changes into one release block. If a change only affects the google-beta provider add (beta) to the end of the release note. If a change only affects the google provider add (ga) to the end of the release note. Don\u0026rsquo;t add either suffix if the change affects both providers. Set an appropriate release note type. Don\u0026rsquo;t leave the type as REPLACEME. Type-specific guidelines and examples # New field(s) Write your release note in the following format:\n```release-note:enhancement PRODUCT: added `FIELD_1`, `FIELD_2`, and `FIELD_N` fields to `RESOURCE_NAME` resource ``` Replace PRODUCT, FIELD_*, and RESOURCE_NAME according to the pull request content. For example:\n```release-note:enhancement compute: added `foo_bar` field to `google_compute_foo` resource ``` New resource Write your release note in the following format:\n```release-note:new-resource `RESOURCE_NAME` ``` Replace RESOURCE_NAME according to the pull request content. For example:\n```release-note:new-resource `google_compute_new_resource` ``` New datasource Write your release note in the following format:\n```release-note:new-datasource `DATASOURCE_NAME` ``` Replace DATASOURCE_NAME according to the pull request content. For example:\n```release-note:new-datasource `google_compute_new_datasource` ``` No user impact If there is no user impact, use an empty release note block of type none. Example:\n```release-note:none ``` Other Choose a release note type # For each release note block, choose an appropriate type from the following list:\nenhancement : New features on existing resources bug : Bug fix deprecation : A field/resource is being marked as deprecated (not being removed) breaking-change : Changes that require users to change their configuration note : General type for other notes that might be relevant to users but don\u0026rsquo;t fit into another category Guidelines # Do Don\u0026rsquo;t Use past tense to describe the end state after the change is released. Start with a verb. For example, \u0026ldquo;added\u0026hellip;\u0026rdquo;, \u0026ldquo;fixed\u0026hellip;\u0026rdquo;, or \u0026ldquo;resolved\u0026hellip;\u0026rdquo;. You can use future tense to describe future changes, such as saying that a deprecated field will be removed in a future version. Don\u0026rsquo;t use present or future tense to describe changes that are included in the pull request. Write user-focused release notes. For example, reference specific impacted terraform resource and field names, and discuss changes in behavior users will experience. Avoid API field/resource/feature names. Avoid implementation details. Avoid language that requires understanding of provider internals. Surround resource or field names with backticks. Don\u0026rsquo;t use resource or field names without punctuation or with other punctuation like quotation marks. Use impersonal third person. Don\u0026rsquo;t use \u0026ldquo;I\u0026rdquo;, \u0026ldquo;you\u0026rdquo;, etc. If the pull request impacts any specific, begin your release note with that product name followed by a colon. Use lower case for the first letter after the colon. For example, cloudrun: added... For MMv1 resources, use the folder name that contains the yaml files as the product name; for handwritten or tpgtools resources, use the API subdomain; for broad cross-product changes, use provider. Don\u0026rsquo;t begin your release note with the full resource name. Don\u0026rsquo;t add backticks around the product name. Don\u0026rsquo;t capitalize the first letter after the colon. Examples # ```release-note:bug cloudrun: fixed perma-diff in `google_cloud_run_service` ``` ```release-note:deprecation container: deprecated `region` and `zone` on `google_container_unicorn`. Use `location` instead. ``` "},{"id":4,"href":"/magic-modules/contribute/review-pr/","title":"Review a PR","section":"Contribute","content":" Review a PR # This page provides guidelines for reviewing Magic Modules pull requests\nRead the PR description to understand the context and ensure the PR either is linked to a GitHub issue or an internal bug if not, check the issue tracker to see whether the feature has already been requested and add the issues in the description, if any. establishes clear context itself via title or description. If the PR adds any new resource, ensure that the resource does not already exists in the GA provider or beta provider Read through all the changes in the PR, generated code in the downstreams and the API documentation to ensure that: the resource schema added in the PR matches the API structure. the features are added in the correct version features only available in beta are not included in the GA google provider. features added to the GA provider are also included in the beta provider \u0026ndash; beta should be a strict superset of GA. no breaking changes are introduced without a valid justification. verify the change actually resolves the linked issues, if any. Check the tests added/modified to ensure that: all fields added/updated in the PR appear in at least one test. It is advisable to test updating from a non-zero value to a zero value if feasible. all mutable fields are tested in at least one update test. all related tests pass in GA for features promoted from beta to GA. Note: Presubmit VCR tests do not run in GA. Manual testing is required for promoted GA features. newly added or modified diff suppress functions are tested in at least one unit test. the linked issue (if any) is covered by at least one test that reproduces the issue for example - a bugfix should test the bug (or explain why it\u0026rsquo;s not feasible to do so in the description) and an enhancement should test the new behaviour(s). all related PR presubmit tests have been completed successfully, including: terraform-provider-breaking-change-test presubmit-rake-tests terraform-provider-google-build-and-unit-tests terraform-provider-google-beta-build-and-unit-tests VCR-test Note: Some acceptance tests may be skipped in VCR and manual testing is required. Check documentation to ensure resouce-level and field-level documentation are generated correctly for MMv1-based resource documentation is added manually for handwritten resources. Check if release notes capture all changes in the PR, and are correctly formatted following the guidance in write release notes before merge the PR. "},{"id":5,"href":"/magic-modules/develop/breaking-changes/","title":"Understand breaking changes","section":"Develop","content":" Breaking Changes and Provider Development # Provider Versioning # As a provider is developed, resources are added, old resources are updated, and bugs are fixed. These changes are bundled together as a release.\nReleases are numerically defined with a version number in the form of MAJOR.MINOR.PATCH. Here, \u0026lsquo;Patch\u0026rsquo; indicates bug fixes, \u0026lsquo;Minor\u0026rsquo; represents new features, and \u0026lsquo;Major\u0026rsquo; represents significant changes which would be breaking to the customer if committed. Once a release is published, the provider binary is copied to Hashicorp\u0026rsquo;s provider registry.\nCustomer Trust # Terraform authors can write modular configurations, aptly named modules. These are shared within organizations and online. Terraform configurations can specify provider requirements, including a version constraint field.\nThe configuration will then tie these version constraints to an approximate minor or exact full version. Maintaining trust and consistency on every MINOR or MAJOR version upgrade is critical.\nIf breaking changes are allowed within MINOR versions, trust in the provider will be eroded and module creators will not have confidence in provider stability. This diminished trust will eventually lead to customers investing or deploying less to GCP.\nExceptions to Breaking Changes # While we strive to minimize breaking changes, there are certain exceptions where they become unavoidable. Notably, breaking changes are permissible when existing functionality is demonstrably broken due to an API or provider-level issue. In such cases, the change does not impact users negatively, since there is no instance where the Terraform provider is currently using the affected field or resource correctly.\nFor example, consider a situation involving the Google provider where an API endpoint we depend on changes its behavior or is deprecated. If the current implementation in the Terraform provider cannot adapt to this change and is thus broken, a breaking change would be necessary to restore the functionality.\nBreaking Changes # Having established that we want to avoid breaking changes, let\u0026rsquo;s delve into what exactly constitutes a breaking change. We\u0026rsquo;ll discuss this under four main categories and the rules within each.\nProvider Configuration Level Breakages # Top-level behavior such as provider configuration and authentication changes. Changing fundamental provider behavior (Undetectable) Including, but not limited to, modification of: authentication, environment variable usage, and constricting retry behavior.\nResource List Level Breakages # Resource/datasource naming conventions and entry differences. Removing or Renaming a Resource In Terraform, resources should be retained whenever possible. Removal of a resource will result in a configuration breakage wherever a dependency on that resource exists. Renaming or removing resources are functionally equivalent in terms of configuration breakages.\nResource Level Breakages # Individual resource breakages like field entry removals or behavior within a resource. Removing or Renaming a field In Terraform, fields should be retained whenever possible. Removal of a field will result in a configuration breakage wherever a dependency on that field exists. Renaming or removing a field are functionally equivalent in terms of configuration breakages.\nChanging resource ID format (Undetectable) Terraform uses resource ID to read resource state from the API. Modification of the ID format will break the ability to parse the IDs from any deployments.\nChanging resource ID import format (Undetectable) Automation external to our provider may rely on importing resources with a certain format. Removal or modification of existing formats will break this automation.\nField Level Breakages # Field-level conventions like attribute changes and naming conventions. Changing Field Type While certain Field Type migrations may be supported at a technical level, it\u0026rsquo;s a practice that we highly discourage. We see little value for these transitions vs the risk they impose.\nField becoming Required Field A field should not become \u0026lsquo;Required\u0026rsquo; as existing configurations may not have this field defined, leading to broken configurations in sequential plans or applies.. If you are adding \u0026lsquo;Required\u0026rsquo; to a field so a block won\u0026rsquo;t remain empty, this can cause two issues. First, if it\u0026rsquo;s a singular nested field, the block may gain more fields later and it\u0026rsquo;s not clear whether the field is actually required so it may be misinterpreted by future contributors. Second, if users are defining empty blocks in existing configurations, this change will break them. Consider these points in admittance of this type of change.\nBecoming a Computed only Field While a field can transition from \u0026lsquo;Optional\u0026rsquo; to \u0026lsquo;Optional+Computed\u0026rsquo;, it should not change from \u0026lsquo;Required\u0026rsquo; or \u0026lsquo;Optional\u0026rsquo; to solely \u0026lsquo;Computed\u0026rsquo;. This transition would effectively make the field read-only, thus breaking configs in sequential plan or applies where this field is defined in a configuration.\nOptional and Computed to Optional A field should not transition from \u0026lsquo;Computed + Optional\u0026rsquo; to \u0026lsquo;Optional\u0026rsquo;. During a sequential apply, the Terraform state retains the previously computed value, which won\u0026rsquo;t match the configuration, thus causing a discrepancy.\nAdding or Changing a Default Value Adding a default value where one was not previously declared can work in a very limited subset of scenarios but is an all around \u0026rsquo;not good\u0026rsquo; practice to engage in. Changing a default value will absolutely cause a breakage. The mechanism of break for both scenarios is current terraform deployments now gain a diff with sequential applies where the diff is the new or changed default value.\nGrowing Minimum Items \u0026lsquo;MinItems\u0026rsquo; cannot grow. Otherwise, existing terraform configurations that don\u0026rsquo;t satisfy this rule will break.\nShrinking Maximum Items \u0026lsquo;MaxItems\u0026rsquo; cannot shrink. Otherwise, existing terraform configurations that don\u0026rsquo;t satisfy this rule will break.\nChanging field data format (Undetectable) Modification of the data format (either by the API or manually) will cause a diff in subsequent plans if that field is not Computed. This results in a breakage. API breaking changes are out of scope with respect to provider responsibility but we may make changes in response to API breakages in some instances to provide more customer stability.\n"},{"id":6,"href":"/magic-modules/develop/","title":"Develop","section":"Overview","content":""},{"id":7,"href":"/magic-modules/get-started/how-magic-modules-works/","title":"How Magic Modules works","section":"Get started","content":" How Magic Modules works # Magic Modules can be thought of as a source of truth for how to map a GCP API resource representation to a Terraform resource (or datasource) representation. Magic Modules uses that mapping (and additional handwritten code where necessary) to generate \u0026ldquo;downstream\u0026rdquo; repositories - in particular, the Terraform providers for Google Platform: google (or TPG) and google-beta (or TPGB).\nGeneration of the downstream repositories happens for every new commit in a PR (to a temporary branch owned by the modular-magician robot user) and on every merge into the main branch (to the main branch of downstreams). Generation for PR commits allows contributors to manually examine the changes, as well as allowing automatic running of unit tests, acceptance tests, and automated checks such as breaking change detection.\nResource types # There are three types of resources supported by Magic Modules: MMv1, Handwritten, and DCL/tpgtools. These are described in more detail in the following sections.\nMMv1 # MMv1 consists of a set of \u0026ldquo;products\u0026rdquo;; each product contains one or more \u0026ldquo;resources\u0026rdquo;.\nEach product has a folder in magic-modules/mmv1/products. The name of the folder is the \u0026ldquo;product name\u0026rdquo;, which usually corresponds to the API subdomain covered by the product (such as compute.googleapis.com). Each product folder contains a product configuration file (product.yaml) and one or more resource configuration files (ResourceName.yaml). The actual name of a ResourceName.yaml file usually matches the name of a GCP API resource in the product\u0026rsquo;s subdomain.\nMMv1 resource configurations may reference handwritten code stored in magic-modules/mmv1/templates/terraform, which will be injected into the generated resource file. Many MMv1 resources also have one or more handwritten tests, which are stored in magic-modules/mmv1/third_party/terraform/tests\nIn the providers, MMv1-based resources are stored in PROVIDER/services/PRODUCT/resource_PRODUCT_RESOURCE.go, where PROVIDER is google or google-beta, PRODUCT is the product name, and RESOURCE is the GCP API resource\u0026rsquo;s name converted to snake case ↗.\nMMv1-based files start with the following header:\n*** AUTO GENERATED CODE *** Type: MMv1 *** Handwritten # Handwritten resources and datasources are technically part of MMv1; however, they are not generated from YAML configurations. Instead, they are written as Go code with minimal ruby \u0026ldquo;version guards\u0026rdquo; to exclude beta-only features from the google provider.\nHandwritten resources and datasources can be grouped by \u0026ldquo;service\u0026rdquo;, which generally corresponds to the API subdomain the resource or datasource interacts with.\nIn addition to the core implementation, handwritten resources and datasources will also have documentation, tests, and sweepers (which clean up stray resources left behind by tests). Each type of code is stored in the following locations:\nResource \u0026amp; datasource implementation: In the appropriate service folder inside magic-modules/mmv1/third_party/terraform/services Resource documentation: magic-modules/mmv1/third_party/terraform/website/docs/r Datasource documentation: magic-modules/mmv1/third_party/terraform/webside/docs/d Tests: magic-modules/mmv1/third_party/terraform/tests Sweepers: magic-modules/mmv1/third_party/terraform/utils In the providers, handwritten resources and datasources are stored in PROVIDER/services/SERVICE/FILENAME.go, where PROVIDER is google or google-beta, SERVICE is the service name, and FILENAME is the name of the handwritten file in magic-modules. Handwritten files do not have an AUTO GENERATED CODE header.\nDCL aka tpgtools (maintenance mode) # DCL / tpgtools is similar to MMv1; however, it is in maintenance mode, which means that new resources using the DCL are not being added.\nDCL-based files start with the following header:\n*** AUTO GENERATED CODE *** Type: DCL *** "},{"id":8,"href":"/magic-modules/reference/resource-reference/","title":"Resource YAML reference ↗","section":"Reference","content":"FORCE MENU RENDER\n"},{"id":9,"href":"/magic-modules/best-practices/","title":"Best practices","section":"Overview","content":" Best practices # The following is a list of best practices that contributions are expected to follow in order to ensure a consistent UX for the Google Terraform provider internally and also compared to other Terraform providers.\nForceNew # ForceNew in a Terraform resource schema attribute that indicates that a field is immutable – that is, that a change to the field requires the resource to be destroyed and recreated.\nThis is necessary and required for cases where a field can\u0026rsquo;t be updated in-place, so that Terraform\u0026rsquo;s core workflow of aligning real infrastructure with configuration can be achieved. If a field or resource can never be updated in-place and is not marked with ForceNew, that is considered a bug in the provider.\nSome fields or resources may be possible to update in place, but only under specific conditions. In these cases, you can treat the field as updatable - that is, do not mark it as ForceNew; instead, implement standard update functionality. Then, call diff.ForceNew inside a CustomizeDiff if the appropriate conditions to allow update in place are not met. Any CustomizeDiff function like this must be thoroughly unit tested. Making a field conditionally updatable like this is considered a good and useful enhancement in cases where recreation is costly and conditional updates do not introduce undue complexity.\nIn complex cases, it is better to mark the field ForceNew to ensure that users can apply their configurations successfully.\nMitigating data loss risk via deletion_protection # Some resources, such as databases, have a significant risk of unrecoverable data loss if the resource is accidentally deleted due to a change to a ForceNew field. For these resources, the best practice is to add a deletion_protection field that defaults to true, which prevents the resource from being deleted if enabled. Although it is a small breaking change, for users, the benefits of deletion_protection defaulting to true outweigh the cost.\nAPIs also sometimes add deletion_protection fields, which will generally default to false for backwards-compatibility reasons. Any deletion_protection API field added to an existing Terraform resource must match the API default initially. The default may be set to true in the next major release. For new Terraform resources, any deletion_protection field should default to true in Terraform regardless of the API default.\nA resource can have up to two deletion_protection fields (with different names): one that represents a field in the API, and one that is only in Terraform. This could happen because the API added its field after deletion_protection already existed in Terraform; it could also happen because a separate field was added in Terraform to make sure that deletion_protection is enabled by default. In either case, they should be reconciled into a single field (that defaults to true) in the next major release.\nResources that do not have a significant risk of unrecoverable data loss or similar critical concern will not be given deletion_protection fields.\nNote: The previous best practice was a field called force_delete that defaulted to false. This is still present on some resources for backwards-compatibility reasons, but deletion_protection is preferred going forward. Deletion policy # Some resources need to let users control the actions taken add deletion time. For these resources, the best practice is to add a deletion_policy enum field that defaults to an empty string and allows special values that control the deletion behavior.\nOne common example is ABANDON, which is useful if the resource is safe to delete from Terraform but could cause problems if deleted from the API - for example, google_bigtable_gc_policy deletion can fail in replicated instances. ABANDON indicates that attempts to delete the resource should remove it from state without actually deleting it.\nSee magic-modules#13107 for an example of adding a deletion_policy field to an existing resource.\n"},{"id":10,"href":"/magic-modules/develop/resource/","title":"Add or modify a resource","section":"Develop","content":" Add or modify a resource # This page describes how to add a new resource to the google or google-beta Terraform provider using MMv1 and/or handwritten code.\nFor more information about types of resources and the generation process overall, see How Magic Modules works.\nBefore you begin # Complete the Generate the providers quickstart to set up your environment and your Google Cloud project. Ensure that your magic-modules, terraform-provider-google, and terraform-provider-google-beta repositories are up to date. cd ~/magic-modules git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull Add a resource # MMv1 Using an editor of your choice, in the appropriate product folder, create a file called RESOURCE_NAME.yaml. Replace RESOURCE_NAME with the name of the API resource you are adding support for. For example, a configuration file for NatAddress would be called NatAddress.yaml.\nCopy the following template into the new file:\n# Copyright 2023 Google Inc. # Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. --- !ruby/object:Api::Resource # API resource name name: \u0026#39;ResourceName\u0026#39; # Resource description for the provider documentation. description: | RESOURCE_DESCRIPTION references: !ruby/object:Api::Resource::ReferenceLinks guides: # Link to quickstart in the API\u0026#39;s Guides section. For example: # \u0026#39;Create and connect to a database\u0026#39;: \u0026#39;https://cloud.google.com/alloydb/docs/quickstart/create-and-connect\u0026#39; \u0026#39;QUICKSTART_TITLE\u0026#39;: \u0026#39;QUICKSTART_URL\u0026#39; # Link to the REST API reference for the resource. For example, # https://cloud.google.com/alloydb/docs/reference/rest/v1/projects.locations.backups api: \u0026#39;API_REFERENCE_URL\u0026#39; # Marks the resource as beta-only. Ensure a beta version block is present in # provider.yaml. # min_version: beta # Inserts styled markdown into the header of the resource\u0026#39;s page in the # provider documentation. # docs: # warning: | # MULTILINE_WARNING_MARKDOWN # note: | # MULTILINE_NOTE_MARKDOWN # URL for the resource\u0026#39;s standard List method. https://google.aip.dev/132 # Terraform field names enclosed in double curly braces are replaced with # the field values from the resource at runtime. base_url: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames\u0026#39; # URL for the resource\u0026#39;s standard Get method. https://google.aip.dev/131 # Terraform field names enclosed in double curly braces are replaced with # the field values from the resource at runtime. self_link: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames/{{name}}\u0026#39; # If true, the resource and all its fields are considered immutable - that is, # only creatable, not updatable. Individual fields can override this if they # have a custom update method in the API. # immutable: true # Overrides one or more timeouts, in minutes. All timeouts default to 20. # timeouts: !ruby/object:Api::Timeouts # insert_minutes: 20 # update_minutes: 20 # delete_minutes: 20 # URL for the resource\u0026#39;s standard Create method, including query parameters. # https://google.aip.dev/133 # Terraform field names enclosed in double curly braces are replaced with # the field values from the resource at runtime. create_url: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames?resourceId={{name}}\u0026#39; # Overrides the HTTP verb used to create a new resource. # Allowed values: :POST, :PUT, :PATCH. Default: :POST # create_verb: :POST # Overrides the URL for the resource\u0026#39;s standard Update method. (If unset, the # self_link URL is used by default.) https://google.aip.dev/134 # Terraform field names enclosed in double curly braces are replaced with # the field values from the resource at runtime. # update_url: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames/{{name}}\u0026#39; # The HTTP verb used to update a resource. Allowed values: :POST, :PUT, :PATCH. Default: :PUT. update_verb: :PATCH # If true, the resource sets an `updateMask` query parameter listing modified # fields when updating the resource. If false, it does not. update_mask: true # Overrides the URL for the resource\u0026#39;s standard Delete method. (If unset, the # self_link URL is used by default.) https://google.aip.dev/135 # Terraform field names enclosed in double curly braces are replaced with # the field values from the resource at runtime. # delete_url: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames/{{name}}\u0026#39; # Overrides the HTTP verb used to delete a resource. # Allowed values: :POST, :PUT, :PATCH, :DELETE. Default: :DELETE # delete_verb: :DELETE # If true, code for handling long-running operations is generated along with # the resource. If false, that code is not generated. autogen_async: true # Sets parameters for handling operations returned by the API. async: !ruby/object:Api::OpAsync # Overrides which API calls return operations. Default: [\u0026#39;create\u0026#39;, # \u0026#39;update\u0026#39;, \u0026#39;delete\u0026#39;] # actions: [\u0026#39;create\u0026#39;, \u0026#39;update\u0026#39;, \u0026#39;delete\u0026#39;] operation: !ruby/object:Api::OpAsync::Operation base_url: \u0026#39;{{op_id}}\u0026#39; # If true, the completed operation\u0026#39;s returned JSON is expected to # contain a full resource in the \u0026#34;response\u0026#34; field # result: !ruby/object:Api::OpAsync::Result # resource_inside_response: true # The following are all required but unused. path: \u0026#39;unused\u0026#39; wait_ms: 0 # unused result: !ruby/object:Api::OpAsync::Result path: \u0026#39;unused\u0026#39; status: !ruby/object:Api::OpAsync::Status path: \u0026#39;unused\u0026#39; allowed: [] error: !ruby/object:Api::OpAsync::Error path: \u0026#39;unused\u0026#39; message: \u0026#39;unused\u0026#39; # All resources (of all kinds) that share a mutex value block rather than # executing concurrent API requests. # Terraform field names enclosed in double curly braces are replaced with # the field values from the resource at runtime. # mutex: RESOURCE_NAME/{{name}} parameters: - !ruby/object:Api::Type::String name: \u0026#39;location\u0026#39; required: true immutable: true url_param_only: true description: | LOCATION_DESCRIPTION - !ruby/object:Api::Type::String name: \u0026#39;name\u0026#39; required: true immutable: true url_param_only: true description: | NAME_DESCRIPTION properties: # Fields go here Modify the template as needed to match the API resource\u0026rsquo;s documented behavior.\nDelete all remaining comments in the resource configuration (including attribute descriptions) that were copied from the above template.\nNote: The template includes the most commonly-used fields. For a comprehensive reference, see ResourceName.yaml reference ↗.\nHandwritten Warning: Handwritten resources are more difficult to develop and maintain. New handwritten resources will only be accepted if implementing the resource in MMv1 would require entirely overriding two or more CRUD methods.\nAdd the resource in MMv1. Generate the beta provider From the beta provider, copy the files generated for the resource to the following locations: Resource: Copy to the appropriate service folder inside magic-modules/mmv1/third_party/terraform/services Documentation: magic-modules/mmv1/third_party/terraform/website/docs/r Tests: magic-modules/mmv1/third_party/terraform/tests Sweepers: magic-modules/mmv1/third_party/terraform/utils Modify the Go code as needed. Replace the comments at the top of the file with the following: \u0026lt;% autogen_exception -%\u0026gt; If any of the added Go code (including any imports) is beta-only, change the file suffix to .go.erb and wrap the beta-only code in a version guard: \u0026lt;% unless version = 'ga' -%\u0026gt;...\u0026lt;% else -%\u0026gt;...\u0026lt;% end -%\u0026gt;. Register the resource in magic-modules/mmv1/third_party/terraform/utils/provider.go.erb under \u0026ldquo;START handwritten resources\u0026rdquo; Add a version guard for any beta-only resources. Add fields # MMv1 For each API field, copy the following template into the resource\u0026rsquo;s properties attribute. Be sure to indent appropriately. # Supported types: String, Integer, Boolean, Double, Enum, # ResourceRef (link to a GCP resource), KeyValuePairs (string -\u0026gt; string map), # Array, and NestedObject - !ruby/object:Api::Type::String name: \u0026#39;API_FIELD_NAME\u0026#39; description: | MULTILINE_FIELD_DESCRIPTION # Marks the field (and any subfields) as beta-only. Ensure a beta version block # is present in provider.yaml. Do not use if an ancestor field (or the overall # resource) is already marked as beta-only. # min_version: beta # If true, the field (and any subfields) are considered immutable - that is, # only settable on create. If unset or false, the field is still considered # immutable if any ancestor field (or the overall resource) is immutable, # unless `update_url` is set. # immutable: true # If set, changes to the field\u0026#39;s value trigger a separate call to a specific # API method for updating the field\u0026#39;s value. The field is not considered # immutable even if an ancestor field (or the overall resource) is immutable. # Terraform field names enclosed in double curly braces are replaced with the # field values from the resource at runtime. # update_url: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames/{{name}}/setFieldName\u0026#39; # If update_url is also set, overrides the verb used to update this specific # field. Allowed values: :POST, :PUT, :PATCH. Default: Resource\u0026#39;s update_verb # (which defaults to :PUT if unset). # update_verb: :POST # If true, the field is required. If unset or false, the field is optional. # required: true # If true, the field is output-only - that is, it cannot be configured by the # user. If unset or false, the field is configurable. # output: true # If true, the provider sets the field\u0026#39;s value in the resource state based only # on the user\u0026#39;s configuration. If false or unset, the provider sets the field\u0026#39;s # value in the resource state based on the API response. Only use this attribute # if the field cannot be read from GCP due to either API or provider constraints. # ignore_read: true # Sets a client-side default value for the field. This should be used if the # API has a default value that applies in all cases and is stable. Removing # or changing a default value is a breaking change. If unset, the field defaults # to an \u0026#34;empty\u0026#34; value (such as zero, false, or an empty string). # default_value: DEFAULT_VALUE # If true, and the field is either not set or set to an \u0026#34;empty\u0026#34; value (such as # zero, false, or empty strings), the provider accepts any value returned from # the API as the value for the field. If false, and the field is either not set # or set to an \u0026#34;empty\u0026#34; value, the provider treats the field\u0026#39;s `default_value` # as the value for the field and shows a diff if the API returns any other # value for the field. This attribute is useful for complex or # frequently-changed API-side defaults, but provides less useful information at # plan time than `default_value` and causes the provider to ignore user # configurations that explicitly set the field to an \u0026#34;empty\u0026#34; value. # `default_from_api` and `send_empty_value` cannot both be true on the same field. # default_from_api: true # If true, the provider sends \u0026#34;empty\u0026#34; values (such as zero, false, or empty # strings) to the API if set explicitly in the user\u0026#39;s configuration. If false, # \u0026#34;empty\u0026#34; values cause the field to be omitted entirely from the API request. # This attribute is useful for fields where the API would behave differently # for an \u0026#34;empty\u0026#34; value vs no value for a particular field - for example, # boolean fields that have an API-side default of true. # `send_empty_value` and `default_from_api` cannot both be true on the same field. # send_empty_value: true # Specifies a list of fields (excluding the current field) that cannot be # specified at the same time as the current field. Must be set separately on # all listed fields. # conflicts: # - field_one # - nested_object.0.nested_field # Specifies a list of fields (including the current field) that cannot be # specified at the same time (but at least one of which must be set). Must be # set separately on all listed fields. # exactly_one_of: # - field_one # - nested_object.0.nested_field # Enum only. Sets allowed values as ruby \u0026#34;literal constants\u0026#34; (prefixed with a # colon). If the allowed values change frequently, use a String field instead # to allow better forwards-compatibility, and link to API documentation # stating the current allowed values in the String field\u0026#39;s description. Do not # include UNSPECIFIED values in this list. # values: # - :VALUE_ONE # - :VALUE_TWO # Array only. Sets the expected type of the items in the array. Primitives # should use the name of the primitive class as a string; other types should # define the attributes of the nested type. # item_type: Api::Type::String # item_type: !ruby/object:Api::Type::Enum # name: \u0026#39;required but unused\u0026#39; # description: \u0026#39;required but unused\u0026#39; # values: # - :VALUE_ONE # - :VALUE_TWO # NestedObject only. Defines fields nested inside the current field. # properties: # - !ruby/object:Api::Type::String # name: \u0026#39;FIELD_NAME\u0026#39; # description: | # MULTI_LINE_FIELD_DESCRIPTION Modify the field configuration according to the API documentation and behavior. Delete all remaining comments in the field configuration (including attribute descriptions) that were copied from the above template. Note: The template includes the most commonly-used fields. For a comprehensive reference, see Field reference ↗.\nHandwritten Add the field to the handwritten resource\u0026rsquo;s schema. The new field(s) should mirror the API\u0026rsquo;s structure to ease predictability and maintenance. However, if there is an existing related / similar field in the resource that uses a different convention, follow that convention instead. Enum fields in the API should be represented as TypeString in Terraform for forwards-compatibility. Link to the API documentation of allowed values in the field description. Terraform field names should always use snake case ↗. See Schema Types ↗ and Schema Behaviors ↗ for more information about field schemas. Add handling for the new field in the resource\u0026rsquo;s Create method and Update methods. \u0026ldquo;Expanders\u0026rdquo; convert Terraform resource data to API request data. For top level fields, add an expander. If the field is set or has changed, call the expander and add the resulting value to the API request. For other fields, add logic to the parent field\u0026rsquo;s expander to add the field to the API request. Use a nested expander for complex logic. Add handling for the new field in the resource\u0026rsquo;s Read method. \u0026ldquo;Flatteners\u0026rdquo; convert API response data to Terraform resource data. For top level fields, add a flattener. Call d.Set() on the flattened API response value to store it in Terraform state. For other fields, add logic to the parent field\u0026rsquo;s flattener to convert the value from the API response to the Terraform state value. Use a nested flattener for complex logic. If any of the added Go code (including any imports) is beta-only, change the file suffix to .go.erb and wrap the beta-only code in a version guard: \u0026lt;% unless version = 'ga' -%\u0026gt;...\u0026lt;% else -%\u0026gt;...\u0026lt;% end -%\u0026gt;. Add a new guard rather than adding the field to an existing guard; it is easier to read. Add IAM support # This section covers how to add IAM resources in Terraform if they are supported by a particular API resource (indicated by setIamPolicy and getIamPolicy methods in the API documentation for the resource).\nMMv1 Add the following top-level block to ResourceName.yaml directly above parameters. iam_policy: !ruby/object:Api::Resource::IamPolicy # Name of the field on the terraform IAM resources which references # the parent resource. Update to match the parent resource\u0026#39;s name. parent_resource_attribute: \u0026#39;resource_name\u0026#39; # Character preceding setIamPolicy in the full URL for the API method. # Usually `:` method_name_separator: \u0026#39;:\u0026#39; # HTTP method for getIamPolicy. Usually :POST. # Allowed values: :GET, :POST. Default: :GET fetch_iam_policy_verb: :POST # Overrides the HTTP method for setIamPolicy. # Allowed values: :POST, :PUT. Default: :POST # set_iam_policy_verb: :POST # Must match the parent resource\u0026#39;s import_format, but with the # parent_resource_attribute value substituted for the final field. import_format: [ \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames/{{resource_name}}\u0026#39; ] # Valid IAM role that can be set by generated tests. Default: \u0026#39;roles/viewer\u0026#39; # allowed_iam_role: \u0026#39;roles/viewer\u0026#39; # If IAM conditions are supported, set this attribute to indicate how the # conditions should be passed to the API. Allowed values: :QUERY_PARAM, # :REQUEST_BODY, :QUERY_PARAM_NESTED. Note: :QUERY_PARAM_NESTED should # only be used if the query param field contains a `.` # iam_conditions_request_type: :REQUEST_BODY # Marks IAM support as beta-only # min_version: beta Modify the template as needed to match the API resource\u0026rsquo;s documented behavior. These are the most commonly-used fields. For a comprehensive reference, see IAM policy YAML reference ↗. Delete all remaining comments in the IAM configuration (including attribute descriptions) that were copied from the above template. Handwritten Warning: IAM support for handwritten resources should be implemented using MMv1. New handwritten IAM resources will only be accepted if they cannot be implemented using MMv1.\nAdd support in MMv1 # Follow the MMv1 directions in Add the resource to create a skeleton ResourceName.yaml file for the handwritten resource, but set only the following top-level fields: name, base_url (set to URL of IAM parent resource), self_link (set to same value as base_url) description (required but unused), id_format, import_format, and properties. Follow the MMv1 directions in Add fields to add only the fields used by base_url. Follow the MMv1 directions in this section to add IAM support. Convert to handwritten (not usually necessary) # Generate the beta provider From the beta provider, copy the files generated for the IAM resources to the following locations: Resource: Copy to the appropriate service folder inside magic-modules/mmv1/third_party/terraform/services Documentation: magic-modules/mmv1/third_party/terraform/website/docs/r Tests: magic-modules/mmv1/third_party/terraform/tests Modify the Go code as needed. Replace the comments at the top of the file with the following: \u0026lt;% autogen_exception -%\u0026gt; If any of the added Go code (including any imports) is beta-only, change the file suffix to .go.erb and wrap the beta-only code in a version guard: \u0026lt;% unless version = 'ga' -%\u0026gt;...\u0026lt;% else -%\u0026gt;...\u0026lt;% end -%\u0026gt;. Register the binding, member, and policy resources in magic-modules/mmv1/third_party/terraform/utils/provider.go.erb under \u0026ldquo;START non-generated IAM resources\u0026rdquo; Add a version guard for any beta-only resources. Add documentation # MMv1 Documentation is autogenerated based on the resource and field configurations. To preview the documentation:\nGenerate the providers Copy and paste the generated documentation into the Hashicorp Registry\u0026rsquo;s Doc Preview Tool to see how it is rendered. Handwritten Open the resource documentation in magic-modules/third_party/terraform/website/docs/r/ using an editor of your choice.\nThe name of the file is the name of the resource without a google_ prefix. For example, for google_compute_instance, the file is called compute_instance.html.markdown For beta-only resources, add the following snippet directly above the first example:\n~\u0026gt; **Warning:** This resource is in beta, and should be used with the terraform-provider-google-beta provider. See [Provider Versions](https://terraform.io/docs/providers/google/guides/provider_versions.html) for more details on beta resources. For resources that are in the google provider but have beta-only fields, make sure that all beta-only fields are clearly marked. For example:\n* `FIELD_NAME` - (Optional, [Beta](https://terraform.io/docs/providers/google/guides/provider_versions.html)) FIELD_DESCRIPTION Replace FIELD_NAME and FIELD_DESCRIPTION with the field\u0026rsquo;s name and description.\nGenerate the providers\nCopy and paste the generated documentation into the Hashicorp Registry\u0026rsquo;s Doc Preview Tool to see how it is rendered.\nWhat\u0026rsquo;s next? # Add MMv1 tests Add handwritten tests Test your changes "},{"id":11,"href":"/magic-modules/contribute/","title":"Contribute","section":"Overview","content":""},{"id":12,"href":"/magic-modules/reference/field-reference/","title":"Field YAML reference ↗","section":"Reference","content":"FORCE MENU RENDER\n"},{"id":13,"href":"/magic-modules/reference/iam-policy-reference/","title":"IAM policy YAML reference ↗","section":"Reference","content":"FORCE MENU RENDER\n"},{"id":14,"href":"/magic-modules/get-started/run-provider-tests/","title":"Run provider tests","section":"Get started","content":" Run provider tests locally # Note: If you want to test changes you\u0026rsquo;ve made in Magic Modules, you need to first generate the provider you want to test. Setup # Authentication is described in more detail here.\nTests generally assume the following environment variables must be set in order to run tests:\nGOOGLE_PROJECT GOOGLE_CREDENTIALS|GOOGLE_CLOUD_KEYFILE_JSON|GCLOUD_KEYFILE_JSON|GOOGLE_USE_DEFAULT_CREDENTIALS GOOGLE_REGION GOOGLE_ZONE Note that the credentials you provide must be granted wide permissions on the specified project. These tests provision real resources, and require permission in order to do so. Most developers on the team grant their test service account roles/editor or roles/owner on their project. Additionally, to ensure that your tests are performed in a region and zone with wide support for GCP features, GOOGLE_REGION should be set to us-central1 and GOOGLE_ZONE to us-central1-a.\nAdditional variable may be required for other tests, and should get flagged when running them by Go skipping the test and flagging in the output it was skipped, with a skip message explaining why. The most typical extra values required are those required for project creation:\nGOOGLE_ORG GOOGLE_BILLING_ACCOUNT Run unit tests # Unit tests (that is, tests that do not interact with the GCP API) are very fast and you can generally run them all if you have changed any of them:\n# for ga provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google make test make lint # for beta provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta make test make lint Run acceptance tests # You can run tests against the provider you generated in the OUTPUT_PATH location. When running tests, specify which to run using TESTARGS, such as:\n# for ga provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google make testacc TEST=./google TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic\u0026#39; # for beta provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta make testacc TEST=./google-beta TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic\u0026#39; TESTARGS allows you to pass testing flags to go test. The most important is -run, which allows you to limit the tests that get run. There are 2000+ tests, and running all of them takes over 9 hours and requires a lot of GCP quota.\n-run is regexp-like, so multiple tests can be run in parallel by specifying a common substring of those tests (for example, TestAccContainerNodePool to run all node pool tests).\nDebugging tests # You can increase your test verbosity and redirect the output to a log file for analysis. This is often helpful in debugging issues.\n# for ga provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google TF_LOG=TRACE make testacc TEST=./google TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic\u0026#39; \u0026gt; output.log # for beta provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta TF_LOG=TRACE make testacc TEST=./google-beta TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic\u0026#39; \u0026gt; output.log You can also debug tests with Delve:\n# Navigate to the google package within your local GCP Terraform provider Git clone. cd $GOPATH/src/github.com/terraform-providers/terraform-provider-google/google # Execute the dlv command to launch the test. # Note that the --test.run flag uses the same regexp matching as go test --run. TF_ACC=1 dlv test -- --test.v --test.run TestAccComputeRegionBackendService_withCdnPolicy Type \u0026#39;help\u0026#39; for list of commands. (dlv) b google.TestAccComputeRegionBackendService_withCdnPolicy Breakpoint 1 set at 0x1de072b for github.com/terraform-providers/terraform-provider-google/google.TestAccComputeRegionBackendService_withCdnPolicy() ./resource_compute_region_backend_service_test.go:540 (dlv) c === RUN TestAccComputeRegionBackendService_withCdnPolicy \u0026gt; github.com/terraform-providers/terraform-provider-google/google.TestAccComputeRegionBackendService_withCdnPolicy() ./resource_compute_region_backend_service_test.go:540 (hits goroutine(7):1 total:1) (PC: 0x1de072b) 535: }, 536: }, 537: }) 538: } 539: =\u0026gt; 540: func TestAccComputeRegionBackendService_withCdnPolicy(t *testing.T) { 541: t.Parallel() 542: 543: var svc compute.BackendService 544: resource.Test(t, resource.TestCase{ 545: PreCheck: func() { acctest.AccTestPreCheck(t) }, (dlv) Testing with different terraform versions # Tests will use whatever version of the terraform binary is found on your path. To test with multiple versions of terraform core, you must run the tests multiple times with different versions. You can use tfenv to manage your system terraform versions.\n"},{"id":15,"href":"/magic-modules/develop/add-mmv1-test/","title":"Add an MMv1 test","section":"Develop","content":" Add an MMv1 test # For generated resources, you can add an example to the mmv1/templates/terraform/examples directory, which contains a set of templated Terraform configurations.\nAfter writing out the example and filling out some metadata, Magic Modules will insert it into the resource documentation page, and generate a test case stepping through the following stages:\nRun terraform apply on the configuration, waiting for it to succeed and recording the results in Terraform state Run terraform plan, and fail if Terraform detects any drift Clear the resource from state and run terraform import on it Deeply compare the original state from terraform apply and the terraform import results, returning an error if any values are not identical Destroy all resources in the configuration using terraform destroy, waiting for the destroy command to succeed Call GET on the resource, and fail the test if it is still present Example Configuration File # First, you\u0026rsquo;ll want to add the example file. It needs to end in the filename .tf.erb, and is typically named service_resource_descriptive_name. For example, pubsub_topic_geo_restricted.tf.erb. Inside, you\u0026rsquo;ll write a complete Terraform configuration that provisions the resource and all of the required dependencies. For example, in mmv1/templates/terraform/examples/pubsub_subscription_dead_letter.tf.erb:\nresource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;\u0026#34; { name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;topic_name\u0026#39;] %\u0026gt;\u0026#34; } resource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;_dead_letter\u0026#34; { name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;topic_name\u0026#39;] %\u0026gt;-dead-letter\u0026#34; } resource \u0026#34;google_pubsub_subscription\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;\u0026#34; { name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;subscription_name\u0026#39;] %\u0026gt;\u0026#34; topic = google_pubsub_topic.\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;.name dead_letter_policy { dead_letter_topic = google_pubsub_topic.\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;_dead_letter.id max_delivery_attempts = 10 } } The ctx variable provides metadata at generation time, and should be used in two ways:\nThe Terraform ID of a single instance of the primary resource should be supplied through \u0026lt;%= ctx[:primary_resource_id] %\u0026gt; (in this example multiple resources use the value, although only the first google_pubsub_topic requires it). The resource kind you are testing with an id equal to \u0026lt;%= ctx[:primary_resource_id] %\u0026gt; is the one that will be imported. Unique values can be supplied through \u0026lt;%= ctx[:vars]['{{var}}'] %\u0026gt;, where {{var}} is an arbitrary key you define. These values are created by appending suffixes to them, and are typically only used for names- most values should be constant within the configuration. Topic.yaml metadata # Once your configuration is written, go in Topic.yaml and find the examples block for the resource. Generally it\u0026rsquo;ll be above the properties block. In there, append an entry such as the following:\n- !ruby/object:Provider::Terraform::Examples name: \u0026#34;pubsub_subscription_dead_letter\u0026#34; primary_resource_id: \u0026#34;example\u0026#34; vars: topic_name: \u0026#34;example-topic\u0026#34; subscription_name: \u0026#34;example-subscription\u0026#34; The name should match the base name of your example file, primary_resource_id is an arbitrary snake_cased string that describes the resource, and the vars map should contain each key you defined previously.\nImportant: Any vars that are part of the resource\u0026rsquo;s id should include at least one hyphen or underscore; this triggers addition of a tf-test or tf_test prefix, which is what we use to detect and delete stray resources that are sometimes left over during test runs. Results # Your configuration will ultimately generate a Go test case similar to the following based on the snippets above:\nfunc TestAccPubsubSubscription_pubsubSubscriptionDeadLetterExample(t *testing.T) { t.Parallel() context := map[string]interface{}{ \u0026#34;random_suffix\u0026#34;: acctest.RandString(t, 10), } acctest.VcrTest(t, resource.TestCase{ PreCheck: func() { acctest.AccTestPreCheck(t) }, ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories(t), CheckDestroy: testAccCheckPubsubSubscriptionDestroyProducer(t), Steps: []resource.TestStep{ { Config: testAccPubsubSubscription_pubsubSubscriptionDeadLetterExample(context), }, { ResourceName: \u0026#34;google_pubsub_subscription.example\u0026#34;, ImportState: true, ImportStateVerify: true, ImportStateVerifyIgnore: []string{\u0026#34;topic\u0026#34;}, }, }, }) } func testAccPubsubSubscription_pubsubSubscriptionDeadLetterExample(context map[string]interface{}) string { return acctest.Nprintf(` resource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;example\u0026#34; { name = \u0026#34;tf-test-example-topic%{random_suffix}\u0026#34; } resource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;example_dead_letter\u0026#34; { name = \u0026#34;tf-test-example-topic%{random_suffix}-dead-letter\u0026#34; } resource \u0026#34;google_pubsub_subscription\u0026#34; \u0026#34;example\u0026#34; { name = \u0026#34;tf-test-example-subscription%{random_suffix}\u0026#34; topic = google_pubsub_topic.example.name dead_letter_policy { dead_letter_topic = google_pubsub_topic.example_dead_letter.id max_delivery_attempts = 10 } } `, context) } Update tests # Update tests can only be added as handwritten tests.\nTests that use beta features # For tests that use beta features, you\u0026rsquo;ll need to perform two additional steps:\nAdd provider = google-beta to every resource in the test (even resources that aren\u0026rsquo;t being tested and/or are also in the GA provider) Add min_version: beta to the Provider::Terraform::Examples block For example, modifying the snippets above:\nresource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;\u0026#34; { provider = google-beta name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;topic_name\u0026#39;] %\u0026gt;\u0026#34; } resource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;_dead_letter\u0026#34; { provider = google-beta name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;topic_name\u0026#39;] %\u0026gt;-dead-letter\u0026#34; } resource \u0026#34;google_pubsub_subscription\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;\u0026#34; { provider = google-beta name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;subscription_name\u0026#39;] %\u0026gt;\u0026#34; topic = google_pubsub_topic.\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;.name dead_letter_policy { dead_letter_topic = google_pubsub_topic.\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;_dead_letter.id max_delivery_attempts = 10 } } - !ruby/object:Provider::Terraform::Examples name: \u0026#34;pubsub_subscription_dead_letter\u0026#34; min_version: beta primary_resource_id: \u0026#34;example\u0026#34; vars: topic_name: \u0026#34;example-topic\u0026#34; subscription_name: \u0026#34;example-subscription\u0026#34; "},{"id":16,"href":"/magic-modules/reference/","title":"Reference","section":"Overview","content":""},{"id":17,"href":"/magic-modules/get-started/use-built-provider/","title":"Use built provider","section":"Get started","content":" Use built provider locally # Note: If you want to test changes you\u0026rsquo;ve made in Magic Modules, you need to first generate the provider you want to test. Sometimes, for example for manual testing, you may want to build the provider from source and use it with terraform.\nDeveloper Overrides # Note: Developer overrides are only available in Terraform v0.14 and later. By default Terraform will download providers from the public Registry, but there are several ways to override this behaviour and use providers from other sources. HashiCorp recommends developers use development overrides when debugging code changes in a provider.\nDeveloper overrides are defined in an explicit CLI configuration file. They allow you to use locally-built versions of providers without needing to change your Terraform configuration files or needing to run terraform init. There are also other features such as explicit warnings when overrides are in effect.\nIn the sections below we describe how to create a Terraform CLI configuration file, and how to make the CLI use the file via an environment variable.\nSetup # Choose your architecture below.\nMac (ARM64 and AMD64), Linux AMD64 First, you need to find the location where built provider binaries are created. To do this, run this command and make a note of the path value:\ngo env GOBIN # If the above returns nothing, then run the command below and add \u0026#34;/bin\u0026#34; to the end of the output path. go env GOPATH Next, create an empty configuration file. This could be in your $HOME directory or in a project directory; location does not matter. The extension .tfrc is required but the file name can be whatever you choose.\n# create an empty file touch ~/tf-dev-override.tfrc # open the file with a text editor of your choice, e.g: vi ~/tf-dev-override.tfrc Open the empty file with a text editor and paste in these contents:\nprovider_installation { # Developer overrides will stop Terraform from downloading the listed # providers their origin provider registries. dev_overrides { \u0026#34;hashicorp/google\u0026#34; = \u0026#34;\u0026lt;REPLACE-ME\u0026gt;/bin\u0026#34; \u0026#34;hashicorp/google-beta\u0026#34; = \u0026#34;\u0026lt;REPLACE-ME\u0026gt;/bin\u0026#34; } # For all other providers, install them directly from their origin provider # registries as normal. If you omit this, Terraform will _only_ use # the dev_overrides block, and so no other providers will be available. direct {} } Edit the file to replace \u0026lt;REPLACE-ME\u0026gt; with the path you saved from the first step, making sure to keep /bin at the end of the path.\nPlease note: the full path is required and environment variables cannot be used. For example, \u0026quot;/Users/MyUserName/go/bin\u0026quot; is a valid path for a user called MyUserName, but \u0026quot;~/go/bin\u0026quot; or \u0026quot;$HOME/go/bin\u0026quot; will not work.\nFinally, save the file.\nWindows (Vista and above) First, you need to find the location where built provider binaries are created. To do this, run this command and make a note of the path value:\necho %GOPATH% Next, create an empty configuration file. The location does not matter and could be in your home directory or a specific project directory. The extension .tfrc is required but the file name can be whatever you choose.\nIf you are unsure where to put the file, put it in the %APPDATA% directory (use $env:APPDATA in PowerShell to find its location on your system).\n# create an empty file type nul \u0026gt; \u0026#34;$($env:APPDATA)\\tf-dev-override.tfrc\u0026#34; # open the file with a text editor of your choice, e.g: notepad \u0026#34;$($env:APPDATA)\\tf-dev-override.tfrc\u0026#34; Open the empty file with a text editor and paste in these contents:\nprovider_installation { # Developer overrides will stop Terraform from downloading the listed # providers their origin provider registries. dev_overrides { \u0026#34;hashicorp/google\u0026#34; = \u0026#34;\u0026lt;REPLACE-ME\u0026gt;\\bin\u0026#34; \u0026#34;hashicorp/google-beta\u0026#34; = \u0026#34;\u0026lt;REPLACE-ME\u0026gt;\\bin\u0026#34; } # For all other providers, install them directly from their origin provider # registries as normal. If you omit this, Terraform will _only_ use # the dev_overrides block, and so no other providers will be available. direct {} } Edit the file to replace \u0026lt;REPLACE-ME\u0026gt; with the output you saved from the first step, making sure to keep \\bin at the end of the path.\nPlease note: The full path is required and environment variables cannot be used. For example, C:\\Users\\MyUserName\\go\\bin is a valid path for a user called MyUserName.\nFinally, save the file.\nThis CLI configuration file you created in the steps above will allow Terraform to automatically use the binaries generated by the make build commands in the terraform-provider-google and terraform-provider-google-beta repositories instead of downloading the latest versions. All other providers will continue to be downloaded from the public Registry as normal.\nBuild provider # # ga provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google make build # beta provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta make build Using Terraform CLI developer overrides # To make Terraform use the configuration file you created, you need to set the TF_CLI_CONFIG_FILE environment variable to be a string containing the path to the configuration file (see the documentation here). The path can be either a relative or absolute path.\nAssuming that a configuration file was created at ~/tf-dev-override.tfrc, you can either export the environment variable or set it explicitly for each terraform command. Note that you need to use the full path:\n# either export the environment variable for your session export TF_CLI_CONFIG_FILE=\u0026#34;/Users/MyUserName/tf-dev-override.tfrc\u0026#34; # OR, set the environment variable value per command TF_CLI_CONFIG_FILE=\u0026#34;/Users/MyUserName/tf-dev-override.tfrc\u0026#34; terraform plan To check that the developer override is working, run a terraform plan command and look for a warning near the start of the terminal output that looks like the example below. It is not necessary to run the terraform init command to use development overrides.\n│ Warning: Provider development overrides are in effect │ │ The following provider development overrides are set in the CLI configuration: │ - hashicorp/google in /Users/MyUserName/go/bin │ - hashicorp/google-beta in /Users/MyUserName/go/bin │ │ The behavior may therefore not match any released version of the provider and applying │ changes may cause the state to become incompatible with published releases. Note: Developer overrides work without you needing to alter your Terraform configuration in any way. Download production providers # To stop using developer overrides, unset the TF_CLI_CONFIG_FILE environment variable or stop setting it in the commands you are executing.\nThis will then let Terraform resume normal behaviour of pulling published provider versions from the public Registry. Any version constraints in your Terraform configuration will come back into effect. Also, you may need to run terraform init to download the required version of the provider into your project directory if you haven\u0026rsquo;t already.\nAlternative: using a global CLI configuration file # If you do not want to use the TF_CLI_CONFIG_FILE environment variable, as described above, you can instead create a global version of the CLI configuration file. This configuration will be used automatically by Terraform. To do this, follow the guidance in the official documentation.\nIn this scenario you will need to remember to edit this file to swap between using developer overrides and using the production provider versions.\nPossible problems # Filesystem mirrors (particularly \u0026ldquo;implicit filesystem mirrors\u0026rdquo;) are used automatically by Terraform, so can interfere with the expected behaviour of Terraform if you\u0026rsquo;re not aware they\u0026rsquo;re present.\nTo stop using the filesystem mirror, you can run:\nrm -rf ~/.terraform.d/plugins/registry.terraform.io/hashicorp/ Another way to debug this is to run a Terraform command with the TF_LOG environment variable set to TRACE . Then, look for a log line similar to the below:\n[TRACE] getproviders.SearchLocalDirectory: found registry.terraform.io/hashicorp/google vX.X.X for darwin_arm64 at /Users/MyUserName/.terraform.d/plugins/registry.terraform.io/hashicorp/google/xxx More information # Filesystem mirrors # An alternative to developer overrides is to use filesystem mirrors, where Terraform can use locally built providers or published providers that you have downloaded to your local disk. More information about this approach is in the expandable section below.\nMore information Filesystem mirrors can used explicitly or implicitly by Terraform. Explicit filesystem mirrors can be defined via the CLI configuration file. In contrast, once implicit filesystem mirrors are created by a user they are discovered and used by Terraform automatically.\nFilesystem mirrors require providers\u0026rsquo; files to be saved with specific paths for them to work correctly. To help with this, you can use the terraform providers mirror command to download a published provider to your local filesystem with the required file path.\nImplied filesystem mirrors require manual cleanup if you want to revert back to using providers downloaded from the public Registry, and if an implied filesystem mirror is in place that a user is unaware of it can lead to confusing behaviour that is hard to debug. Other disadvantages compared to developer overrides include:\nNo warning in terminal output letting you know when your local files are in use. Need to set a version number for your local version of the provider which is compatible with your Terraform configuration\u0026rsquo;s version constraints Setup and cleanup required each time you swap to and from using them "},{"id":18,"href":"/magic-modules/develop/add-handwritten-test/","title":"Add a handwritten test","section":"Develop","content":" Add a handwritten test # For handwritten resources and generated resources that need to test update, handwritten tests must be added.\nTests are made up of a templated Terraform configuration where unique values like GCE names are passed in as arguments, and boilerplate to exercise that configuration.\nThe test boilerplate effectively does the following:\nRun terraform apply on the configuration, waiting for it to succeed and recording the results in Terraform state Run terraform plan, and fail if Terraform detects any drift Clear the resource from state and run terraform import on it Deeply compare the original state from terraform apply and the terraform import results, returning an error if any values are not identical Destroy all resources in the configuration using terraform destroy, waiting for the destroy command to succeed Call GET on the resource, and fail the test if it is still present Simple Tests # Terraform configurations are stored as string constants wrapped in Go functions like the following:\nfunc testAccComputeFirewall_basic(network, firewall string) string { return fmt.Sprintf(` resource \u0026#34;google_compute_network\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; auto_create_subnetworks = false } resource \u0026#34;google_compute_firewall\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; description = \u0026#34;Resource created for Terraform acceptance testing\u0026#34; network = google_compute_network.foobar.name source_tags = [\u0026#34;foo\u0026#34;] allow { protocol = \u0026#34;icmp\u0026#34; } } `, network, firewall) } For the most part, you can copy and paste a preexisting test case and modify it. For example, the following test case is a good reference:\nfunc TestAccComputeFirewall_noSource(t *testing.T) { t.Parallel() networkName := fmt.Sprintf(\u0026#34;tf-test-firewall-%s\u0026#34;, acctest.RandString(t, 10)) firewallName := fmt.Sprintf(\u0026#34;tf-test-firewall-%s\u0026#34;, acctest.RandString(t, 10)) acctest.VcrTest(t, resource.TestCase{ PreCheck: func() { acctest.AccTestPreCheck(t) }, ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories(t), CheckDestroy: testAccCheckComputeFirewallDestroyProducer(t), Steps: []resource.TestStep{ { Config: testAccComputeFirewall_noSource(networkName, firewallName), }, { ResourceName: \u0026#34;google_compute_firewall.foobar\u0026#34;, ImportState: true, ImportStateVerify: true, }, }, }) } func testAccComputeFirewall_noSource(network, firewall string) string { return fmt.Sprintf(` resource \u0026#34;google_compute_network\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; auto_create_subnetworks = false } resource \u0026#34;google_compute_firewall\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; description = \u0026#34;Resource created for Terraform acceptance testing\u0026#34; network = google_compute_network.foobar.name allow { protocol = \u0026#34;tcp\u0026#34; ports = [22] } } `, network, firewall) } Update tests # Inside of a test, additional steps can be added in order to transition between Terraform configurations, updating the stored state as it progresses. This allows you to exercise update behaviour. This modifies the flow from before:\nStart with an empty Terraform state For each Config and ImportState pair: Run terraform apply on the configuration, waiting for it to succeed and recording the results in Terraform state Run terraform plan, and fail if Terraform detects any drift Clear the resource from state and run terraform import on it Deeply compare the original state from terraform apply and the terraform import results, returning an error if any values are not identical Destroy all resources in the configuration using terraform destroy, waiting for the destroy command to succeed Call GET on the resource, and fail the test if it is still present For example:\nfunc TestAccComputeFirewall_disabled(t *testing.T) { t.Parallel() networkName := fmt.Sprintf(\u0026#34;tf-test-firewall-%s\u0026#34;, acctest.RandString(t, 10)) firewallName := fmt.Sprintf(\u0026#34;tf-test-firewall-%s\u0026#34;, acctest.RandString(t, 10)) acctest.VcrTest(t, resource.TestCase{ PreCheck: func() { acctest.AccTestPreCheck(t) }, ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories(t), CheckDestroy: testAccCheckComputeFirewallDestroyProducer(t), Steps: []resource.TestStep{ { Config: testAccComputeFirewall_disabled(networkName, firewallName), }, { ResourceName: \u0026#34;google_compute_firewall.foobar\u0026#34;, ImportState: true, ImportStateVerify: true, }, { Config: testAccComputeFirewall_basic(networkName, firewallName), }, { ResourceName: \u0026#34;google_compute_firewall.foobar\u0026#34;, ImportState: true, ImportStateVerify: true, }, }, }) } func testAccComputeFirewall_basic(network, firewall string) string { return fmt.Sprintf(` resource \u0026#34;google_compute_network\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; auto_create_subnetworks = false } resource \u0026#34;google_compute_firewall\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; description = \u0026#34;Resource created for Terraform acceptance testing\u0026#34; network = google_compute_network.foobar.name source_tags = [\u0026#34;foo\u0026#34;] allow { protocol = \u0026#34;icmp\u0026#34; } } `, network, firewall) } func testAccComputeFirewall_disabled(network, firewall string) string { return fmt.Sprintf(` resource \u0026#34;google_compute_network\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; auto_create_subnetworks = false } resource \u0026#34;google_compute_firewall\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; description = \u0026#34;Resource created for Terraform acceptance testing\u0026#34; network = google_compute_network.foobar.name source_tags = [\u0026#34;foo\u0026#34;] allow { protocol = \u0026#34;icmp\u0026#34; } disabled = true } `, network, firewall) } Testing Beta Features # If you worked with a beta feature and had to use beta version guards in a handwritten resource or set min_version: beta in a generated resource, you\u0026rsquo;ll want to version guard both the test case and configuration by enclosing them in ERB tags like below. Additionally, if the filename ends in .go, rename it to end in .go.erb.\n\u0026lt;% unless version == \u0026#39;ga\u0026#39; -%\u0026gt; // test case + config here \u0026lt;% end -%\u0026gt; Otherwise, tests using a beta feature are written exactly the same as tests using a GA one. Normally to use the beta provider, it\u0026rsquo;s necessary to specify provider = google-beta, as Terraform maps any resources prefixed with google_ to the google provider by default. However, inside the test framework, the google-beta provider has been aliased as the google provider and that is not necessary.\nNote: You may use version guards to test different configurations between the GA and beta provider tests, but it\u0026rsquo;s strongly recommended that you write different test cases instead, even if they\u0026rsquo;re slightly duplicative.\n"},{"id":19,"href":"/magic-modules/get-started/contributing/","title":"Contributing","section":"Get started","content":" General contributing steps # If you haven\u0026rsquo;t done so already, fork the Magic Modules repository into your GitHub account.\nCheck the issue tracker to see whether your feature has already been requested.\nIf there\u0026rsquo;s an issue and it already has a dedicated assignee, this indicates that someone might have already started to work on a solution. Otherwise, you\u0026rsquo;re welcome to work on the issue. Check whether the resource you would like to work on already exists in the following places:\ngoogle provider providers google-beta provider Hashicorp documentation If it exists, check the header of the downstream file to identify the type of tools used to generate the resource. For some resources, the code file, the test file and the documentation file might not be generated via the same tools.\nGenerated resources like google_compute_address can be identified by looking in their Go source for an AUTO GENERATED CODE header as well as a Type. \u0026ldquo;Generated resources\u0026rdquo; typically refers to just the MMv1 type, and DCL type resources are considered \u0026ldquo;DCL-based\u0026rdquo;. (Currently DCL-related contribution are not supported) Handwritten resources like google_container_cluster can be identified if they have source code present under the mmv1/third_party/terraform/resources folder or by the absence of the AUTO GENERATED CODE header in their Go source. If not, decide which tool you would like to use to implement the resource:\nMMv1 is strongly preferred over handwriting the resource unless the resource cannot be generated. Currently, only handwritten datasources are supported. Make the code change.\nThe How To section provides detailed instructions on how to make your change. Generate the providers that include your change.\nRun provider tests locally that are relevant to the change you made. (Testing the PR locally and pushing the commit to the PR only after the tests pass locally may significantly reduce back-and-forth in review.)\nPush your changes to your magic-modules repo fork and send a pull request from that branch to the main branch on magic-modules. A reviewer will be assigned automatically to your PR.\nGet approval to start Clould Builder jobs from the reviewer if you\u0026rsquo;re an community contributor\nWait for the the modules magician to generate downstream diff (which should take about 15 mins after creating the PR) to make sure all changes are generated correctly in downstream repos.\nWait for the VCR test results. Get to know general workflow for VCR tests Submit your change. The recorded tests are ran against your changes by the modular-magician. Tests will fail if: Your PR has changed the HTTP request values sent by the provider Your PR does not change the HTTP request values, but fails on the values returned in an old recording The recordings are out of sync with the merge-base of your PR, and an unrelated contributor\u0026rsquo;s change has caused a false positive The modular-magician will leave a message indicating the number of passing and failing VCR tests. If there is a failure, the modular-magician user will leave a message indicating the \u0026ldquo;Triggering VCR tests in RECORDING mode for the following tests that failed during VCR:\u0026rdquo; marking which tests failed. If a test does not appear related to your PR, it probably isn\u0026rsquo;t! The modular-magician will kick off a second test run targeting only the failed tests, this time hitting the live GCP APIs. If there are tests that fail at this point, a message stating Tests failed during RECORDING mode: will be left indicating the tests. If a test that appears to be related to your change has failed here, it\u0026rsquo;s likely your change has introduced an issue. You can view the debug logs for the test by clicking the \u0026ldquo;view\u0026rdquo; link beside the test case to attempt to debug what\u0026rsquo;s going wrong. If a test that appears to be completely unrelated has failed, it\u0026rsquo;s possible that a GCP API has changed in a way that broke the provider or our environment capped on a quota. Where possible, take a look at the logs and see if you can figure out what needs to be fixed related to your change. The false positive rate on these tests is extremely high between changes in the API, Cloud Build bugs, and eventual consistency issues in test recordings so we don\u0026rsquo;t expect contributors to wholly interpret the results — that\u0026rsquo;s the responsibility of your reviewer.\nIf your assigned reviewer does not respond to changes on a pull request within two US business days, ping them on the pull request.\nAfter your PR is merged, it will be released to customers in around one to two weeks.\n"},{"id":20,"href":"/magic-modules/develop/add-handwritten-datasource/","title":"Add a datasource","section":"Develop","content":" Add a datasource # Note: only handwritten datasources are currently supported\nDatasources are like terraform resources except they don\u0026rsquo;t create anything. They are simply read-only operations that will expose some sort of values needed for subsequent resource operations. If you\u0026rsquo;re adding a field to an existing datasource, check the Resource section. Everything there will be mostly consistent with the type of change you\u0026rsquo;ll need to make. For adding a new datasource there are 5 steps to doing so.\nCreate a new datasource declaration file and a corresponding test file Add Schema and Read operation implementation Add the datasource to the provider.go.erb index Implement a test which will create and resources and read the corresponding datasource. Add documentation. See: Add documentation for a handwritten data source For creating a datasource based off an existing resource you can make use of the schema directly. Otherwise implementing the schema directly, similar to normal resource creation, is the desired path.\nResourceless Datasources # Datasources not backed by a resource are possible to add as well. They follow the same general steps as adding a resource-based datasource, except that a full Read method will need to be defined for them rather than calling a resource\u0026rsquo;s Read method.\nNote that while resource-based datasources can depend on the resource read method for API calls, resourceless datasources need to make them themselves. An HTTP-based client that\u0026rsquo;s properly configured with logging and retries must be used, such as a client from the https://github.com/googleapis/google-api-go-client library, or the raw HTTP client used in MMV1 through SendRequest.\n"},{"id":21,"href":"/magic-modules/get-started/provider-documentation/","title":"Provider documentation","section":"Get started","content":" Provider documentation # The provider is documented on HashiCorp\u0026rsquo;s Terraform Registry, which includes information about individual resources and datasources, and includes guides to help users configure or upgrade the provider in their projects.\nThis document includes details about how provider documentation is used by the Terraform Registry, how it is made in the Magic Modules repo, and tools you can use when editing documentation.\nThere are other pages under How To that describe how to approach making additions to the documentation.\nHow documentation is used by the Terraform Registry # The provider\u0026rsquo;s documentation is rendered in the Terraform Registry using markdown files that are packaged into each release. The Registry allows users to browse past versions of the documentation, for example the documentation for v3.0.0.\nThere are 4 types of documentation page. There\u0026rsquo;s the index page, documentation for resources, documentation for data sources, and finally guide pages.\nFor the Registry to successfully render documentation page, the markdown files in each provider release need to follow some requirements, described below.\nDirectory structure # Files need to be saved in a specific directory.\nmmv1/third_party/terraform/website/docs/ ├─ guides/ │ ├─ ... ├─ d/ │ ├─ ... ├─ r/ │ ├─ ... ├─ index.html.markdown Note that the Google provider uses a legacy version of this requirement - a website/docs/ folder.\nYAML frontmatter # Each file must include specific YAML frontmatter.\nsubcategory - for resource/data source pages - determines where the link to the page is located in the left-side navigation. page_title - for guide pages - sets the page title (as there isn\u0026rsquo;t a resource to name it after). Here\u0026rsquo;s an example. What information documentation needs to include # HashiCorp advice is to include these sections:\nTitle and description Example Usage section Argument Reference section Attribute Reference section In the Google provider we also include:\nTimeouts, describing configurable timeouts for a resource: see example Import, how to import a resource into Terraform state: see example User Project Overrides, whether or not direct user project overrides are supported: see example How do you test documentation changes? # You can copy and paste markdown into the Registry\u0026rsquo;s Doc Preview Tool to see how it will be rendered.\nThere currently isn\u0026rsquo;t a way to preview how frontmatter will be used to create the left-side navigation menu.\nWhat formatting is available # You can expect markdown to be rendered in a similar way to READMEs in GitHub. When in doubt, you can test how some markdown will be rendered using the testing tool in the Doc Preview Tool mentioned above.\nSomething useful to be aware of are callouts, that allow blue, yellow and red (warning) sections to be used for important information. To see how they\u0026rsquo;re rendered, paste the markdown below into the Doc Preview Tool.\n-\u0026gt; **Note** This callout is blue ~\u0026gt; **Note** This callout is yellow !\u0026gt; **Warning** This callout is red How to contribute to the provider documentation # Handwritten documentation # Terraform Provider Google (TPG) contains handwritten documentation for handwritten resources and data sources. For guidance on updating handwritten documentation, see:\nUpdate handwritten provider documentation Add documentation for a handwritten data source Generated documentation (mmv1) # The majority of resources in TPG are generated, and the information used to generate provider code is also used to generate documentation. For information about how documentation is generated, see:\nAdd and update MMv1 resource documentation "},{"id":22,"href":"/magic-modules/develop/add-handwritten-datasource-documentation/","title":"Add datasource documentation","section":"Develop","content":" Add data source documentation # Note: If you want to find information about documentation for a generated resource, look at the MMv1 resource documentation page instead. The information on this page will not be relevant for resources that have generated documentation. How provider documentation works # For general information about how provider documentation works, see Provider Documentation. That page contains information about how documentation should be structured and how you can test changes to documentation.\nThis page includes only instructions on how to add documentation for a new handwritten data source, with minimal background info.\nFinding the relevant file location # Handwritten documentation is located in the website/docs folder, shown below.\nmmv1/third_party/terraform/website/docs/ ├─ guides/ │ ├─ ... ├─ d/ │ ├─ ... ├─ r/ │ ├─ ... ├─ index.html.markdown The subfolder d corresponds to data sources, and inside there is a file for each data source.\nCreating the new markdown file # Next you need to add the file for the new data source\u0026rsquo;s documentation. Create a new file inside the d folder. The filename should be the name of the data source with the google_ prefix removed. For example if you were adding a new data source google_foobar then you would need to create a new file with the name foobar.html.markdown.\nAdding contents # Pages within the documentation need to be consistent and contain the sections that users expect. Below is some guidance about the different sections to include and what their contents should be.\nFrontmatter # The top of the file needs to contain frontmatter, which is used to create the new documentation page\u0026rsquo;s title and manage how the page is linked to in the documentation\u0026rsquo;s sidebar navigation. It it not rendered but it is very important for the new page in the documentation to be generated and available to users.\nYou need to make sure your file\u0026rsquo;s frontmatter includes:\nsubcategory - This sets which section in the left-side navigation menu the new page is categorised into. page_title - This frontmatter is specific to files in the Guides section (/website/docs/guides) but we set it for all markdown files. description - A description of the page. For example, here is the frontmatter from /website/docs/d/container_cluster.html.markdown (link to generated page):\n--- subcategory: \u0026#34;Kubernetes (Container) Engine\u0026#34; page_title: \u0026#34;Google: google_container_cluster\u0026#34; description: |- Get info about a Google Kubernetes Engine cluster. --- Page title and description # The next section in the markdown file is rendered as the first part of the page body.\nIt should contain:\nthe page title, as an H1 header a description general information about the data source The description can be as long or as short as necessary. The minimum information that\u0026rsquo;s included in this section are links to official documentation and the API reference pages. Other guidance, warnings, or explanations of concepts can be included here. To create pronounced warning or info sections, see the provider documentation page for info.\nFor example, here\u0026rsquo;s the title and opening description of /website/docs/d/cloud_run_locations.html.markdown (link to generated page):\n# google\\_cloud\\_run\\_locations Get Cloud Run locations available for a project. To get more information about Cloud Run, see: * [API documentation](https://cloud.google.com/run/docs/reference/rest/v1/projects.locations) * How-to Guides * [Official Documentation](https://cloud.google.com/run/docs/) Example usage # The next section includes one or more examples showing how a user may use the data source in their Terraform configuration. The examples can be basic and show what the minimum number of arguments are required, or they can be used to demonstrate more complex usage of the data source if necessary.\nFor example, here\u0026rsquo;s the example usage section from /website/docs/d/kms_crypto_key.html.markdown (link to generated page):\n## Example Usage ```hcl data \u0026#34;google_kms_key_ring\u0026#34; \u0026#34;my_key_ring\u0026#34; { name = \u0026#34;my-key-ring\u0026#34; location = \u0026#34;us-central1\u0026#34; } data \u0026#34;google_kms_crypto_key\u0026#34; \u0026#34;my_crypto_key\u0026#34; { name = \u0026#34;my-crypto-key\u0026#34; key_ring = data.google_kms_key_ring.my_key_ring.id } Argument reference # The argument reference section tells user about the fields in the schema which they can set via their Terraform configuration. The fields are listed using bullet points, and each field is marked with whether it is required or optional.\nFor example, this is the argument reference section from /website/docs/d/compute_backend_bucket.html.markdown:\n## Argument Reference The following arguments are supported: * `name` - (Required) Name of the resource. - - - * `project` - (Optional) The ID of the project in which the resource belongs. If it is not provided, the provider project is used. Nested blocks # If the data source contains a nested block we include the name of the nested block in the list of arguments and then link to a dedicated section below that describes all arguments within that block. If there are multiple levels of nesting in a block then this approach should be repeated.\nFor example in /website/docs/d/cloud_identity_group_membership.html.markdown the roles attribute is documented using this approach. To see it in action, view the attribute in the documentation.\nInside the list of arguments there is this entry, which contains a link to a target elsewhere on the page:\n* `roles` - The MembershipRoles that apply to the Membership. Structure is [documented below](#nested_roles). Under the list of arguments there are sections like this that contain an anchor tag that defines the target of the hyperlink above using the name attribute. These sections should be in the same order that the blocks\u0026rsquo; names are listed in the documentation.\n\u0026lt;a name=\u0026#34;nested_roles\u0026#34;\u0026gt;\u0026lt;/a\u0026gt;The `roles` block supports: * `name` - The name of the MembershipRole. One of OWNER, MANAGER, MEMBER. Attribute reference # Attributes are exported values that can be accessed from a data source (or resource) and are not set by the users Terraform configuration. They could be computed values, or values read from the API.\nIf the data source has the same attributes as its equivalent resource in the provider, you can just link to the documentation for the resource. This avoids duplicating information that already exists elsewhere.\nFor example the documentation for the google_storage_bucket data source links to the google_storage_bucket resource documentation (see here)\nIf there isn\u0026rsquo;t an equivalent resource in the provider, or the attributes are different, then document the attributes in a bulleted list as usual. Nested blocks are documented in the way previously described above.\n"},{"id":23,"href":"/magic-modules/develop/promote-to-ga/","title":"Promote to GA","section":"Develop","content":" Promote from beta to GA # This document describes how to promote an existing resource or field that uses MMv1 and/or handwritten code from the google-beta provider to the google (also known as \u0026ldquo;GA\u0026rdquo;) provider.\nHandwritten code (including custom_code) commonly uses \u0026ldquo;version guards\u0026rdquo; in the form of \u0026lt;% unless version == 'ga' -%\u0026gt;...\u0026lt;% end -%\u0026gt; to wrap code that is beta-specific, which need to be removed during promotion.\nFor more information about types of resources and the generation process overall, see How Magic Modules works.\nBefore you begin # Complete the Generate the providers quickstart to set up your environment and your Google Cloud project. Ensure that your magic-modules, terraform-provider-google, and terraform-provider-google-beta repositories are up to date. cd ~/magic-modules git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull Promote fields and resources # MMv1 Remove min_version: beta from the resource\u0026rsquo;s or field\u0026rsquo;s configuration in ResourceName.yaml. If necessary, remove version guards from resource-level custom_code. Add min_version: beta on any fields or subfields that should not be promoted. If necessary, add \u0026lt;% unless version == 'ga' -%\u0026gt;...\u0026lt;% end -%\u0026gt; version guards to resource-level custom_code that should not be promoted. Handwritten Remove version guards from the resource\u0026rsquo;s implementation for any functionality being promoted. Be sure to check: The overall resource (if the entire resource was beta-only) The resource schema For top-level fields, the resource\u0026rsquo;s Create, Update, and Read methods For other fields, expanders and flatteners Any other resource-specific code Add \u0026lt;% unless version == 'ga' -%\u0026gt;...\u0026lt;% end -%\u0026gt; version guards to any parts of the resource or field implementation that should not be promoted. Be sure to check: The resource schema For top-level fields, the resource\u0026rsquo;s Create, Update, and Read methods For other fields, expanders and flatteners Any other resource-specific code Promote tests # Remove min_version: beta from any examples in a ResourceName.yaml which only test fields and resources that are present in the google provider. Remove version guards from any handwritten code related to fields and resources that are present in the google provider. Remove provider = google-beta from any test configurations (from MMv1 examples or handwritten) which have been promoted. Ensure that there is at least one test that will run for the google provider that covers any promoted fields and resources. Promote documentation # For handwritten resources, modify the documentation as appropriate for your change:\nIf the entire resource has been promoted to google, remove the beta warning at the top of the documentation.\nRemove the Beta annotation for any fields that have been promoted.\nAdd Beta as an annotation on any fields or subfields that remained beta-only. For example:\n* `FIELD_NAME` - (Optional, [Beta](https://terraform.io/docs/providers/google/guides/provider_versions.html)) FIELD_DESCRIPTION Replace FIELD_NAME and FIELD_DESCRIPTION with the field\u0026rsquo;s name and description.\nWhat\u0026rsquo;s next? # Test your changes "}]