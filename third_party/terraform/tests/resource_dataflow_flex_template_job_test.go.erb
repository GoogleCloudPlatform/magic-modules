<% autogen_exception -%>
package google
<% unless version == 'ga' -%>

import (
	"fmt"
	"testing"

	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/resource"
)

func TestAccDataflowFlexTemplateJob_basic(t *testing.T) {
    // This resource uses custom retry logic that cannot be sped up without
    // modifying the actual resource
    skipIfVcr(t)
	t.Parallel()

	randStr := randString(t, 10)
	bucket := "tf-test-dataflow-gcs-" + randStr
	job := "tf-test-dataflow-job-" + randStr

	vcrTest(t, resource.TestCase{
		PreCheck:     func() { testAccPreCheck(t) },
		Providers:    testAccProviders,
		CheckDestroy: testAccCheckDataflowJobDestroyProducer(t),
		Steps: []resource.TestStep{
			{
				Config: testAccDataflowFlowFlexTemplateJob_basic(bucket, job),
				Check: resource.ComposeTestCheckFunc(
					testAccDataflowJobExists(t, "google_dataflow_flex_template_job.big_data"),
				),
			},
		},
	})
}

// note: this config creates a job that doesn't actually do anything
func testAccDataflowFlowFlexTemplateJob_basic(bucket, job string) string {
	return fmt.Sprintf(`
resource "google_storage_bucket" "temp" {
  name = "%s"
  force_destroy = true
}

resource "google_storage_bucket_object" "flex_template" {
	name   = "flex_template.json"
	bucket = google_storage_bucket.temp.name
	content = <<EOF
{
    "image": "my-image",
    "metadata": {
        "description": "An Apache Beam streaming pipeline that reads JSON encoded messages from Pub/Sub, uses Beam SQL to transform the message data, and writes the results to a BigQuery",
        "name": "Streaming Beam SQL",
        "parameters": [
            {
                "helpText": "Pub/Sub subscription to read from.",
                "label": "Pub/Sub input subscription.",
                "name": "inputSubscription",
                "regexes": [
                    "[-_.a-zA-Z0-9]+"
                ]
            },
            {
                "helpText": "BigQuery table spec to write to, in the form 'project:dataset.table'.",
                "is_optional": true,
                "label": "BigQuery output table",
                "name": "outputTable",
                "regexes": [
                    "[^:]+:[^.]+[.].+"
                ]
            }
        ]
    },
    "sdkInfo": {
        "language": "JAVA"
    }
}
EOF
}

resource "google_dataflow_flex_template_job" "big_data" {
  name = "%s"
  container_spec_gcs_path = "${google_storage_bucket.temp.url}/${google_storage_bucket_object.flex_template.name}"
  on_delete = "cancel"
  parameters = {
    inputSubscription = "my-subscription"
    outputTable  = "my-project:my-dataset.my-table"
  }
}
`, bucket, job)
}

<% end -%>
