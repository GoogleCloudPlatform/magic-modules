[{"id":0,"href":"/magic-modules/docs/how-to/types-of-resources/","title":"Types of resources","section":"How To","content":" Types of resources # MMv1 # MMv1 is a Ruby-based code generator that implements Terraform Provider Google (TPG) resources from YAML specification files.\nMMv1-generated resources like google_compute_address can be identified by looking in their Go source for an AUTO GENERATED CODE header as well as a Type MMv1. MMv1-generated resources should have source code present under their product folders, like mmv1/products/compute for the google_compute_address resource.\nHandwritten # Handwritten resources like google_container_cluster can be identified if they have source code present under the mmv1/third_party/terraform/resources folder or by the absence of the AUTO GENERATED CODE header in their Go source in the downstream repositories. Handwritten datasources should be under the mmv1/third_party/terraform/data_sources folder, tests under the mmv1/third_party/terraform/tests folder and web documentation under the mmv1/third_party/terraform/website folder.\nDCL aka tpgtools (maintenance mode) # DCL is a Go-based code generator that implements Terraform Provider Google (TPG) resources from YAML specification files.\nDCL-generated resources like google_bigquery_reservation_assignment can be identified by looking in their Go source for an AUTO GENERATED CODE header as well as a Type DCL.\nDCL is in maintenance mode, which means that new resources using the DCL are not being added.\n"},{"id":1,"href":"/magic-modules/docs/how-to/add-mmv1-resource/","title":"Add an MMv1 resource","section":"How To","content":" Add an MMv1 resource # Generated resources are created using the mmv1 code generator, and are configured by editing definition files under the mmv1/products path. Go to the service for your resource like compute and open the api.yaml and terraform.yaml files. In each of those, find the resource\u0026rsquo;s properties field.\nFor example, for google_spanner_database:\napi.yaml\nterraform.yaml\nIn short,properties is an array of the resource\u0026rsquo;s fields. api.yaml it contains the fields of the resource based on how it behaves in the API, and terraform.yaml contains Terraform-specific amendments to those fields' behaviour. Not all fields will need to be added to terraform.yaml- only add an entry for your field if you need to configure one of the available option(s).\nField Configuration # api.yaml # To add a field, you\u0026rsquo;ll append an entry to properties within api.yaml, such as the following adding support for a fooBar field in the API:\n- !ruby/object:Api::Type::String name: \u0026#39;fooBar\u0026#39; min_version: beta input: true description: | The cloud.google.com description of this field. The first line of that snippet is the type of the field in the API, including primitives like String, Integer, Boolean, Double. Additional special types are detailed below in \u0026ldquo;Complex Types\u0026rdquo;.\nYou can configure settings on the field that describe it in the API. Avoid setting values to false, and omit them instead.\ndescription is the cloud.google.com description of the field, and must be filled out manually. min_version can be set to beta if the field is only available at public preview or beta. If it is GA, do not set a min_version value. required: true indicates that a field is required. New top-level fields should not be considered required, as that is a breaking change. Subfields of newly-added optional fields can be added as required. input: true indicates that a field can only be set when the API resource is created. Changing the field will force the resource to be recreated. output: true indicates that a field is output-only in the API and cannot be configured by the user. default_value: {{value}} adds a default value for the field. This should only be used if the default value is fixed in the API. send_empty_value: true indicates that an explicit zero value should be sent to the API. This is useful when a value has a nonzero default in the API but the zero value for the type can be set. This is extremely common for booleans that default to true. update_verb and update_url configure a custom update function for a field.update_verbshould be set to a literal symbol for the type (such as :POST for POST) and the URL to a templated URL such asprojects/{{project}}/global/backendServices/{{name}}/setSecurityPolicy. terraform.yaml # You can add additional values within terraform.yaml:\nfoobar: !ruby/object:Overrides::Terraform::PropertyOverride ignore_read: true default_from_api: true custom_expand: \u0026#39;templates/terraform/custom_expand/shortname_to_url.go.erb\u0026#39; Commonly configured values include the following:\ndefault_from_api: true indicates that Terraform needs to handle a field specially. This is common for fields with complex defaults from the API that can\u0026rsquo;t be represented with default_value. If a default_from_api: true field is set in a user\u0026rsquo;s config, Terraform will treat it as an optional field, detecting drift and correcting drift. If it is not set, it will be treated as an output-only field. ignore_read: true indicates that a value is not returned from an API, and Terraform should not look for it in API responses. custom_expand and custom_flatten are custom functions to read/write a value from state. They refer to files holding function contents under mmv1/template/terraform/custom_expand and mmv1/template/terraform/custom_flatten respectively. Field Configuration - Complex Types # Enum # - !ruby/object:Api::Type::Enum name: \u0026#39;metadata\u0026#39; description: | Can only be specified if VPC flow logging for this subnetwork is enabled. Configures whether metadata fields should be added to the reported VPC flow logs. values: - :EXCLUDE_ALL_METADATA - :INCLUDE_ALL_METADATA - :CUSTOM_METADATA default_value: :INCLUDE_ALL_METADATA Enum values represent enums in the underlying API where it is valuable to restrict the range of inputs to a fixed set of values. They are strings that support a values key to define the array of possible values specified as literal constants, and default_value should be specified as a literal constant as well.\nMost API enums should be typed as String instead- if the value will not be fixed for \u0026gt;1 year, use a String.\nResourceRef # - !ruby/object:Api::Type::ResourceRef name: \u0026#39;urlMap\u0026#39; resource: \u0026#39;UrlMap\u0026#39; imports: \u0026#39;selfLink\u0026#39; description: | A reference to the UrlMap resource that defines the mapping from URL to the BackendService. ResourceRefs are fields that reference other resource. They\u0026rsquo;re most typical in GCE, and making a field a ResourceRef instead of a String will cause Terraform to allow switching between reference formats and versions safely. If a field can refer to multiple resource types, use a String instead.\nIn a ResourceRef, resource and imports must be defined but Terraform ignores those values. resource should be set to the resource kind, and imports to selfLink within GCE and name elsewhere.\nArray # - !ruby/object:Api::Type::Array name: scopes item_type: Api::Type::String description: | The list of scopes to be made available for this service account. - !ruby/object:Api::Type::Array name: \u0026#39;instances\u0026#39; description: | A list of virtual machine instances serving this pool. They must live in zones contained in the same region as this pool. item_type: !ruby/object:Api::Type::ResourceRef name: \u0026#39;instance\u0026#39; description: \u0026#39;The instance being served by this pool.\u0026#39; resource: \u0026#39;Instance\u0026#39; imports: \u0026#39;selfLink\u0026#39; Arrays refer to arrays in the underlying API, with their item being specified through an item_type field. item_type accepts any type, although primitives (String / Integer / Boolean) must be specified differently than other types as shown above.\nNestedObject # - !ruby/object:Api::Type::NestedObject name: \u0026#39;imageEncryptionKey\u0026#39; description: | Encrypts the image using a customer-supplied encryption key. After you encrypt an image with a customer-supplied key, you must provide the same key if you use the image later (e.g. to create a disk from the image) properties: - !ruby/object:Api::Type::String name: \u0026#39;rawKey\u0026#39; description: | Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648 base64 to either encrypt or decrypt this resource. - !ruby/object:Api::Type::String name: \u0026#39;sha256\u0026#39; output: true description: | The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption key that protects this resource. NestedObject is an object in the JSON API, and contains a properties subfield where a sub-properties array can be defined (including additional NestedObjects)\nKeyValuePairs (Labels / Annotations) # - !ruby/object:Api::Type::KeyValuePairs name: \u0026#39;labels\u0026#39; description: Labels to apply to this address. A list of key-\u0026gt;value pairs. KeyValuePairs is a special type to handle string -\u0026gt; string maps, such as GCE labels fields. No extra configuration is required.\nExactly One Of # To restrain a parent object to contain exactly one of its nested objects, use exactly_one_of in the affected child objects.\nYaml:\nobjects: - !ruby/object:Api::Resource name: \u0026#39;Connection\u0026#39; ... properties: - !ruby/object:Api::Type::NestedObject name: \u0026#39;cloudSql\u0026#39; exactly_one_of: - cloud_sql - aws properties: ... - !ruby/object:Api::Type::NestedObject name: aws exactly_one_of: - cloud_sql - aws properties: ... Advanced customization # DiffSuppressFunc # Terraform allows fields to specify a DiffSuppressFunc, which allows you to ignore diffs in cases where the two values are functionally identical. This is generally useful when the API returns a normalized value - for example by standardizing the case.\nNote: The preferred behavior for APIs is to always return the value that the user sent. DiffSuppressFunc is a workaround for APIs that don\u0026rsquo;t.\nThe Terraform provider comes with a set of \u0026ldquo;common diff suppress functions\u0026rdquo;. These fit frequent needs like ignoring whitespace at the beginning and end of a string, or ignoring case differences.\nIf you need to define a custom diff specifically for your resource, you can do so in a \u0026ldquo;constants\u0026rdquo; file, which is a .go.erb file in mmv1/templates/terraform/constants named \u0026lt;product\u0026gt;_\u0026lt;resource\u0026gt;.erb. You can then declare this custom code in terraform.yaml:\n--- !ruby/object:Provider::Terraform::Config overrides: !ruby/object:Overrides::ResourceOverrides ResourceName: # various overrides go here custom_code: !ruby/object:Provider::Terraform::CustomCode constants: templates/terraform/constants/product_resource_name.go.erb Once you have chosen a DiffSuppressFunc, you can declare it as an override on your resource:\n--- !ruby/object:Provider::Terraform::Config overrides: !ruby/object:Overrides::ResourceOverrides ResourceName: # various overrides go here properties: myField: !ruby/object:Overrides::Terraform::PropertyOverride diff_suppress_func: \u0026#39;caseDiffSuppress\u0026#39; The value of diff_suppress_func can be any valid DiffSuppressFunc, including the result of a function call. For example:\ndiff_suppress_func: \u0026#39;optionalPrefixSuppress(\u0026#34;folders/\u0026#34;)\u0026#39; Please make sure to add thorough unit tests (in addition to basic integration tests) for your diff suppress func.\nExample: DomainMapping (domainMappingLabelDiffSuppress)\nterraform.yaml resource overrides custom_code diff_suppress_func: 'resourceBigQueryDatasetAccessRoleDiffSuppress' constants file unit tests Beta features # When the underlying API of a feature is not final (i.e. a vN version like v1 or v2), is in preview, or the API has no SLO we add it to the google-beta provider rather than the google provider, allowing users to self-select for the stability level they are comfortable with.\nIn MMv1, a \u0026ldquo;version tag\u0026rdquo; can be annotated on resources, fields, resource iam metadata and examples to control the stability level that a feature is available at. Version tags are a specification of the minimum version a feature is available at, written as min_version: {{version}}. This is only specified when a feature is available at beta, and omitting a tag indicates the target is generally available, or available at ga.\nAdding a beta resource # To add support for a beta resource in a preexisting product, ensure that a beta level exists in the versions map in the api.yaml file for the product. If one doesn\u0026rsquo;t already exist, add it, setting the base_url to the appropriate value. This is generally an API version including beta, such as v1beta, but may be the same base_url as the ga entry for services that mix fields with different stability levels within a single endpoint.\nFor example:\nversions: - !ruby/object:Api::Product::Version name: ga base_url: https://compute.googleapis.com/compute/v1/ + - !ruby/object:Api::Product::Version + name: beta + base_url: https://compute.googleapis.com/compute/beta/ If the product doesn\u0026rsquo;t already exist, it\u0026rsquo;s only necessary to add the beta entry, i.e.:\nversions: - !ruby/object:Api::Product::Version name: beta base_url: https://runtimeconfig.googleapis.com/v1beta1/ Next, annotate the resource (part of resources in api.yaml) i.e.:\n- !ruby/object:Api::Resource name: \u0026#39;Config\u0026#39; base_url: projects/{{project}}/configs self_link: projects/{{project}}/configs/{{name}} + min_version: beta description: | A RuntimeConfig resource is the primary resource in the Cloud RuntimeConfig service. A RuntimeConfig resource consists of metadata and a hierarchy of variables. iam_policy: !ruby/object:Api::Resource::IamPolicy parent_resource_attribute: \u0026#39;config\u0026#39; method_name_separator: \u0026#39;:\u0026#39; exclude: false properties: ... You\u0026rsquo;ll notice above that the iam_policy is not annotated with a version tag. Due to the resource having a min_version tagged already, that\u0026rsquo;s passed through to the iam_policy (although the same is not true for examples entries used to create tests). IAM-level tagging is only necessary in the (rare) case that a resource is available at a higher stability level than its getIamPolicy/setIamPolicy methods.\nAdding beta field(s) # NOTE: If a resource is already tagged as min_version: beta, follow the general instructions for adding a field instead.\nTo add support for a beta field to a GA resource, ensure that the beta entry already exists in the versions map for the product. See above for details on doing so.\nNext, add the field(s) as normal with a min_version: beta tag specified. In the case of nested fields, only the highest-level field must be tagged, as demonstrated below:\n- !ruby/object:Api::Type::NestedObject name: \u0026#39;scaleDownControl\u0026#39; + min_version: beta description: | Defines scale down controls to reduce the risk of response latency and outages due to abrupt scale-in events properties: - !ruby/object:Api::Type::Integer name: \u0026#39;timeWindowSec\u0026#39; description: | How long back autoscaling should look when computing recommendations to include directives regarding slower scale down, as described above. ... Promote a beta feature # In order to promote a beta feature to GA, remove the version tags previously set on the feature or its tests. This will automatically make it available in the google provider and remove the note that the feature is in beta in the provider documentation.\nFor a resource, this typically means ensuring their removal:\nAt the resource level, resources in api.yaml On all resource examples, examples in terraform.yaml (unless some examples use other beta resources or fields) Additionally, for any modified examples, all provider = google-beta annotations must be cleared For a field, this typically means ensuring their removal:\nAt the field level, properties in api.yaml On any resource examples where this was the last beta feature, examples in terraform.yaml Additionally, for any modified examples, all provider = google-beta annotations must be cleared If the feature was tested using handwritten tests, the version guards must be removed, as described in the guidance for handwritten resources.\nWhen writing a changelog entry for a promotion, write it as if it was a new field or resource, and suffix it with (ga only). For example, if the google_container_cluster resource was promoted to GA in your change:\n\\`\\`\\`release-note:new-resource `google_container_cluster` (ga only) \\`\\`\\` Alternatively, for field promotions, you may use \u0026ldquo;{{service}}: promoted {{field}} in {{resource}} to GA\u0026rdquo;, i.e.\n\\`\\`\\`release-note:enhancement container: promoted `node_locations` field in google_container_cluster` to GA \\`\\`\\` "},{"id":2,"href":"/magic-modules/docs/getting-started/setup/","title":"Set up your environment","section":"Getting Started","content":" Set up your environment # Cloning Terraform providers # If you\u0026rsquo;re generating the Terraform providers (google and google-beta), you\u0026rsquo;ll need to check out the repo(s) you\u0026rsquo;re generating in your GOPATH. For example:\ngit clone https://github.com/hashicorp/terraform-provider-google.git $GOPATH/src/github.com/hashicorp/terraform-provider-google git clone https://github.com/hashicorp/terraform-provider-google-beta.git $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta Or run the following to check them all out:\n./tools/bootstrap Magic Modules won\u0026rsquo;t work with old versions of the Terraform provider repos. If you\u0026rsquo;re encountering issues with vendoring and paths, make sure both MM and the Terraform provider are running on up to date copies of main.\nSetting up a container-based environment # NOTE this approach is in beta and still collecting feedback. Please file an issue if you encounter challenges, and try pulling the latest container (see command below) first to see if any recent changes may fix you.\nYou do not need to run these instructions if you are setting up your environment manually.\nFor ease of contribution, we provide containers with the required dependencies for building magic-modules, as well as the option to build them yourself.\nYou can work with containers with either Podman or Docker.\nscripts/make-in-container.sh includes all the instructions to build and run containers by hand. Refer to the script for individual steps, but for most users you only have to run the script directly, as a replacement for make.\nHere is an example of how to build Terraform (after cloning the provider):\n./scripts/make-in-container.sh \\ terraform VERSION=ga \\ OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; Generally, you can replace any reference to make in this guide with scripts/make-in-container.sh.\nPreparing your environment manually # NOTE: you don\u0026rsquo;t need to run these instructions if you are using a container-based environment.\nYou can also build magic-modules within your local development environment.\nTo get started, you\u0026rsquo;ll need:\nGo If you\u0026rsquo;re using a Mac with Homebrew installed, you can follow these instructions to set up Go: YouTube video. If you\u0026rsquo;re using Cloud Shell, Go is already installed. Currently it\u0026rsquo;s recommended to use Go 1.18, Go 1.19 changed the gofmt rules which causes some gofmt issue and our CIs are all on 1.18.X Ruby 2.6.0 You can use rbenv to manage your Ruby version(s). To install rbenv: Homebrew: run brew install rbenv ruby-build Debian, Ubuntu, and their derivatives: run sudo apt install rbenv Then run rbenv install 2.6.0. For M1 Mac users, run RUBY_CFLAGS=\u0026quot;-Wno-error=implicit-function-declaration\u0026quot; rbenv install 2.6.0 Bundler This can be installed with gem install bundler Gems for magic-modules This can be installed with cd mmv1 \u0026amp;\u0026amp; bundler install Goimports go install golang.org/x/tools/cmd/goimports / go install golang.org/x/tools/cmd/goimports@latest Terraform Install Terraform If you are getting \u0026ldquo;Too many open files\u0026rdquo; ulimit needs to be raised. Mac OSX: ulimit -n 1000 Now, you can verify you\u0026rsquo;re ready with:\n./tools/doctor Check for rbenv in path... found! Checking ruby version... 2.6.0 (set by [PATH]/magic-modules/mmv1/.ruby-version) Check for bundler in path... found! Check for go in path... found! Check for goimports in path... found! Check for git in path... found! Test your setup # Try generating the providers. If your environment is set up correctly, it should succeed with no errors!\n"},{"id":3,"href":"/magic-modules/docs/how-to/add-mmv1-iam/","title":"Add MMv1 IAM resources","section":"How To","content":" Add MMv1 IAM resources # For resources implemented through the MMv1 engine, the majority of configuration for IAM support can be inferred based on the preexisting YAML specification file.\nTo add support for IAM resources based on an existing resource, add an iam_policy block to the resource\u0026rsquo;s definition in api.yaml, such as the following:\niam_policy: !ruby/object:Api::Resource::IamPolicy method_name_separator: \u0026#39;:\u0026#39; fetch_iam_policy_verb: :POST parent_resource_attribute: \u0026#39;registry\u0026#39; import_format: [\u0026#34;projects/{{project}}/locations/{{location}}/registries/{{name}}\u0026#34;, \u0026#34;{{name}}\u0026#34;] The specification values can be determined based on a mixture of the resource specification and the cloud.google.com setIamPolicy/getIamPolicy REST documentation, such as this page for Cloud IOT Registries.\nparent_resource_attribute - (Required) determines the field name of the parent resource reference in the IAM resources. Generally, this should be the singular form of the parent resource kind in snake case, i.e. registries -\u0026gt; registry or backendServices -\u0026gt; backend_service.\nmethod_name_separator - (Required) should be set to the character preceding setIamPolicy in the \u0026ldquo;HTTP Request\u0026rdquo; section on the resource\u0026rsquo;s setIamPolicy page. This is almost always : for APIs other than Google Compute Engine (GCE), MMv1\u0026rsquo;s compute product.\nfetch_iam_policy_verb - (Required) should be set to the HTTP verb listed in the \u0026ldquo;HTTP Request\u0026rdquo; section on the resource\u0026rsquo;s getIamPolicy page. This is generally POST but is occasionally GET. Note: This is specified as a Ruby symbol, prefixed with a :. For example, for GET, you would specify :GET.\nimport_format - (Optional) A list of templated strings used to determine the Terraform import format. If the resource has a custom import_format or id_format defined in terraform.yaml, this must be supplied.\nIf an import_format is set on the parent resource use that set of values exactly, substituting parent_resource_attribute for the field name of the final templated value. If an id_format is set on the parent resource use that as the first entry (substituting the final templated value, as with import_format) and define a second format with only the templated values, /-separated. For example, projects/{{project}}/locations/{{region}}/myResources/{{name}} -\u0026gt; [\u0026quot;projects/{{project}}/locations/{{region}}/myResources/{{myResource}}\u0026quot;, \u0026quot;{{project}}/{{region}}/{{myResource}}\u0026quot;]. Optionally, you may provide a version of the shortened format that excludes entries called {{project}}, {{region}}, and {{zone}}. For example, given {{project}}/{{region}}/{{myResource}}/{{entry}}, {{myResource}}/{{entry}} is a valid format. When a user specifies this format, the provider\u0026rsquo;s default values for project/region/zone will be used. allowed_iam_role - (Optional) If the resource does not allow the roles/viewer IAM role to be set, an alternate, valid role must be provided.\niam_conditions_request_type - (Optional) The method the IAM policy version is set in getIamPolicy. If unset, IAM conditions are assumed to not be supported for the resource. One of QUERY_PARAM, QUERY_PARAM_NESTED or REQUEST_BODY. For resources where a query parameter is expected, QUERY_PARAM should be used if the key is optionsRequestedPolicyVersion, while QUERY_PARAM_NESTED should be used if it is options.requestedPolicyVersion.\nmin_version - (Optional) If the resource or IAM method is not generally available, this should be set to beta or alpha as appropriate.\nset_iam_policy_verb - (Optional, rare) Similar to fetch_iam_policy_verb, the HTTP verb expected by setIamPolicy. Defaults to :POST, and should only be specified if it differs (typically if :PUT is expected).\nSeveral single-user settings are not documented on this page as they are not expected to recur often. If you are unable to configure your API successfully, you may want to consult https://github.com/GoogleCloudPlatform/magic-modules/blob/main/mmv1/api/resource/iam_policy.rb for additional configuration options.\nAdditionally, in order to generate IAM tests based on a preexisting resource configuration, the first examples entry in terraform.yaml must be modified to include a primary_resource_name entry:\n- !ruby/object:Provider::Terraform::Examples name: \u0026#34;disk_basic\u0026#34; primary_resource_id: \u0026#34;default\u0026#34; + primary_resource_name: \u0026#34;fmt.Sprintf(\\\u0026#34;tf-test-test-disk%s\\\u0026#34;, context[\\\u0026#34;random_suffix\\\u0026#34;])\u0026#34; vars: disk_name: \u0026#34;test-disk\u0026#34; primary_resource_name - Typically \u0026quot;fmt.Sprintf(\\\u0026quot;tf-test-{{shortname}}%s\\\u0026quot;, context[\\\u0026quot;random_suffix\\\u0026quot;])\u0026quot;, substituting the parent resource\u0026rsquo;s shortname from the example configuration for {{shortname}}, such as test-disk above. This value is variable, as both the key and value are user-defined parts of the example configuration. In some cases the value must be customized further, albeit rarely.\nOnce an iam_policy block is added and filled out, and primary_resource_name is set on the first example, you\u0026rsquo;re finished, and you can run MMv1 to generate the IAM resources you\u0026rsquo;ve added, alongside documentation, and tests.\nAdding IAM support to nonexistent resources # Some IAM targets don\u0026rsquo;t exist as distinct resources, such as IAP, or their target is supported through an engine other than MMv1 (i.e. through tpgtools/DCL or a handwritten resource). For these resources, the exclude_resource: true annotation can be used. To use it, partially define the resource in the product\u0026rsquo;s api.yaml file and apply the annotation. MMv1 won\u0026rsquo;t attempt to generate the resource itself and will only generate IAM resources targeting it.\nThe IAP product is a good reference for adding these: https://github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/products/iap\n"},{"id":4,"href":"/magic-modules/docs/how-to/add-mmv1-test/","title":"Add an MMv1 test","section":"How To","content":" Add an MMv1 test # For generated resources, you can add an example to the mmv1/templates/terraform/examples directory, which contains a set of templated Terraform configurations.\nAfter writing out the example and filling out some metadata, Magic Modules will insert it into the resource documentation page, and generate a test case stepping through the following stages:\nRun terraform apply on the configuration, waiting for it to succeed and recording the results in Terraform state Run terraform plan, and fail if Terraform detects any drift Clear the resource from state and run terraform import on it Deeply compare the original state from terraform apply and the terraform import results, returning an error if any values are not identical Destroy all resources in the configuration using terraform destroy, waiting for the destroy command to succeed Call GET on the resource, and fail the test if it is still present Example Configuration File # First, you\u0026rsquo;ll want to add the example file. It needs to end in the filename .tf.erb, and is typically named service_resource_descriptive_name. For example, pubsub_topic_geo_restricted.tf.erb. Inside, you\u0026rsquo;ll write a complete Terraform configuration that provisions the resource and all of the required dependencies. For example, in mmv1/templates/terraform/examples/pubsub_subscription_dead_letter.tf.erb:\nresource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;\u0026#34; { name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;topic_name\u0026#39;] %\u0026gt;\u0026#34; } resource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;_dead_letter\u0026#34; { name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;topic_name\u0026#39;] %\u0026gt;-dead-letter\u0026#34; } resource \u0026#34;google_pubsub_subscription\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;\u0026#34; { name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;subscription_name\u0026#39;] %\u0026gt;\u0026#34; topic = google_pubsub_topic.\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;.name dead_letter_policy { dead_letter_topic = google_pubsub_topic.\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;_dead_letter.id max_delivery_attempts = 10 } } The ctx variable provides metadata at generation time, and should be used in two ways:\nThe Terraform ID of a single instance of the primary resource should be supplied through \u0026lt;%= ctx[:primary_resource_id] %\u0026gt; (in this example multiple resources use the value, although only the first google_pubsub_topic requires it). The resource kind you are testing with an id equal to \u0026lt;%= ctx[:primary_resource_id] %\u0026gt; is the one that will be imported. Unique values can be supplied through \u0026lt;%= ctx[:vars]['{{var}}'] %\u0026gt;, where {{var}} is an arbitrary key you define. These values are created by appending suffixes to them, and are typically only used for names- most values should be constant within the configuration. terraform.yaml metadata # Once your configuration is written, go in terraform.yaml and find the examples block for the resource. Generally it\u0026rsquo;ll be above the properties block. In there, append an entry such as the following:\n- !ruby/object:Provider::Terraform::Examples name: \u0026#34;pubsub_subscription_dead_letter\u0026#34; primary_resource_id: \u0026#34;example\u0026#34; vars: topic_name: \u0026#34;example-topic\u0026#34; subscription_name: \u0026#34;example-subscription\u0026#34; The name should match the base name of your example file, primary_resource_id is an arbitrary snake_cased string that describes the resource, and the vars map should contain each key you defined previously.\nImportant: Any vars that are part of the resource\u0026rsquo;s id should include at least one hyphen or underscore; this triggers addition of a tf-test or tf_test prefix, which is what we use to detect and delete stray resources that are sometimes left over during test runs.\nResults # Your configuration will ultimately generate a Go test case similar to the following based on the snippets above:\nfunc TestAccPubsubSubscription_pubsubSubscriptionDeadLetterExample(t *testing.T) { t.Parallel() context := map[string]interface{}{ \u0026#34;random_suffix\u0026#34;: randString(t, 10), } vcrTest(t, resource.TestCase{ PreCheck: func() { testAccPreCheck(t) }, Providers: testAccProviders, CheckDestroy: testAccCheckPubsubSubscriptionDestroyProducer(t), Steps: []resource.TestStep{ { Config: testAccPubsubSubscription_pubsubSubscriptionDeadLetterExample(context), }, { ResourceName: \u0026#34;google_pubsub_subscription.example\u0026#34;, ImportState: true, ImportStateVerify: true, ImportStateVerifyIgnore: []string{\u0026#34;topic\u0026#34;}, }, }, }) } func testAccPubsubSubscription_pubsubSubscriptionDeadLetterExample(context map[string]interface{}) string { return Nprintf(` resource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;example\u0026#34; { name = \u0026#34;tf-test-example-topic%{random_suffix}\u0026#34; } resource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;example_dead_letter\u0026#34; { name = \u0026#34;tf-test-example-topic%{random_suffix}-dead-letter\u0026#34; } resource \u0026#34;google_pubsub_subscription\u0026#34; \u0026#34;example\u0026#34; { name = \u0026#34;tf-test-example-subscription%{random_suffix}\u0026#34; topic = google_pubsub_topic.example.name dead_letter_policy { dead_letter_topic = google_pubsub_topic.example_dead_letter.id max_delivery_attempts = 10 } } `, context) } Update tests # Update tests can only be added as handwritten tests.\nTests that use beta features # For tests that use beta features, you\u0026rsquo;ll need to perform two additional steps:\nAdd provider = google-beta to every resource in the test (even resources that aren\u0026rsquo;t being tested and/or are also in the GA provider) Add min_version: beta to the Provider::Terraform::Examples block For example, modifying the snippets above:\nresource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;\u0026#34; { provider = google-beta name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;topic_name\u0026#39;] %\u0026gt;\u0026#34; } resource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;_dead_letter\u0026#34; { provider = google-beta name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;topic_name\u0026#39;] %\u0026gt;-dead-letter\u0026#34; } resource \u0026#34;google_pubsub_subscription\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;\u0026#34; { provider = google-beta name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;subscription_name\u0026#39;] %\u0026gt;\u0026#34; topic = google_pubsub_topic.\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;.name dead_letter_policy { dead_letter_topic = google_pubsub_topic.\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;_dead_letter.id max_delivery_attempts = 10 } } - !ruby/object:Provider::Terraform::Examples name: \u0026#34;pubsub_subscription_dead_letter\u0026#34; min_version: beta primary_resource_id: \u0026#34;example\u0026#34; vars: topic_name: \u0026#34;example-topic\u0026#34; subscription_name: \u0026#34;example-subscription\u0026#34; "},{"id":5,"href":"/magic-modules/docs/getting-started/generate-providers/","title":"Generate the providers","section":"Getting Started","content":" Generate the providers # You can compile the Terraform provider you\u0026rsquo;re working on by running the following commands from the root directory of the repository. OUTPUT_PATH should be set to the location of your provider repository, which is recommended to be inside your GOPATH.\ncd magic-modules make terraform VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; make terraform VERSION=beta OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google-beta\u0026#34; # Only generate a specific product (plus all common files) make terraform VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; PRODUCT=pubsub # Only generate only a specific resources for a product make terraform VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; PRODUCT=pubsub RESOURCE=Topic The PRODUCT variable values correspond to folder names in mmv1/products for generated resources. The RESOURCE variable value needs to match the name of the resource inside the api.yaml file for that product.\nHandwritten files in mmv1/third_party are always compiled. If you are only working on common files or third_party code, you can pass a non-existent PRODUCT to reduce the generation time.\n# Only generate common files, including all third_party code make terraform VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; PRODUCT=foo Cleaning up old files # Magic Modules will only generate on top of whatever is in the downstream repository. This means that, from time to time, you may end up with stale files or changes in your downstream that cause compilation or tests to fail.\nYou can clean up by running the following commands in your downstream repository:\ngit checkout -- . git clean -f google/ google-beta/ website/ "},{"id":6,"href":"/magic-modules/docs/how-to/","title":"How To","section":"Docs","content":" How To # Types of resources Check the header in the Go source to determine what type of resource it is. If there is no header, it is likely handwritten. Add an MMv1 resource Generated resources are created using the mmv1 code generator, and are configured by editing definition files under the mmv1/products path. Add MMv1 IAM resources For resources implemented through the MMv1 engine, the majority of configuration for IAM support can be inferred based on the preexisting YAML specification file. Add an MMv1 test An example terraform configuration can be used to generate docs and tests for a resource. Update a handwritten resource The Google providers for Terraform have a large number of handwritten go files, primarily for resources written before Magic Modules was used with them. Most handwritten files are expected to stay handwritten indefinitely, although conversion to a generator may be possible for a limited subset of them. Add a handwritten test For handwritten resources and generated resources that need to test update, handwritten tests must be added. Add a handwritten datasource Datasources are like terraform resources except they don\u0026rsquo;t create anything. Add handwritten IAM resources Handwritten IAM support is only recommended for resources that cannot be managed using MMv1. "},{"id":7,"href":"/magic-modules/docs/how-to/update-handwritten-resource/","title":"Update a handwritten resource","section":"How To","content":" Update a handwritten resource # The Google providers for Terraform have a large number of handwritten go files, primarily for resources written before Magic Modules was used with them. Most handwritten files are expected to stay handwritten indefinitely, although conversion to a generator may be possible for a limited subset of them.\nWe no longer accept new handwritten resources except in rare cases. However, understanding how to edit and add to existing resources may be important for implementing new fields or changing existing behavior.\nTo edit an existing resource to add a field there are four steps you\u0026rsquo;ll go through.\nAdd the new field to the schema Implement the respective flattener and/or expander for the new field Add a testcase for the field or extend an existing one Add documentation for the field to the respective markdown file Shared concepts # This section will serve as a point of reference for some shared concepts that all handwritten files share. It\u0026rsquo;s meant to be an introduction to our serialization strategy and overview.\nSerialization strategy # The go files within the directory files are copied literally to their respective providers. Our serialization methodology may seem complicated but for the case of handwritten resources its quite simple. Editing the file will change its counterpart downstream.\ngo and go.erb # Within the third party library you\u0026rsquo;ll notice go and go.erb files. Go files are native golang code while go.erb pass through ruby before being serialized. The reason go.erb files exist are to protect certain properties or fields from entering the ga provider. Thus you\u0026rsquo;ll often see lines like \u0026lt;% unless version == 'ga' -%\u0026gt; within the file. These blocks will omit the enclosure from being output to the GA provider. In the rare case where you are promoting all fields to ga and these blocks are no longer needed you can remove the .erb extension.\nCreate, Read, Update, Delete # As far as terraform schema is concerned these are the functions we need to provide for terraform to be able to provision and delete resources. In editing any fields you\u0026rsquo;ll likely be adding functionality to these functions or implementing them wholesale.\nExpanders and Flatteners # Expanders and flatteners are concepts created to simplify common patterns and add conformity/code consistency. Essentially expanders are functions used to segregate some translation from terraform representation to api representation. We will use these to encapsulate this translation for blocks and/or complicated fields. This allows our code to be concise and functionality to be readable and easily apparent by separating these into their own functions. While expanders are used for terraform to api, flatteners do just the opposite. Converting api to terraform.\nThus\nexpanders - helper functions used for translating tf -\u0026gt; api representation flatteners - helper functions used for translating api -\u0026gt; tf representation Adding a new field to the schema # To add a new field you will have to compare an existing resource to it\u0026rsquo;s respective rest api documentation. Dependant on how the api implements the field we will in almost all cases mirror the structure. For example if there is an enabled field nested under a IdentityServiceConfig block we will mirror this within the schema.\nThus the block for terraform to utilize this field would then be\nresource \u0026#34;x\u0026#34; \u0026#34;y\u0026#34; { identity_service_config{ enabled = true } } You might think it convoluted to provide such a structure. Why not simply provide a single enable_identity_service_config. One constant has echoed through our mind as terraform developers through the years. Api\u0026rsquo;s are ever evolving. Mirroring the api gives us the best chance to stay in step with that evolution. Therefore if IdentityServiceConfig is extended with new parameters in the future we can cleanly encapsulate those into the existing block(s).\nAs far as providing the field itself, it\u0026rsquo;s fairly straightforward. Mirror the field from the api and look to the other fields and the schema type in the SDK to see what\u0026rsquo;s available and how to structure it. For the documentation, copying the documentation from the rest api will be the usual practice.\nIf you are adding a field that is an ENUM from the api standpoint its best practice to provide it as as a string to the provider. This field will likely have values added to it by the api and this future proofs our provider to support new values without haven\u0026rsquo;t to make new additions. There will be rare exceptions, but generally its a good practice.\nImplement the respective flattener and/or expander for the new field # Once you\u0026rsquo;ve added the field to the schema you will implement the corresponding expander/flattener. See expanders and flatters for more context on what these fields are used for. Essentially we will be editing the read, create, and update operations to parse the schema and call the api to make the changes to the state of the resource. Following existing patterns to create this operation will be the best way to implement this. As there are many unique ways to implement a given field we won\u0026rsquo;t get into specifics.\nFor example a field in bigtable google_sheets_options containers two nested properties. range and skip_leading_rows.\n// GoogleSheetsOptions: [Optional] Additional options if sourceFormat is set to GOOGLE_SHEETS. \u0026#34;google_sheets_options\u0026#34;: { Type: schema.TypeList, Optional: true, MaxItems: 1, Description: `Additional options if source_format is set to \u0026#34;GOOGLE_SHEETS\u0026#34;.`, Elem: \u0026amp;schema.Resource{ Schema: map[string]*schema.Schema{ // Range: [Optional] Range of a sheet to query from. Only used when non-empty. // Typical format: !: \u0026#34;range\u0026#34;: { Type: schema.TypeString, Optional: true, Description: `Range of a sheet to query from. Only used when non-empty. At least one of range or skip_leading_rows must be set. Typical format: \u0026#34;sheet_name!top_left_cell_id:bottom_right_cell_id\u0026#34; For example: \u0026#34;sheet1!A1:B20\u0026#34;`, AtLeastOneOf: []string{ \u0026#34;external_data_configuration.0.google_sheets_options.0.skip_leading_rows\u0026#34;, \u0026#34;external_data_configuration.0.google_sheets_options.0.range\u0026#34;, }, }, // SkipLeadingRows: [Optional] The number of rows at the top // of the sheet that BigQuery will skip when reading the data. \u0026#34;skip_leading_rows\u0026#34;: { Type: schema.TypeInt, Optional: true, Description: `The number of rows at the top of the sheet that BigQuery will skip when reading the data. At least one of range or skip_leading_rows must be set.`, AtLeastOneOf: []string{ \u0026#34;external_data_configuration.0.google_sheets_options.0.skip_leading_rows\u0026#34;, \u0026#34;external_data_configuration.0.google_sheets_options.0.range\u0026#34;, }, }, }, }, }, To simplify the implementation management of these fields can be delegated to expanders and flatteners.\nfunc expandGoogleSheetsOptions(configured interface{}) *bigquery.GoogleSheetsOptions { if len(configured.([]interface{})) == 0 { return nil } raw := configured.([]interface{})[0].(map[string]interface{}) opts := \u0026amp;bigquery.GoogleSheetsOptions{} if v, ok := raw[\u0026#34;range\u0026#34;]; ok { opts.Range = v.(string) } if v, ok := raw[\u0026#34;skip_leading_rows\u0026#34;]; ok { opts.SkipLeadingRows = int64(v.(int)) } return opts } func flattenGoogleSheetsOptions(opts *bigquery.GoogleSheetsOptions) []map[string]interface{} { result := map[string]interface{}{} if opts.Range != \u0026#34;\u0026#34; { result[\u0026#34;range\u0026#34;] = opts.Range } if opts.SkipLeadingRows != 0 { result[\u0026#34;skip_leading_rows\u0026#34;] = opts.SkipLeadingRows } return []map[string]interface{}{result} } Add a testcase for the field or extend an existing one # Once your field has been implemented, go to the corresponding test file for your resource and extend it. If your field is updatable it\u0026rsquo;s good practice to have a two step apply to ensure that the field can be updated. You\u0026rsquo;ll notice a lot of our tests have a import state verify directly after apply. These steps are important as they will essentially attempt to import the resource you just provisioned and verify that the field values are consistent with the applied state. Please test all fields you\u0026rsquo;ve added to the provider. It\u0026rsquo;s important for us to ensure all fields are usable and workable.\nAdd documentation for the field to the respective markdown file # See Documentation for more information. Essentially you will just be opening the corresponding markdown file and adding documentation, likely copied from the rest api to the markdown file. Follow the existing patterns there-in.\nBeta features # When the underlying API of a feature is not final (i.e. a vN version like v1 or v2), is in preview, or the API has no SLO we add it to the google-beta provider rather than the google provider, allowing users to self-select for the stability level they are comfortable with.\nBoth the google and google-beta providers operate off of a shared codebase, including for handwritten code. MMv1 allows us to write Go source files as .go.erb templated source, and renders them as .go files in the downstream repo.\nThe sole generator feature you need to be aware of is a \u0026ldquo;version guard\u0026rdquo;, what is effectively a preprocessor directive implemented using Embedded Ruby (ERB). A version guard is a snippet used across this codebase by convention guarding versioned code on an unless clause in a version check. For example:\nnetworkInterfaces, err := expandNetworkInterfaces(d, config) if err != nil { return nil, fmt.Errorf(\u0026#34;Error creating network interfaces: %s\u0026#34;, err) } \u0026lt;% unless version == \u0026#39;ga\u0026#39; -%\u0026gt; networkPerformanceConfig, err := expandNetworkPerformanceConfig(d, config) if err != nil { return nil, fmt.Errorf(\u0026#34;Error creating network performance config: %s\u0026#34;, err) } \u0026lt;% end -%\u0026gt; In the snippet above, the networkInterfaces field is generally available and is not guarded. The networkPerformanceConfig field is only available at beta, and is guarded by unless version == ga, and the guarded block is terminated by an end statement.\nIf a service includes handwritten resources and mixed features or resources at different versions, the client libraries used by each provider must be switched using guards so that the stability level of the client library matches that of the provider. For example, all handwritten Google Compute Engine (GCE) files have the following guarded import:\n\u0026lt;% if version == \u0026#34;ga\u0026#34; -%\u0026gt; \u0026#34;google.golang.org/api/compute/v1\u0026#34; \u0026lt;% else -%\u0026gt; compute \u0026#34;google.golang.org/api/compute/v0.beta\u0026#34; \u0026lt;% end -%\u0026gt; This is not necessary for beta-only services, or for services that are generally available in their entirety.\nAdding a beta resource # MMv1 doesn\u0026rsquo;t selectively generate files, and any file that is beta-only must have all of its contents guarded. When writing a resource that\u0026rsquo;s available at beta, start with the following snippet:\n\u0026lt;% autogen_exception -%\u0026gt; package google \u0026lt;% unless version == \u0026#39;ga\u0026#39; -%\u0026gt; // Add the implementation of the file here \u0026lt;% end -\u0026gt; This will generate a blank file in the google provider. The resource file, resource test file, and any service or resource specific utility files should be guarded in this way.\nDocumentation should not be guarded. Instead, write it as normal including the following snippet above the first example.\n~\u0026gt; **Warning:** This resource is in beta, and should be used with the terraform-provider-google-beta provider. See [Provider Versions](https://terraform.io/docs/providers/google/guides/provider_versions.html) for more details on beta resources. When registering the resource in provider.go.erb, the entry should be guarded:\n\u0026#34;google_monitoring_dashboard\u0026#34;: resourceMonitoringDashboard(), +\t\u0026lt;% unless version == \u0026#39;ga\u0026#39; -%\u0026gt; +\t\u0026#34;google_project_service_identity\u0026#34;: resourceProjectServiceIdentity(), +\t\u0026lt;% end -%\u0026gt; \u0026#34;google_service_networking_connection\u0026#34;: resourceServiceNetworkingConnection(), If this is a new service entirely, all service-specific entries like client factory initialization should be guarded as well. However, new services should generally be implemented using an alternate engine- either MMv1 or tpgtools/DCL.\nAdding beta field(s) # By contrast to beta resources, adding support for a beta field is much more involved as small snippets of code throughout a resource file must be annotated.\nTo begin with, add the field to the Schema of the resource with guards, i.e.:\n\u0026lt;% unless version == \u0026#39;ga\u0026#39; -%\u0026gt; \u0026#34;network_performance_config\u0026#34;: { Type: schema.TypeList, MaxItems: 1, Optional: true, ForceNew: true, Description: `Configures network performance settings for the instance. If not specified, the instance will be created with its default network performance configuration.`, Elem: \u0026amp;schema.Resource{ Schema: map[string]*schema.Schema{ \u0026#34;total_egress_bandwidth_tier\u0026#34;: { // ... }, }, }, }, \u0026lt;% end -%\u0026gt; Next, implement the d.Get/d.Set calls (for top level fields) or expanders/flatteners for nested fields within guards.\nEven if there are other guarded fields, it\u0026rsquo;s recommended that you add distinct guards per feature- that way, promotion (covered below) will be simpler as you\u0026rsquo;ll only need to remove lines rather that move them around.\nPromoting a beta feature # \u0026ldquo;Promoting\u0026rdquo; a beta feature- making it available in the GA google provider when the underlying feature or service has gone GA- requires removing the version guards placed previously, so that the previously beta-only code is generated in the google provider as well.\nFor all promotions, ensure that you remove the guards in:\nThe documentation for the resource or field The test(s) for the resource or field. For whole resource promotions, you\u0026rsquo;ll generally only need to remove the file-level guards and the guards on the resource registration in provider.go.erb.\nFor field promotions ensure that you remove the guards in:\nThe Resource schema The Resource CRUD methods (for top level fields) The Resource Expanders and Flatteners (for nested fields) When writing a changelog entry for a promotion, write it as if it was a new field or resource, and suffix it with (ga only). For example, if the google_container_cluster resource was promoted to GA in your change:\n\\`\\`\\`release-note:new-resource `google_container_cluster` (ga only) \\`\\`\\` Alternatively, for field promotions, you may use \u0026ldquo;{{service}}: promoted {{field}} in {{resource}} to GA\u0026rdquo;, i.e.\n\\`\\`\\`release-note:enhancement container: promoted `node_locations` field in google_container_cluster` to GA \\`\\`\\` "},{"id":8,"href":"/magic-modules/docs/how-to/add-handwritten-test/","title":"Add a handwritten test","section":"How To","content":" Add a handwritten test # For handwritten resources and generated resources that need to test update, handwritten tests must be added.\nTests are made up of a templated Terraform configuration where unique values like GCE names are passed in as arguments, and boilerplate to exercise that configuration.\nThe test boilerplate effectively does the following:\nRun terraform apply on the configuration, waiting for it to succeed and recording the results in Terraform state Run terraform plan, and fail if Terraform detects any drift Clear the resource from state and run terraform import on it Deeply compare the original state from terraform apply and the terraform import results, returning an error if any values are not identical Destroy all resources in the configuration using terraform destroy, waiting for the destroy command to succeed Call GET on the resource, and fail the test if it is still present Simple Tests # Terraform configurations are stored as string constants wrapped in Go functions like the following:\nfunc testAccComputeFirewall_basic(network, firewall string) string { return fmt.Sprintf(` resource \u0026#34;google_compute_network\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; auto_create_subnetworks = false } resource \u0026#34;google_compute_firewall\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; description = \u0026#34;Resource created for Terraform acceptance testing\u0026#34; network = google_compute_network.foobar.name source_tags = [\u0026#34;foo\u0026#34;] allow { protocol = \u0026#34;icmp\u0026#34; } } `, network, firewall) } For the most part, you can copy and paste a preexisting test case and modify it. For example, the following test case is a good reference:\nfunc TestAccComputeFirewall_noSource(t *testing.T) { t.Parallel() networkName := fmt.Sprintf(\u0026#34;tf-test-firewall-%s\u0026#34;, randString(t, 10)) firewallName := fmt.Sprintf(\u0026#34;tf-test-firewall-%s\u0026#34;, randString(t, 10)) vcrTest(t, resource.TestCase{ PreCheck: func() { testAccPreCheck(t) }, Providers: testAccProviders, CheckDestroy: testAccCheckComputeFirewallDestroyProducer(t), Steps: []resource.TestStep{ { Config: testAccComputeFirewall_noSource(networkName, firewallName), }, { ResourceName: \u0026#34;google_compute_firewall.foobar\u0026#34;, ImportState: true, ImportStateVerify: true, }, }, }) } func testAccComputeFirewall_noSource(network, firewall string) string { return fmt.Sprintf(` resource \u0026#34;google_compute_network\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; auto_create_subnetworks = false } resource \u0026#34;google_compute_firewall\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; description = \u0026#34;Resource created for Terraform acceptance testing\u0026#34; network = google_compute_network.foobar.name allow { protocol = \u0026#34;tcp\u0026#34; ports = [22] } } `, network, firewall) } Update tests # Inside of a test, additional steps can be added in order to transition between Terraform configurations, updating the stored state as it progresses. This allows you to exercise update behaviour. This modifies the flow from before:\nStart with an empty Terraform state For each Config and ImportState pair: Run terraform apply on the configuration, waiting for it to succeed and recording the results in Terraform state Run terraform plan, and fail if Terraform detects any drift Clear the resource from state and run terraform import on it Deeply compare the original state from terraform apply and the terraform import results, returning an error if any values are not identical Destroy all resources in the configuration using terraform destroy, waiting for the destroy command to succeed Call GET on the resource, and fail the test if it is still present For example:\nfunc TestAccComputeFirewall_disabled(t *testing.T) { t.Parallel() networkName := fmt.Sprintf(\u0026#34;tf-test-firewall-%s\u0026#34;, randString(t, 10)) firewallName := fmt.Sprintf(\u0026#34;tf-test-firewall-%s\u0026#34;, randString(t, 10)) vcrTest(t, resource.TestCase{ PreCheck: func() { testAccPreCheck(t) }, Providers: testAccProviders, CheckDestroy: testAccCheckComputeFirewallDestroyProducer(t), Steps: []resource.TestStep{ { Config: testAccComputeFirewall_disabled(networkName, firewallName), }, { ResourceName: \u0026#34;google_compute_firewall.foobar\u0026#34;, ImportState: true, ImportStateVerify: true, }, { Config: testAccComputeFirewall_basic(networkName, firewallName), }, { ResourceName: \u0026#34;google_compute_firewall.foobar\u0026#34;, ImportState: true, ImportStateVerify: true, }, }, }) } func testAccComputeFirewall_basic(network, firewall string) string { return fmt.Sprintf(` resource \u0026#34;google_compute_network\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; auto_create_subnetworks = false } resource \u0026#34;google_compute_firewall\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; description = \u0026#34;Resource created for Terraform acceptance testing\u0026#34; network = google_compute_network.foobar.name source_tags = [\u0026#34;foo\u0026#34;] allow { protocol = \u0026#34;icmp\u0026#34; } } `, network, firewall) } func testAccComputeFirewall_disabled(network, firewall string) string { return fmt.Sprintf(` resource \u0026#34;google_compute_network\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; auto_create_subnetworks = false } resource \u0026#34;google_compute_firewall\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; description = \u0026#34;Resource created for Terraform acceptance testing\u0026#34; network = google_compute_network.foobar.name source_tags = [\u0026#34;foo\u0026#34;] allow { protocol = \u0026#34;icmp\u0026#34; } disabled = true } `, network, firewall) } Testing Beta Features # If you worked with a beta feature and had to use beta version guards in a handwritten resource or set min_version: beta in a generated resource, you\u0026rsquo;ll want to version guard both the test case and configuration by enclosing them in ERB tags like below. Additionally, if the filename ends in .go, rename it to end in .go.erb.\n\u0026lt;% unless version == \u0026#39;ga\u0026#39; -%\u0026gt; // test case + config here \u0026lt;% end -%\u0026gt; Otherwise, tests using a beta feature are written exactly the same as tests using a GA one. Normally to use the beta provider, it\u0026rsquo;s necessary to specify provider = google-beta, as Terraform maps any resources prefixed with google_ to the google provider by default. However, inside the test framework, the google-beta provider has been aliased as the google provider and that is not necessary.\nNote: You may use version guards to test different configurations between the GA and beta provider tests, but it\u0026rsquo;s strongly recommended that you write different test cases instead, even if they\u0026rsquo;re slightly duplicative.\n"},{"id":9,"href":"/magic-modules/docs/how-to/add-handwritten-datasource/","title":"Add a handwritten datasource","section":"How To","content":" Add a handwritten datasource # Note: only handwritten datasources are currently supported\nDatasources are like terraform resources except they don\u0026rsquo;t create anything. They are simply read-only operations that will expose some sort of values needed for subsequent resource operations. If you\u0026rsquo;re adding a field to an existing datasource, check the Resource section. Everything there will be mostly consistent with the type of change you\u0026rsquo;ll need to make. For adding a new datasource there are 5 steps to doing so.\nCreate a new datasource declaration file and a corresponding test file Add Schema and Read operation implementation Add the datasource to the provider.go.erb index Implement a test which will create and resources and read the corresponding datasource. Add documentation. For creating a datasource based off an existing resource you can make use of the schema directly. Otherwise implementing the schema directly, similar to normal resource creation, is the desired path.\n"},{"id":10,"href":"/magic-modules/docs/how-to/add-handwritten-iam/","title":"Add handwritten IAM resources","section":"How To","content":" Add handwritten IAM resources # Handwritten IAM support is only recommended for resources that cannot be managed using MMv1, including for handwritten resources, due to the need to manage tests and documentation by hand. This guidance goes through the motions of adding support for new handwritten IAM resources, but does not go into the details of the implementation as any new handwritten IAM resources are expected to be exceptional.\nIAM resources are implemented using an IAM framework, where you implement an interface for each parent resource supporting getIamPolicy/setIamPolicy and the associated IAM resources that target that parent resource- _member, _binding, and _policy- are created by the framework.\nTo add support for a new target, create a new file in mmv1/third_party/terraform/utils called iam_{{resource}}.go, and implement the ResourceIamUpdater, newResourceIamUpdaterFunc, iamPolicyModifyFunc, resourceIdParserFunc interfaces from https://github.com/GoogleCloudPlatform/magic-modules/blob/main/mmv1/third_party/terraform/utils/iam.go.erb in public types, alongside a public map[string]*schema.Schema containing all fields referenced in the resource.\nOnce your implementation is complete, add the IAM resources to provider.go inside the START non-generated IAM resources block, creating the concrete resource types using the ResourceIamMember, ResourceIamBinding, and ResourceIamPolicy functions. For example:\n\u0026#34;google_bigtable_instance_iam_binding\u0026#34;: ResourceIamBinding(IamBigtableInstanceSchema, NewBigtableInstanceUpdater, BigtableInstanceIdParseFunc), \u0026#34;google_bigtable_instance_iam_member\u0026#34;: ResourceIamMember(IamBigtableInstanceSchema, NewBigtableInstanceUpdater, BigtableInstanceIdParseFunc), \u0026#34;google_bigtable_instance_iam_policy\u0026#34;: ResourceIamPolicy(IamBigtableInstanceSchema, NewBigtableInstanceUpdater, BigtableInstanceIdParseFunc), Following that, write a test for each resource exercising create and update for both _policy and _binding, and create for _member. No special accommodations are needed for the IAM test compared to a normal Terraform resource test.\nDocumentation for IAM resources is done using single page per target resource, rather than a distinct page for each IAM resource level. As most of the page is standard, you can generally copy and edit an existing handwritten page such as https://github.com/GoogleCloudPlatform/magic-modules/blob/main/mmv1/third_party/terraform/website/docs/r/bigtable_instance_iam.html.markdown to write the documentation.\n"},{"id":11,"href":"/magic-modules/docs/getting-started/run-provider-tests/","title":"Run provider tests","section":"Getting Started","content":" Run provider tests locally # Note: If you want to test changes you\u0026rsquo;ve made in Magic Modules, you need to first generate the provider you want to test. Setup # Tests generally assume the following environment variables must be set in order to run tests:\nGOOGLE_PROJECT GOOGLE_CREDENTIALS|GOOGLE_CLOUD_KEYFILE_JSON|GCLOUD_KEYFILE_JSON|GOOGLE_USE_DEFAULT_CREDENTIALS GOOGLE_REGION GOOGLE_ZONE Note that the credentials you provide must be granted wide permissions on the specified project. These tests provision real resources, and require permission in order to do so. Most developers on the team grant their test service account roles/editor or roles/owner on their project. Additionally, to ensure that your tests are performed in a region and zone with wide support for GCP features, GOOGLE_REGION should be set to us-central1 and GOOGLE_ZONE to us-central1-a.\nAdditional variable may be required for other tests, and should get flagged when running them by Go skipping the test and flagging in the output it was skipped, with a skip message explaining why. The most typical extra values required are those required for project creation:\nGOOGLE_ORG GOOGLE_BILLING_ACCOUNT Run unit tests # Unit tests (that is, tests that do not interact with the GCP API) are very fast and you can generally run them all if you have changed any of them:\nmake test Run acceptance tests # You can run tests against the provider you generated in the OUTPUT_PATH location. When running tests, specify which to run using TESTARGS, such as:\n# for ga provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google make testacc TEST=./google TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic\u0026#39; # for beta provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta make testacc TEST=./google-beta TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic\u0026#39; TESTARGS allows you to pass testing flags to go test. The most important is -run, which allows you to limit the tests that get run. There are 2000+ tests, and running all of them takes over 9 hours and requires a lot of GCP quota.\n-run is regexp-like, so multiple tests can be run in parallel by specifying a common substring of those tests (for example, TestAccContainerNodePool to run all node pool tests).\nDebugging tests # You can increase your test verbosity and redirect the output to a log file for analysis. This is often helpful in debugging issues.\n# for ga provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google TF_LOG=TRACE make testacc TEST=./google TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic\u0026#39; \u0026gt; output.log # for beta provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta TF_LOG=TRACE make testacc TEST=./google-beta TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic\u0026#39; \u0026gt; output.log You can also debug tests with Delve:\n# Navigate to the google package within your local GCP Terraform provider Git clone. cd $GOPATH/src/github.com/terraform-providers/terraform-provider-google/google # Execute the dlv command to launch the test. # Note that the --test.run flag uses the same regexp matching as go test --run. TF_ACC=1 dlv test -- --test.v --test.run TestAccComputeRegionBackendService_withCdnPolicy Type \u0026#39;help\u0026#39; for list of commands. (dlv) b google.TestAccComputeRegionBackendService_withCdnPolicy Breakpoint 1 set at 0x1de072b for github.com/terraform-providers/terraform-provider-google/google.TestAccComputeRegionBackendService_withCdnPolicy() ./resource_compute_region_backend_service_test.go:540 (dlv) c === RUN TestAccComputeRegionBackendService_withCdnPolicy \u0026gt; github.com/terraform-providers/terraform-provider-google/google.TestAccComputeRegionBackendService_withCdnPolicy() ./resource_compute_region_backend_service_test.go:540 (hits goroutine(7):1 total:1) (PC: 0x1de072b) 535: }, 536: }, 537: }) 538: } 539: =\u0026gt; 540: func TestAccComputeRegionBackendService_withCdnPolicy(t *testing.T) { 541: t.Parallel() 542: 543: var svc compute.BackendService 544: resource.Test(t, resource.TestCase{ 545: PreCheck: func() { testAccPreCheck(t) }, (dlv) Testing with different terraform versions # Tests will use whatever version of the terraform binary is found on your path. To test with multiple versions of terraform core, you must run the tests multiple times with different versions. You can use tfenv to manage your system terraform versions.\n"},{"id":12,"href":"/magic-modules/docs/getting-started/use-built-provider/","title":"Use built provider","section":"Getting Started","content":" Use built provider locally # Note: If you want to test changes you\u0026rsquo;ve made in Magic Modules, you need to first generate the provider you want to test. Sometimes, for example for manual testing, you may want to build the provider from source and use it with terraform.\nSetup # Choose your architecture below.\nMac ARM64 mkdir -p ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google/9.0.0/darwin_arm64 mkdir -p ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google-beta/9.0.0/darwin_arm64 ln -s $GOPATH/bin/terraform-provider-google ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google/9.0.0/darwin_arm64/terraform-provider-google_v9.0.0 ln -s $GOPATH/bin/terraform-provider-google-beta ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google-beta/9.0.0/darwin_arm64/terraform-provider-google-beta_v9.0.0 Mac AMD64 mkdir -p ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google/9.0.0/darwin_amd64 mkdir -p ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google-beta/9.0.0/darwin_amd64 ln -s $GOPATH/bin/terraform-provider-google ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google/9.0.0/darwin_amd64/terraform-provider-google_v9.0.0 ln -s $GOPATH/bin/terraform-provider-google-beta ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google-beta/9.0.0/darwin_amd64/terraform-provider-google-beta_v9.0.0 Linux AMD64 mkdir -p ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google/9.0.0/linux_amd64 mkdir -p ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google-beta/9.0.0/linux_amd64 ln -s $GOPATH/bin/terraform-provider-google ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google/9.0.0/linux_amd64/terraform-provider-google_v9.0.0 ln -s $GOPATH/bin/terraform-provider-google-beta ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google-beta/9.0.0/linux_amd64/terraform-provider-google-beta_v9.0.0 Other: substitute your architecture mkdir -p ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google/9.0.0/myarch_amd64 mkdir -p ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google-beta/9.0.0/myarch_amd64 ln -s $GOPATH/bin/terraform-provider-google ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google/9.0.0/myarch_amd64/terraform-provider-google_v9.0.0 ln -s $GOPATH/bin/terraform-provider-google-beta ~/.terraform.d/plugins/registry.terraform.io/hashicorp/google-beta/9.0.0/myarch_amd64/terraform-provider-google-beta_v9.0.0 Once this setup is complete, terraform will automatically use the binaries generated by the make build commands in the terraform-provider-google and terraform-provider-google-beta repositories instead of downloading the latest versions.\nBuild provider # # ga provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google make build # beta provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta make build Cleanup # To stop using the local provider binary, you can run:\nrm -rf ~/.terraform.d/plugins/registry.terraform.io/hashicorp/ Download production providers # When in this mode, Terraform will be unable to pull the google and google-beta providers from the registry using terraform init, even if a version constraint requires them. However, providers downloaded to the discovery directory may be used by init. To download providers to the discovery directory, run terraform providers mirror ~/.terraform.d/plugins from your configuration\u0026rsquo;s directory prior to running terraform init.\nMore information # For more information, check out Hashicorp\u0026rsquo;s documentation on the 0.13+ filesystem layout.\nIf multiple versions are available in a plugin directory (for example after terraform providers mirror is used), Terraform will pick the most up-to-date provider version within version constraints. As such, we recommend using a version that is several major versions ahead for your local copy of the provider, such as 9.0.0.\n"},{"id":13,"href":"/magic-modules/docs/getting-started/contributing/","title":"Contributing","section":"Getting Started","content":" General contributing steps # Fork Magic Modules repository into your GitHub account if you haven\u0026rsquo;t done before.\nCheck the issue tracker to see whether your feature has already been requested.\nif there\u0026rsquo;s an issue and it\u0026rsquo;s already has a dedicated assignee, it indicates that someone may have already started to work on a solution. otherwise, you\u0026rsquo;re welcome to work on the issue. Check whether the resource you would like to work on already exists in the providers (google / google-beta or check the website).\nIf it exists, check the header of the downstream file to identify the type of tools used to generate the resource. For some resources, the code file, the test file and the documentation file may not be generated via the same tools. Generated resources like google_compute_address can be identified by looking in their Go source for an AUTO GENERATED CODE header as well as a Type. \u0026ldquo;Generated resources\u0026rdquo; typically refers to just the MMv1 type, and DCL type resources are considered \u0026ldquo;DCL-based\u0026rdquo;. (Currently DCL-related contribution are not supported) Handwritten resources like google_container_cluster can be identified if they have source code present under the mmv1/third_party/terraform/resources folder or by the absence of the AUTO GENERATED CODE header in their Go source. If not, decide which tool you would like to use to implement the resource. MMv1 is strongly preferred over handwriting the resource unless the resource can not be generated. Currently, only handwritten datasources are supported. Make the actual code change.\nThe How To section will guide you to the detailed instructions on how to make your change. Generate the providers that include your change.\nRun provider tests locally that are relevant to the change you made. (Testing the PR locally and pushing the commit to the PR only after the tests pass locally may significantly reduce back-and-forth in review.)\nPush your changes to your magic-modules repo fork and send a pull request from that branch to the main branch on magic-modules. A reviewer will be assigned automatically to your PR.\nWait until the the modules magician to generate downstream diff (which should take about 15 mins after creating the PR) to make sure all changes are generated correctly in downstream repos.\nWait for the VCR test results. Get to know general workflow for VCR tests 1. You submit your change. 1. The recorded tests are ran against your changes by the `modular-magician`. Tests will fail if: 1. Your PR has changed the HTTP request values sent by the provider 1. Your PR does not change the HTTP request values, but fails on the values returned in an old recording 1. The recordings are out of sync with the merge-base of your PR, and an unrelated contributor's change has caused a false positive 1. The `modular-magician` will leave a message indicating the number of passing and failing VCR tests. If there is a failure, the `modular-magician` user will leave a message indicating the \u0026quot;`Triggering VCR tests in RECORDING mode for the following tests that failed during VCR:`\u0026quot; marking which tests failed. 1. If a test does not appear related, it probably isn't! 1. The `modular-magician` will kick off a second test run targeting only the failed tests, this time hitting the live GCP APIs. If there are tests that fail at this point, a message stating `Tests failed during RECORDING mode:` will be left indicating the tests. 1. If a test that appears to be related to your change has failed here, it's likely your change has introduced an issue. You can view the debug logs for the test by clicking the \u0026quot;view\u0026quot; link beside the test case to attempt to debug what's going wrong. 1. If a test appears to be completely unrelated has failed, it's possible that a GCP API has changed in a way that broke the provider or our environment capped on a quota. Where possible, take a look at the logs and see if you can figure out what needs to be fixed related to your change. The false positive rate on these tests is extremely high between changes in the API, Cloud Build bugs, and eventual consistency issues in test recordings so we don\u0026rsquo;t expect contributors to wholly interpret the results- that\u0026rsquo;s the responsibility of your reviewer.\nIf your assigned reviewers does not reply / review within a week, gently ping them on github.\nAfter your PR is merged, it will be released to customers in around a week or two.\n"},{"id":14,"href":"/magic-modules/docs/reference/api-yaml-resource/","title":"api.yaml resource ","section":"Reference","content":"FORCE MENU RENDER\n"},{"id":15,"href":"/magic-modules/docs/reference/terraform-yaml-resource/","title":"terraform.yaml resource ","section":"Reference","content":"FORCE MENU RENDER\n"}]