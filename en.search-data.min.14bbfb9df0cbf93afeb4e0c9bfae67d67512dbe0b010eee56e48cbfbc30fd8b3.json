[{"id":0,"href":"/magic-modules/docs/how-to/types-of-resources/","title":"Types of resources","section":"How To","content":" Types of resources # MMv1 # MMv1 is a Ruby-based code generator that implements Terraform Provider Google (TPG) resources from YAML specification files.\nMMv1-generated resources like google_compute_address can be identified by looking in their Go source for an AUTO GENERATED CODE header as well as a Type MMv1. MMv1-generated resources should have source code present under their product folders, like mmv1/products/compute for the google_compute_address resource.\nHandwritten # Handwritten resources like google_container_cluster can be identified if they have source code present under the mmv1/third_party/terraform/resources folder or by the absence of the AUTO GENERATED CODE header in their Go source in the downstream repositories. Handwritten datasources should be under the mmv1/third_party/terraform/data_sources folder, tests under the mmv1/third_party/terraform/tests folder and web documentation under the mmv1/third_party/terraform/website folder.\nDCL aka tpgtools (maintenance mode) # DCL is a Go-based code generator that implements Terraform Provider Google (TPG) resources from YAML specification files.\nDCL-generated resources like google_bigquery_reservation_assignment can be identified by looking in their Go source for an AUTO GENERATED CODE header as well as a Type DCL.\nDCL is in maintenance mode, which means that new resources using the DCL are not being added.\n"},{"id":1,"href":"/magic-modules/docs/how-to/add-mmv1-resource/","title":"Add an MMv1 resource","section":"How To","content":" Add an MMv1 resource # Generated resources are created using the mmv1 code generator, and are configured by editing definition files under the mmv1/products path. Go to the service for your resource like compute and open the api.yaml and terraform.yaml files. In each of those, find the resource\u0026rsquo;s properties field.\nFor example, for google_spanner_database:\napi.yaml\nterraform.yaml\nIn short,properties is an array of the resource\u0026rsquo;s fields. api.yaml it contains the fields of the resource based on how it behaves in the API, and terraform.yaml contains Terraform-specific amendments to those fields' behaviour. Not all fields will need to be added to terraform.yaml- only add an entry for your field if you need to configure one of the available option(s).\nField Configuration # api.yaml # To add a field, you\u0026rsquo;ll append an entry to properties within api.yaml, such as the following adding support for a fooBar field in the API:\n- !ruby/object:Api::Type::String name: \u0026#39;fooBar\u0026#39; min_version: beta input: true description: | The cloud.google.com description of this field. The first line of that snippet is the type of the field in the API, including primitives like String, Integer, Boolean, Double. Additional special types are detailed below in \u0026ldquo;Complex Types\u0026rdquo;.\nYou can configure settings on the field that describe it in the API. Avoid setting values to false, and omit them instead.\ndescription is the cloud.google.com description of the field, and must be filled out manually. min_version can be set to beta if the field is only available at public preview or beta. If it is GA, do not set a min_version value. required: true indicates that a field is required. New top-level fields should not be considered required, as that is a breaking change. Subfields of newly-added optional fields can be added as required. input: true indicates that a field can only be set when the API resource is created. Changing the field will force the resource to be recreated. output: true indicates that a field is output-only in the API and cannot be configured by the user. default_value: {{value}} adds a default value for the field. This should only be used if the default value is fixed in the API. send_empty_value: true indicates that an explicit zero value should be sent to the API. This is useful when a value has a nonzero default in the API but the zero value for the type can be set. This is extremely common for booleans that default to true. update_verb and update_url configure a custom update function for a field.update_verbshould be set to a literal symbol for the type (such as :POST for POST) and the URL to a templated URL such asprojects/{{project}}/global/backendServices/{{name}}/setSecurityPolicy. terraform.yaml # You can add additional values within terraform.yaml:\nfoobar: !ruby/object:Overrides::Terraform::PropertyOverride ignore_read: true default_from_api: true custom_expand: \u0026#39;templates/terraform/custom_expand/shortname_to_url.go.erb\u0026#39; Commonly configured values include the following:\ndefault_from_api: true indicates that Terraform needs to handle a field specially. This is common for fields with complex defaults from the API that can\u0026rsquo;t be represented with default_value. If a default_from_api: true field is set in a user\u0026rsquo;s config, Terraform will treat it as an optional field, detecting drift and correcting drift. If it is not set, it will be treated as an output-only field. ignore_read: true indicates that a value is not returned from an API, and Terraform should not look for it in API responses. custom_expand and custom_flatten are custom functions to read/write a value from state. They refer to files holding function contents under mmv1/template/terraform/custom_expand and mmv1/template/terraform/custom_flatten respectively. Field Configuration - Complex Types # Enum # - !ruby/object:Api::Type::Enum name: \u0026#39;metadata\u0026#39; description: | Can only be specified if VPC flow logging for this subnetwork is enabled. Configures whether metadata fields should be added to the reported VPC flow logs. values: - :EXCLUDE_ALL_METADATA - :INCLUDE_ALL_METADATA - :CUSTOM_METADATA default_value: :INCLUDE_ALL_METADATA Enum values represent enums in the underlying API where it is valuable to restrict the range of inputs to a fixed set of values. They are strings that support a values key to define the array of possible values specified as literal constants, and default_value should be specified as a literal constant as well.\nMost API enums should be typed as String instead- if the value will not be fixed for \u0026gt;1 year, use a String.\nResourceRef # - !ruby/object:Api::Type::ResourceRef name: \u0026#39;urlMap\u0026#39; resource: \u0026#39;UrlMap\u0026#39; imports: \u0026#39;selfLink\u0026#39; description: | A reference to the UrlMap resource that defines the mapping from URL to the BackendService. ResourceRefs are fields that reference other resource. They\u0026rsquo;re most typical in GCE, and making a field a ResourceRef instead of a String will cause Terraform to allow switching between reference formats and versions safely. If a field can refer to multiple resource types, use a String instead.\nIn a ResourceRef, resource and imports must be defined but Terraform ignores those values. resource should be set to the resource kind, and imports to selfLink within GCE and name elsewhere.\nArray # - !ruby/object:Api::Type::Array name: scopes item_type: Api::Type::String description: | The list of scopes to be made available for this service account. - !ruby/object:Api::Type::Array name: \u0026#39;instances\u0026#39; description: | A list of virtual machine instances serving this pool. They must live in zones contained in the same region as this pool. item_type: !ruby/object:Api::Type::ResourceRef name: \u0026#39;instance\u0026#39; description: \u0026#39;The instance being served by this pool.\u0026#39; resource: \u0026#39;Instance\u0026#39; imports: \u0026#39;selfLink\u0026#39; Arrays refer to arrays in the underlying API, with their item being specified through an item_type field. item_type accepts any type, although primitives (String / Integer / Boolean) must be specified differently than other types as shown above.\nNestedObject # - !ruby/object:Api::Type::NestedObject name: \u0026#39;imageEncryptionKey\u0026#39; description: | Encrypts the image using a customer-supplied encryption key. After you encrypt an image with a customer-supplied key, you must provide the same key if you use the image later (e.g. to create a disk from the image) properties: - !ruby/object:Api::Type::String name: \u0026#39;rawKey\u0026#39; description: | Specifies a 256-bit customer-supplied encryption key, encoded in RFC 4648 base64 to either encrypt or decrypt this resource. - !ruby/object:Api::Type::String name: \u0026#39;sha256\u0026#39; output: true description: | The RFC 4648 base64 encoded SHA-256 hash of the customer-supplied encryption key that protects this resource. NestedObject is an object in the JSON API, and contains a properties subfield where a sub-properties array can be defined (including additional NestedObjects)\nKeyValuePairs (Labels / Annotations) # - !ruby/object:Api::Type::KeyValuePairs name: \u0026#39;labels\u0026#39; description: Labels to apply to this address. A list of key-\u0026gt;value pairs. KeyValuePairs is a special type to handle string -\u0026gt; string maps, such as GCE labels fields. No extra configuration is required.\nExactly One Of # To restrain a parent object to contain exactly one of its nested objects, use exactly_one_of in the affected child objects.\nYaml:\nobjects: - !ruby/object:Api::Resource name: \u0026#39;Connection\u0026#39; ... properties: - !ruby/object:Api::Type::NestedObject name: \u0026#39;cloudSql\u0026#39; exactly_one_of: - cloud_sql - aws properties: ... - !ruby/object:Api::Type::NestedObject name: aws exactly_one_of: - cloud_sql - aws properties: ... Advanced customization # DiffSuppressFunc # Terraform allows fields to specify a DiffSuppressFunc, which allows you to ignore diffs in cases where the two values are functionally identical. This is generally useful when the API returns a normalized value - for example by standardizing the case.\nNote: The preferred behavior for APIs is to always return the value that the user sent. DiffSuppressFunc is a workaround for APIs that don\u0026rsquo;t.\nThe Terraform provider comes with a set of \u0026ldquo;common diff suppress functions\u0026rdquo;. These fit frequent needs like ignoring whitespace at the beginning and end of a string, or ignoring case differences.\nIf you need to define a custom diff specifically for your resource, you can do so in a \u0026ldquo;constants\u0026rdquo; file, which is a .go.erb file in mmv1/templates/terraform/constants named \u0026lt;product\u0026gt;_\u0026lt;resource\u0026gt;.erb. You can then declare this custom code in terraform.yaml:\n--- !ruby/object:Provider::Terraform::Config overrides: !ruby/object:Overrides::ResourceOverrides ResourceName: # various overrides go here custom_code: !ruby/object:Provider::Terraform::CustomCode constants: templates/terraform/constants/product_resource_name.go.erb Once you have chosen a DiffSuppressFunc, you can declare it as an override on your resource:\n--- !ruby/object:Provider::Terraform::Config overrides: !ruby/object:Overrides::ResourceOverrides ResourceName: # various overrides go here properties: myField: !ruby/object:Overrides::Terraform::PropertyOverride diff_suppress_func: \u0026#39;caseDiffSuppress\u0026#39; The value of diff_suppress_func can be any valid DiffSuppressFunc, including the result of a function call. For example:\ndiff_suppress_func: \u0026#39;optionalPrefixSuppress(\u0026#34;folders/\u0026#34;)\u0026#39; Please make sure to add thorough unit tests (in addition to basic integration tests) for your diff suppress func.\nExample: DomainMapping (domainMappingLabelDiffSuppress)\nterraform.yaml resource overrides custom_code diff_suppress_func: 'resourceBigQueryDatasetAccessRoleDiffSuppress' constants file unit tests Documentation # When adding a new MMv1 product or resource there are fields that you need to set within api.yaml and terraform.yaml that are specific to documentation for that resource. To learn more about MMv1 generated documentation and what YAML fields you need to pay attention to, see Update MMv1 resource documentation.\nBeta features # When the underlying API of a feature is not final (i.e. a vN version like v1 or v2), is in preview, or the API has no SLO we add it to the google-beta provider rather than the google provider, allowing users to self-select for the stability level they are comfortable with.\nIn MMv1, a \u0026ldquo;version tag\u0026rdquo; can be annotated on resources, fields, resource iam metadata and examples to control the stability level that a feature is available at. Version tags are a specification of the minimum version a feature is available at, written as min_version: {{version}}. This is only specified when a feature is available at beta, and omitting a tag indicates the target is generally available, or available at ga.\nAdding a beta resource # To add support for a beta resource in a preexisting product, ensure that a beta level exists in the versions map in the api.yaml file for the product. If one doesn\u0026rsquo;t already exist, add it, setting the base_url to the appropriate value. This is generally an API version including beta, such as v1beta, but may be the same base_url as the ga entry for services that mix fields with different stability levels within a single endpoint.\nFor example:\nversions: - !ruby/object:Api::Product::Version name: ga base_url: https://compute.googleapis.com/compute/v1/ + - !ruby/object:Api::Product::Version + name: beta + base_url: https://compute.googleapis.com/compute/beta/ If the product doesn\u0026rsquo;t already exist, it\u0026rsquo;s only necessary to add the beta entry, i.e.:\nversions: - !ruby/object:Api::Product::Version name: beta base_url: https://runtimeconfig.googleapis.com/v1beta1/ Next, annotate the resource (part of resources in api.yaml) i.e.:\n- !ruby/object:Api::Resource name: \u0026#39;Config\u0026#39; base_url: projects/{{project}}/configs self_link: projects/{{project}}/configs/{{name}} + min_version: beta description: | A RuntimeConfig resource is the primary resource in the Cloud RuntimeConfig service. A RuntimeConfig resource consists of metadata and a hierarchy of variables. iam_policy: !ruby/object:Api::Resource::IamPolicy parent_resource_attribute: \u0026#39;config\u0026#39; method_name_separator: \u0026#39;:\u0026#39; exclude: false properties: ... You\u0026rsquo;ll notice above that the iam_policy is not annotated with a version tag. Due to the resource having a min_version tagged already, that\u0026rsquo;s passed through to the iam_policy (although the same is not true for examples entries used to create tests). IAM-level tagging is only necessary in the (rare) case that a resource is available at a higher stability level than its getIamPolicy/setIamPolicy methods.\nAdding beta field(s) # NOTE: If a resource is already tagged as min_version: beta, follow the general instructions for adding a field instead.\nTo add support for a beta field to a GA resource, ensure that the beta entry already exists in the versions map for the product. See above for details on doing so.\nNext, add the field(s) as normal with a min_version: beta tag specified. In the case of nested fields, only the highest-level field must be tagged, as demonstrated below:\n- !ruby/object:Api::Type::NestedObject name: \u0026#39;scaleDownControl\u0026#39; + min_version: beta description: | Defines scale down controls to reduce the risk of response latency and outages due to abrupt scale-in events properties: - !ruby/object:Api::Type::Integer name: \u0026#39;timeWindowSec\u0026#39; description: | How long back autoscaling should look when computing recommendations to include directives regarding slower scale down, as described above. ... Promote a beta feature # In order to promote a beta feature to GA, remove the version tags previously set on the feature or its tests. This will automatically make it available in the google provider and remove the note that the feature is in beta in the provider documentation.\nFor a resource, this typically means ensuring their removal:\nAt the resource level, resources in api.yaml On all resource examples, examples in terraform.yaml (unless some examples use other beta resources or fields) Additionally, for any modified examples, all provider = google-beta annotations must be cleared For a field, this typically means ensuring their removal:\nAt the field level, properties in api.yaml On any resource examples where this was the last beta feature, examples in terraform.yaml Additionally, for any modified examples, all provider = google-beta annotations must be cleared If the feature was tested using handwritten tests, the version guards must be removed, as described in the guidance for handwritten resources.\nWhen writing a changelog entry for a promotion, write it as if it was a new field or resource, and suffix it with (ga only). For example, if the google_container_cluster resource was promoted to GA in your change:\n\\`\\`\\`release-note:new-resource `google_container_cluster` (ga only) \\`\\`\\` Alternatively, for field promotions, you may use \u0026ldquo;{{service}}: promoted {{field}} in {{resource}} to GA\u0026rdquo;, i.e.\n\\`\\`\\`release-note:enhancement container: promoted `node_locations` field in google_container_cluster` to GA \\`\\`\\` "},{"id":2,"href":"/magic-modules/docs/getting-started/setup/","title":"Set up your environment","section":"Getting Started","content":" Set up your environment # Cloning Terraform providers # If you\u0026rsquo;re generating the Terraform providers (google and google-beta), you\u0026rsquo;ll need to check out the repo(s) you\u0026rsquo;re generating in your GOPATH. For example:\ngit clone https://github.com/hashicorp/terraform-provider-google.git $GOPATH/src/github.com/hashicorp/terraform-provider-google git clone https://github.com/hashicorp/terraform-provider-google-beta.git $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta Or run the following to check them all out:\n./scripts/bootstrap Magic Modules won\u0026rsquo;t work with old versions of the Terraform provider repos. If you\u0026rsquo;re encountering issues with vendoring and paths, make sure both MM and the Terraform provider are running on up to date copies of main.\nSetting up a container-based environment # NOTE this approach is in beta and still collecting feedback. Please file an issue if you encounter challenges, and try pulling the latest container (see command below) first to see if any recent changes may fix you.\nYou do not need to run these instructions if you are setting up your environment manually.\nFor ease of contribution, we provide containers with the required dependencies for building magic-modules, as well as the option to build them yourself.\nYou can work with containers with either Podman or Docker.\nscripts/make-in-container.sh includes all the instructions to build and run containers by hand. Refer to the script for individual steps, but for most users you only have to run the script directly, as a replacement for make.\nHere is an example of how to build Terraform (after cloning the provider):\n./scripts/make-in-container.sh \\ terraform VERSION=ga \\ OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; Generally, you can replace any reference to make in this guide with scripts/make-in-container.sh.\nPreparing your environment manually # NOTE: you don\u0026rsquo;t need to run these instructions if you are using a container-based environment.\nYou can also build magic-modules within your local development environment.\nTo get started, you\u0026rsquo;ll need:\nGo If you\u0026rsquo;re using a Mac with Homebrew installed, you can follow these instructions to set up Go: YouTube video. If you\u0026rsquo;re using Cloud Shell, Go is already installed. Currently it\u0026rsquo;s recommended to use Go 1.18, Go 1.19 changed the gofmt rules which causes some gofmt issue and our CIs are all on 1.18.X Ruby 2.6.0 You can use rbenv to manage your Ruby version(s). To install rbenv: Homebrew: run brew install rbenv ruby-build Debian, Ubuntu, and their derivatives: run sudo apt install rbenv Then run rbenv install 2.6.0. For M1 Mac users, run RUBY_CFLAGS=\u0026quot;-Wno-error=implicit-function-declaration\u0026quot; rbenv install 2.6.0 Bundler This can be installed with gem install bundler Gems for magic-modules This can be installed with cd mmv1 \u0026amp;\u0026amp; bundler install Goimports go install golang.org/x/tools/cmd/goimports / go install golang.org/x/tools/cmd/goimports@latest Terraform Install Terraform If you are getting \u0026ldquo;Too many open files\u0026rdquo; ulimit needs to be raised. Mac OSX: ulimit -n 1000 Now, you can verify you\u0026rsquo;re ready with:\nmake doctor Check for rbenv in path... found! Checking ruby version... 2.6.0 (set by [PATH]/magic-modules/mmv1/.ruby-version) Check for bundler in path... found! Check for go in path... found! Check for goimports in path... found! Check for git in path... found! Test your setup # Try generating the providers. If your environment is set up correctly, it should succeed with no errors!\n"},{"id":3,"href":"/magic-modules/docs/how-to/add-mmv1-iam/","title":"Add MMv1 IAM resources","section":"How To","content":" Add MMv1 IAM resources # For resources implemented through the MMv1 engine, the majority of configuration for IAM support can be inferred based on the preexisting YAML specification file.\nTo add support for IAM resources based on an existing resource, add an iam_policy block to the resource\u0026rsquo;s definition in api.yaml, such as the following:\niam_policy: !ruby/object:Api::Resource::IamPolicy method_name_separator: \u0026#39;:\u0026#39; fetch_iam_policy_verb: :POST parent_resource_attribute: \u0026#39;registry\u0026#39; import_format: [\u0026#34;projects/{{project}}/locations/{{location}}/registries/{{name}}\u0026#34;, \u0026#34;{{name}}\u0026#34;] The specification values can be determined based on a mixture of the resource specification and the cloud.google.com setIamPolicy/getIamPolicy REST documentation, such as this page for Cloud IOT Registries.\nparent_resource_attribute - (Required) determines the field name of the parent resource reference in the IAM resources. Generally, this should be the singular form of the parent resource kind in snake case, i.e. registries -\u0026gt; registry or backendServices -\u0026gt; backend_service.\nmethod_name_separator - (Required) should be set to the character preceding setIamPolicy in the \u0026ldquo;HTTP Request\u0026rdquo; section on the resource\u0026rsquo;s setIamPolicy page. This is almost always : for APIs other than Google Compute Engine (GCE), MMv1\u0026rsquo;s compute product.\nfetch_iam_policy_verb - (Required) should be set to the HTTP verb listed in the \u0026ldquo;HTTP Request\u0026rdquo; section on the resource\u0026rsquo;s getIamPolicy page. This is generally POST but is occasionally GET. Note: This is specified as a Ruby symbol, prefixed with a :. For example, for GET, you would specify :GET.\nimport_format - (Optional) A list of templated strings used to determine the Terraform import format. If the resource has a custom import_format or id_format defined in terraform.yaml, this must be supplied.\nIf an import_format is set on the parent resource use that set of values exactly, substituting parent_resource_attribute for the field name of the final templated value. If an id_format is set on the parent resource use that as the first entry (substituting the final templated value, as with import_format) and define a second format with only the templated values, /-separated. For example, projects/{{project}}/locations/{{region}}/myResources/{{name}} -\u0026gt; [\u0026quot;projects/{{project}}/locations/{{region}}/myResources/{{myResource}}\u0026quot;, \u0026quot;{{project}}/{{region}}/{{myResource}}\u0026quot;]. Optionally, you may provide a version of the shortened format that excludes entries called {{project}}, {{region}}, and {{zone}}. For example, given {{project}}/{{region}}/{{myResource}}/{{entry}}, {{myResource}}/{{entry}} is a valid format. When a user specifies this format, the provider\u0026rsquo;s default values for project/region/zone will be used. allowed_iam_role - (Optional) If the resource does not allow the roles/viewer IAM role to be set, an alternate, valid role must be provided.\niam_conditions_request_type - (Optional) The method the IAM policy version is set in getIamPolicy. If unset, IAM conditions are assumed to not be supported for the resource. One of QUERY_PARAM, QUERY_PARAM_NESTED or REQUEST_BODY. For resources where a query parameter is expected, QUERY_PARAM should be used if the key is optionsRequestedPolicyVersion, while QUERY_PARAM_NESTED should be used if it is options.requestedPolicyVersion.\nmin_version - (Optional) If the resource or IAM method is not generally available, this should be set to beta or alpha as appropriate.\nset_iam_policy_verb - (Optional, rare) Similar to fetch_iam_policy_verb, the HTTP verb expected by setIamPolicy. Defaults to :POST, and should only be specified if it differs (typically if :PUT is expected).\nSeveral single-user settings are not documented on this page as they are not expected to recur often. If you are unable to configure your API successfully, you may want to consult https://github.com/GoogleCloudPlatform/magic-modules/blob/main/mmv1/api/resource/iam_policy.rb for additional configuration options.\nAdditionally, in order to generate IAM tests based on a preexisting resource configuration, the first examples entry in terraform.yaml must be modified to include a primary_resource_name entry:\n- !ruby/object:Provider::Terraform::Examples name: \u0026#34;disk_basic\u0026#34; primary_resource_id: \u0026#34;default\u0026#34; + primary_resource_name: \u0026#34;fmt.Sprintf(\\\u0026#34;tf-test-test-disk%s\\\u0026#34;, context[\\\u0026#34;random_suffix\\\u0026#34;])\u0026#34; vars: disk_name: \u0026#34;test-disk\u0026#34; primary_resource_name - Typically \u0026quot;fmt.Sprintf(\\\u0026quot;tf-test-{{shortname}}%s\\\u0026quot;, context[\\\u0026quot;random_suffix\\\u0026quot;])\u0026quot;, substituting the parent resource\u0026rsquo;s shortname from the example configuration for {{shortname}}, such as test-disk above. This value is variable, as both the key and value are user-defined parts of the example configuration. In some cases the value must be customized further, albeit rarely.\nOnce an iam_policy block is added and filled out, and primary_resource_name is set on the first example, you\u0026rsquo;re finished, and you can run MMv1 to generate the IAM resources you\u0026rsquo;ve added, alongside documentation, and tests.\nAdding IAM support to nonexistent resources # Some IAM targets don\u0026rsquo;t exist as distinct resources, such as IAP, or their target is supported through an engine other than MMv1 (i.e. through tpgtools/DCL or a handwritten resource). For these resources, the exclude_resource: true annotation can be used. To use it, partially define the resource in the product\u0026rsquo;s api.yaml file and apply the annotation. MMv1 won\u0026rsquo;t attempt to generate the resource itself and will only generate IAM resources targeting it.\nThe IAP product is a good reference for adding these: https://github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/products/iap\n"},{"id":4,"href":"/magic-modules/docs/how-to/add-mmv1-test/","title":"Add an MMv1 test","section":"How To","content":" Add an MMv1 test # For generated resources, you can add an example to the mmv1/templates/terraform/examples directory, which contains a set of templated Terraform configurations.\nAfter writing out the example and filling out some metadata, Magic Modules will insert it into the resource documentation page, and generate a test case stepping through the following stages:\nRun terraform apply on the configuration, waiting for it to succeed and recording the results in Terraform state Run terraform plan, and fail if Terraform detects any drift Clear the resource from state and run terraform import on it Deeply compare the original state from terraform apply and the terraform import results, returning an error if any values are not identical Destroy all resources in the configuration using terraform destroy, waiting for the destroy command to succeed Call GET on the resource, and fail the test if it is still present Example Configuration File # First, you\u0026rsquo;ll want to add the example file. It needs to end in the filename .tf.erb, and is typically named service_resource_descriptive_name. For example, pubsub_topic_geo_restricted.tf.erb. Inside, you\u0026rsquo;ll write a complete Terraform configuration that provisions the resource and all of the required dependencies. For example, in mmv1/templates/terraform/examples/pubsub_subscription_dead_letter.tf.erb:\nresource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;\u0026#34; { name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;topic_name\u0026#39;] %\u0026gt;\u0026#34; } resource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;_dead_letter\u0026#34; { name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;topic_name\u0026#39;] %\u0026gt;-dead-letter\u0026#34; } resource \u0026#34;google_pubsub_subscription\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;\u0026#34; { name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;subscription_name\u0026#39;] %\u0026gt;\u0026#34; topic = google_pubsub_topic.\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;.name dead_letter_policy { dead_letter_topic = google_pubsub_topic.\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;_dead_letter.id max_delivery_attempts = 10 } } The ctx variable provides metadata at generation time, and should be used in two ways:\nThe Terraform ID of a single instance of the primary resource should be supplied through \u0026lt;%= ctx[:primary_resource_id] %\u0026gt; (in this example multiple resources use the value, although only the first google_pubsub_topic requires it). The resource kind you are testing with an id equal to \u0026lt;%= ctx[:primary_resource_id] %\u0026gt; is the one that will be imported. Unique values can be supplied through \u0026lt;%= ctx[:vars]['{{var}}'] %\u0026gt;, where {{var}} is an arbitrary key you define. These values are created by appending suffixes to them, and are typically only used for names- most values should be constant within the configuration. terraform.yaml metadata # Once your configuration is written, go in terraform.yaml and find the examples block for the resource. Generally it\u0026rsquo;ll be above the properties block. In there, append an entry such as the following:\n- !ruby/object:Provider::Terraform::Examples name: \u0026#34;pubsub_subscription_dead_letter\u0026#34; primary_resource_id: \u0026#34;example\u0026#34; vars: topic_name: \u0026#34;example-topic\u0026#34; subscription_name: \u0026#34;example-subscription\u0026#34; The name should match the base name of your example file, primary_resource_id is an arbitrary snake_cased string that describes the resource, and the vars map should contain each key you defined previously.\nImportant: Any vars that are part of the resource\u0026rsquo;s id should include at least one hyphen or underscore; this triggers addition of a tf-test or tf_test prefix, which is what we use to detect and delete stray resources that are sometimes left over during test runs.\nResults # Your configuration will ultimately generate a Go test case similar to the following based on the snippets above:\nfunc TestAccPubsubSubscription_pubsubSubscriptionDeadLetterExample(t *testing.T) { t.Parallel() context := map[string]interface{}{ \u0026#34;random_suffix\u0026#34;: randString(t, 10), } vcrTest(t, resource.TestCase{ PreCheck: func() { testAccPreCheck(t) }, Providers: testAccProviders, CheckDestroy: testAccCheckPubsubSubscriptionDestroyProducer(t), Steps: []resource.TestStep{ { Config: testAccPubsubSubscription_pubsubSubscriptionDeadLetterExample(context), }, { ResourceName: \u0026#34;google_pubsub_subscription.example\u0026#34;, ImportState: true, ImportStateVerify: true, ImportStateVerifyIgnore: []string{\u0026#34;topic\u0026#34;}, }, }, }) } func testAccPubsubSubscription_pubsubSubscriptionDeadLetterExample(context map[string]interface{}) string { return Nprintf(` resource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;example\u0026#34; { name = \u0026#34;tf-test-example-topic%{random_suffix}\u0026#34; } resource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;example_dead_letter\u0026#34; { name = \u0026#34;tf-test-example-topic%{random_suffix}-dead-letter\u0026#34; } resource \u0026#34;google_pubsub_subscription\u0026#34; \u0026#34;example\u0026#34; { name = \u0026#34;tf-test-example-subscription%{random_suffix}\u0026#34; topic = google_pubsub_topic.example.name dead_letter_policy { dead_letter_topic = google_pubsub_topic.example_dead_letter.id max_delivery_attempts = 10 } } `, context) } Update tests # Update tests can only be added as handwritten tests.\nTests that use beta features # For tests that use beta features, you\u0026rsquo;ll need to perform two additional steps:\nAdd provider = google-beta to every resource in the test (even resources that aren\u0026rsquo;t being tested and/or are also in the GA provider) Add min_version: beta to the Provider::Terraform::Examples block For example, modifying the snippets above:\nresource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;\u0026#34; { provider = google-beta name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;topic_name\u0026#39;] %\u0026gt;\u0026#34; } resource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;_dead_letter\u0026#34; { provider = google-beta name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;topic_name\u0026#39;] %\u0026gt;-dead-letter\u0026#34; } resource \u0026#34;google_pubsub_subscription\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;\u0026#34; { provider = google-beta name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;subscription_name\u0026#39;] %\u0026gt;\u0026#34; topic = google_pubsub_topic.\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;.name dead_letter_policy { dead_letter_topic = google_pubsub_topic.\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;_dead_letter.id max_delivery_attempts = 10 } } - !ruby/object:Provider::Terraform::Examples name: \u0026#34;pubsub_subscription_dead_letter\u0026#34; min_version: beta primary_resource_id: \u0026#34;example\u0026#34; vars: topic_name: \u0026#34;example-topic\u0026#34; subscription_name: \u0026#34;example-subscription\u0026#34; "},{"id":5,"href":"/magic-modules/docs/how-to/mmv1-resource-documentation/","title":"Add and update MMv1 resource documentation","section":"How To","content":" MMv1 resource documentation # A majority of the provider\u0026rsquo;s documentation is generated using the same information that\u0026rsquo;s used for generating the provider\u0026rsquo;s Go code. For example, when adding a new field to a resource in the relevant api.yaml file we include a description field. This is used to set a field description in the resource\u0026rsquo;s schema and is also used to document the field in generated markdown files.\nUpdating an existing MMv1 resource\u0026rsquo;s documentation # As a result of code generation, you often do not need to explicitly think about making updates to documentation. However it is a good idea to check the markdown changes when you generate the provider, especially if you are making lots of changes.\nAdding new documentation for a new MMv1 resource # More thought is required when adding a new resource from scratch. See the relevant section below for guidance about what YAML fields are needed to create complete documentation.\nHow generated documentation is made # The Magic Modules compiler parses YAML files, creates Ruby objects that are populated with the data from those files, and then uses that data within template files to create produce the final markdown files.\nThe main template used for documentation is mmv1/templates/terraform/resource.html.markdown.erb. As an example of how it works, you can see that the main title of documentation pages are created by some processing of name data for a given resource and then using Ruby string methods to print an escaped version of the name into an H1 header.\nWhat YAML fields are used in the documentation # The YAML files in Magic Modules are used to generate both the provider\u0026rsquo;s Go code and the markdown documentation. As a result of this, changes to documentation happen automatically while you make a change to a resource\u0026rsquo;s implementation in the provider. Often it\u0026rsquo;s possible to address an issue without ever needing to think about documentation changes.\nHowever, if you are implementing a new product or resource from scratch, or making non-routine changes to documentation, then you will need to be aware of how the YAML fields are used. Especially as some are specific to documentation.\nBelow are descriptions of fields that are directly referenced in the documentation templates.\nTop level fields for a product # These fields are found at the top of api.yaml files, and describe an overall product (ruby/object:Api::Product).\nField Type Relation to documentation Example value display_name string Controls the value of subcategory in YAML frontmatter; determines where the link to the page appears in the left-side navigation menu. See example Top level fields within resources # These can be top-level properties of a resource (ruby/object:Api::Resource) or overrides for the resource (ruby/object:Overrides::Terraform::ResourceOverride), i.e. in api.yaml or terraform.yaml.\nField Type Relation to documentation Example value has_self_link boolean Boolean to indicate if a resource has a self_link attribute. If true, the attribute is included in the templated markdown See example and the resulting self_link attribute in docs import_format array of strings Sets the identifiers that can be used to import a resource into Terraform state. Used to add multiple entries in the \u0026lsquo;Import\u0026rsquo; section of documentation. See example that results in an import section listing multiple options description string Sets the description of the resource at the top of the page See example docs.note string Text is templated into a callout block at the top of the page which is titled \u0026ldquo;Note\u0026rdquo; See example and the resulting callout in the docs docs.warning string Text is templated into a callout block at the top of the page which is titled \u0026ldquo;Warning\u0026rdquo; See example and the resulting callout in the docs * docs.optional_properties string Used to append extra content to the bulleted list describing optional properties for a resource. See example * docs.required_properties string Used to append extra content to the bulleted list describing required properties for a resource. There are no examples of this currently in use. * docs.attributes string Used to append extra content to the bulleted list describing attributes for a resource. There is currently only one example of this field in use, here. min_version string If set to beta, the template includes a beta warning at the start of the documentation See example in the official docs references.api string Sets the URL used in generated links to documentation See example references.guides hash A set of key-value pairs where the key is text to be rendered and the value is the URL the text links to See example supports_indirect_user_project_override boolean This is the explicit way to make sure the \u0026lsquo;User Project Overrides\u0026rsquo; section is shown in the resource\u0026rsquo;s documentation See example and the resulting section in the docs * = Avoid unless absolutely necessary.\nFields set within resource properties # The main thing to focus on for properties is to provide an adequate description. Typically we copy and paste the descriptions from the official API reference, making sure to pick the richest description and include any links.\nUpdates to other fields, like output and required, are easier to troubleshoot via acceptance testing but are also relevant to the produced documentation.\nField Type Relation to documentation deprecated boolean Controls if (Deprecated) will be shown next to the argument name description string The description shown in for a given argument or attribute name string The name displayed in a list of arguments or attributes output boolean Used to prevent a field being presented as an argument in the docs required boolean Controls if (Required) will be shown next to the argument name sensitive boolean Is used to help create a list of sensitive values. This list is used in a warning callout about sensitive values in state at the top of the page skip_docs_values boolean Controls if a default value will be shown, or not, in the docs "},{"id":6,"href":"/magic-modules/docs/getting-started/generate-providers/","title":"Generate the providers","section":"Getting Started","content":" Generate the provider # You can compile the Terraform provider you\u0026rsquo;re working on using make or make provider in the magic-modules directory. Below you\u0026rsquo;ll find a command reference, sample commands, and instructions on how to clean up the repository.\nmake provider reference # make or make provider will build the terraform provider. The following are variables set either as environment or inline when calling make. They will inform the generator where and how to generate.\nNote: Generation is done by running definitions through templates, then unioning these generated files with the actual provider downstream. Thus please ensure the provider you are generating into and magic-modules are in-sync and/or up to date.\nmagic-modules - build variables OUTPUT_PATH (required) The location of the provider you are unioning generation into. VERSION (required) The version of the provider you are building into. Valid values are ga and beta. ENGINE (optional) Modifies make provider to build either tpgtools or mmv1 valid values are mmv1 or tpgtools. Note that running make provider with ENGINE set to tpgtools will build any prerequisite mmv1 files required for tpgtools. PRODUCT (optional) Specifies the product to build. Equivalent to the folder name within /mmv1/products or /tpgtools/api. Useful to scope the build to your changes. Note: mmv1 files in mmv1/third_party/terraform on run of make provider are always built. So if youve only modified files in this directory you can set the PRODUCT to a non-existant one to skip the generation of non-handwritten, code. RESOURCE (optional) Specifies the resource to build. Equivalent to the product name within the api.yaml file for mmv1 or the terraform resource name for tpgtools resources. If filtering for mmv1 PRODUCT must be defined. Sample commands # Run the following commands from the root directory of the repository. OUTPUT_PATH should be set to the location of your provider repository, which is recommended to be inside your GOPATH.\ncd magic-modules make provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; make provider VERSION=beta OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google-beta\u0026#34; # Only generate a specific product (plus all common files) make provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; PRODUCT=pubsub # Only generate only a specific resources for a product make provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; PRODUCT=pubsub RESOURCE=Topic # Only generate common files, including all third_party code make provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; PRODUCT=foo Cleaning up old files # Magic Modules will only generate on top of whatever is in the downstream repository. This means that, from time to time, you may end up with stale files or changes in your downstream that cause compilation or tests to fail.\nYou can clean up by running the following commands in your downstream repository:\ngit checkout -- . git clean -f google/ google-beta/ website/ "},{"id":7,"href":"/magic-modules/docs/how-to/","title":"How To","section":"Docs","content":" How To # Types of resources Check the header in the Go source to determine what type of resource it is. If there is no header, it is likely handwritten. Add an MMv1 resource Generated resources are created using the mmv1 code generator, and are configured by editing definition files under the mmv1/products path. Add MMv1 IAM resources For resources implemented through the MMv1 engine, the majority of configuration for IAM support can be inferred based on the preexisting YAML specification file. Add an MMv1 test An example terraform configuration can be used to generate docs and tests for a resource. Add and update MMv1 resource documentation Generated resources have generated documentation. This page describes the generation process and what YAML inputs are used. Update a handwritten resource The Google providers for Terraform have a large number of handwritten go files, primarily for resources written before Magic Modules was used with them. Most handwritten files are expected to stay handwritten indefinitely, although conversion to a generator may be possible for a limited subset of them. Add a handwritten test For handwritten resources and generated resources that need to test update, handwritten tests must be added. Add a handwritten datasource Datasources are like terraform resources except they don\u0026rsquo;t create anything. Add handwritten IAM resources Handwritten IAM support is only recommended for resources that cannot be managed using MMv1. Update handwritten provider documentation Handwritten resources and datasources have handwritten documentation that needs to be updated in PRs. Add documentation for a handwritten data source New handwritten datasources require new handwritten documentation to be created. "},{"id":8,"href":"/magic-modules/docs/how-to/update-handwritten-resource/","title":"Update a handwritten resource","section":"How To","content":" Update a handwritten resource # The Google providers for Terraform have a large number of handwritten go files, primarily for resources written before Magic Modules was used with them. Most handwritten files are expected to stay handwritten indefinitely, although conversion to a generator may be possible for a limited subset of them.\nWe no longer accept new handwritten resources except in rare cases. However, understanding how to edit and add to existing resources may be important for implementing new fields or changing existing behavior.\nTo edit an existing resource to add a field there are four steps you\u0026rsquo;ll go through.\nAdd the new field to the schema Implement the respective flattener and/or expander for the new field Add a testcase for the field or extend an existing one Add documentation for the field to the respective markdown file Shared concepts # This section will serve as a point of reference for some shared concepts that all handwritten files share. It\u0026rsquo;s meant to be an introduction to our serialization strategy and overview.\nSerialization strategy # The go files within the directory files are copied literally to their respective providers. Our serialization methodology may seem complicated but for the case of handwritten resources its quite simple. Editing the file will change its counterpart downstream.\ngo and go.erb # Within the third party library you\u0026rsquo;ll notice go and go.erb files. Go files are native golang code while go.erb pass through ruby before being serialized. The reason go.erb files exist are to protect certain properties or fields from entering the ga provider. Thus you\u0026rsquo;ll often see lines like \u0026lt;% unless version == 'ga' -%\u0026gt; within the file. These blocks will omit the enclosure from being output to the GA provider. In the rare case where you are promoting all fields to ga and these blocks are no longer needed you can remove the .erb extension.\nCreate, Read, Update, Delete # As far as terraform schema is concerned these are the functions we need to provide for terraform to be able to provision and delete resources. In editing any fields you\u0026rsquo;ll likely be adding functionality to these functions or implementing them wholesale.\nExpanders and Flatteners # Expanders and flatteners are concepts created to simplify common patterns and add conformity/code consistency. Essentially expanders are functions used to segregate some translation from terraform representation to api representation. We will use these to encapsulate this translation for blocks and/or complicated fields. This allows our code to be concise and functionality to be readable and easily apparent by separating these into their own functions. While expanders are used for terraform to api, flatteners do just the opposite. Converting api to terraform.\nThus\nexpanders - helper functions used for translating tf -\u0026gt; api representation flatteners - helper functions used for translating api -\u0026gt; tf representation Adding a new field to the schema # To add a new field you will have to compare an existing resource to it\u0026rsquo;s respective rest api documentation. Dependant on how the api implements the field we will in almost all cases mirror the structure. For example if there is an enabled field nested under a IdentityServiceConfig block we will mirror this within the schema.\nThus the block for terraform to utilize this field would then be\nresource \u0026#34;x\u0026#34; \u0026#34;y\u0026#34; { identity_service_config{ enabled = true } } You might think it convoluted to provide such a structure. Why not simply provide a single enable_identity_service_config. One constant has echoed through our mind as terraform developers through the years. Api\u0026rsquo;s are ever evolving. Mirroring the api gives us the best chance to stay in step with that evolution. Therefore if IdentityServiceConfig is extended with new parameters in the future we can cleanly encapsulate those into the existing block(s).\nAs far as providing the field itself, it\u0026rsquo;s fairly straightforward. Mirror the field from the api and look to the other fields and the schema type in the SDK to see what\u0026rsquo;s available and how to structure it. For the documentation, copying the documentation from the rest api will be the usual practice.\nIf you are adding a field that is an ENUM from the api standpoint its best practice to provide it as as a string to the provider. This field will likely have values added to it by the api and this future proofs our provider to support new values without haven\u0026rsquo;t to make new additions. There will be rare exceptions, but generally its a good practice.\nImplement the respective flattener and/or expander for the new field # Once you\u0026rsquo;ve added the field to the schema you will implement the corresponding expander/flattener. See expanders and flatters for more context on what these fields are used for. Essentially we will be editing the read, create, and update operations to parse the schema and call the api to make the changes to the state of the resource. Following existing patterns to create this operation will be the best way to implement this. As there are many unique ways to implement a given field we won\u0026rsquo;t get into specifics.\nFor example a field in bigtable google_sheets_options containers two nested properties. range and skip_leading_rows.\n// GoogleSheetsOptions: [Optional] Additional options if sourceFormat is set to GOOGLE_SHEETS. \u0026#34;google_sheets_options\u0026#34;: { Type: schema.TypeList, Optional: true, MaxItems: 1, Description: `Additional options if source_format is set to \u0026#34;GOOGLE_SHEETS\u0026#34;.`, Elem: \u0026amp;schema.Resource{ Schema: map[string]*schema.Schema{ // Range: [Optional] Range of a sheet to query from. Only used when non-empty. // Typical format: !: \u0026#34;range\u0026#34;: { Type: schema.TypeString, Optional: true, Description: `Range of a sheet to query from. Only used when non-empty. At least one of range or skip_leading_rows must be set. Typical format: \u0026#34;sheet_name!top_left_cell_id:bottom_right_cell_id\u0026#34; For example: \u0026#34;sheet1!A1:B20\u0026#34;`, AtLeastOneOf: []string{ \u0026#34;external_data_configuration.0.google_sheets_options.0.skip_leading_rows\u0026#34;, \u0026#34;external_data_configuration.0.google_sheets_options.0.range\u0026#34;, }, }, // SkipLeadingRows: [Optional] The number of rows at the top // of the sheet that BigQuery will skip when reading the data. \u0026#34;skip_leading_rows\u0026#34;: { Type: schema.TypeInt, Optional: true, Description: `The number of rows at the top of the sheet that BigQuery will skip when reading the data. At least one of range or skip_leading_rows must be set.`, AtLeastOneOf: []string{ \u0026#34;external_data_configuration.0.google_sheets_options.0.skip_leading_rows\u0026#34;, \u0026#34;external_data_configuration.0.google_sheets_options.0.range\u0026#34;, }, }, }, }, }, To simplify the implementation management of these fields can be delegated to expanders and flatteners.\nfunc expandGoogleSheetsOptions(configured interface{}) *bigquery.GoogleSheetsOptions { if len(configured.([]interface{})) == 0 { return nil } raw := configured.([]interface{})[0].(map[string]interface{}) opts := \u0026amp;bigquery.GoogleSheetsOptions{} if v, ok := raw[\u0026#34;range\u0026#34;]; ok { opts.Range = v.(string) } if v, ok := raw[\u0026#34;skip_leading_rows\u0026#34;]; ok { opts.SkipLeadingRows = int64(v.(int)) } return opts } func flattenGoogleSheetsOptions(opts *bigquery.GoogleSheetsOptions) []map[string]interface{} { result := map[string]interface{}{} if opts.Range != \u0026#34;\u0026#34; { result[\u0026#34;range\u0026#34;] = opts.Range } if opts.SkipLeadingRows != 0 { result[\u0026#34;skip_leading_rows\u0026#34;] = opts.SkipLeadingRows } return []map[string]interface{}{result} } Add a testcase for the field or extend an existing one # Once your field has been implemented, go to the corresponding test file for your resource and extend it. If your field is updatable it\u0026rsquo;s good practice to have a two step apply to ensure that the field can be updated. You\u0026rsquo;ll notice a lot of our tests have a import state verify directly after apply. These steps are important as they will essentially attempt to import the resource you just provisioned and verify that the field values are consistent with the applied state. Please test all fields you\u0026rsquo;ve added to the provider. It\u0026rsquo;s important for us to ensure all fields are usable and workable.\nAdd documentation for the field to the respective markdown file # See Update handwritten provider documentation for more information. Essentially you will just be opening the corresponding markdown file and adding documentation, likely copied from the rest api to the markdown file. Follow the existing patterns there-in.\nBeta features # When the underlying API of a feature is not final (i.e. a vN version like v1 or v2), is in preview, or the API has no SLO we add it to the google-beta provider rather than the google provider, allowing users to self-select for the stability level they are comfortable with.\nBoth the google and google-beta providers operate off of a shared codebase, including for handwritten code. MMv1 allows us to write Go source files as .go.erb templated source, and renders them as .go files in the downstream repo.\nThe sole generator feature you need to be aware of is a \u0026ldquo;version guard\u0026rdquo;, what is effectively a preprocessor directive implemented using Embedded Ruby (ERB). A version guard is a snippet used across this codebase by convention guarding versioned code on an unless clause in a version check. For example:\nnetworkInterfaces, err := expandNetworkInterfaces(d, config) if err != nil { return nil, fmt.Errorf(\u0026#34;Error creating network interfaces: %s\u0026#34;, err) } \u0026lt;% unless version == \u0026#39;ga\u0026#39; -%\u0026gt; networkPerformanceConfig, err := expandNetworkPerformanceConfig(d, config) if err != nil { return nil, fmt.Errorf(\u0026#34;Error creating network performance config: %s\u0026#34;, err) } \u0026lt;% end -%\u0026gt; In the snippet above, the networkInterfaces field is generally available and is not guarded. The networkPerformanceConfig field is only available at beta, and is guarded by unless version == ga, and the guarded block is terminated by an end statement.\nIf a service includes handwritten resources and mixed features or resources at different versions, the client libraries used by each provider must be switched using guards so that the stability level of the client library matches that of the provider. For example, all handwritten Google Compute Engine (GCE) files have the following guarded import:\n\u0026lt;% if version == \u0026#34;ga\u0026#34; -%\u0026gt; \u0026#34;google.golang.org/api/compute/v1\u0026#34; \u0026lt;% else -%\u0026gt; compute \u0026#34;google.golang.org/api/compute/v0.beta\u0026#34; \u0026lt;% end -%\u0026gt; This is not necessary for beta-only services, or for services that are generally available in their entirety.\nAdding a beta resource # MMv1 doesn\u0026rsquo;t selectively generate files, and any file that is beta-only must have all of its contents guarded. When writing a resource that\u0026rsquo;s available at beta, start with the following snippet:\n\u0026lt;% autogen_exception -%\u0026gt; package google \u0026lt;% unless version == \u0026#39;ga\u0026#39; -%\u0026gt; // Add the implementation of the file here \u0026lt;% end -\u0026gt; This will generate a blank file in the google provider. The resource file, resource test file, and any service or resource specific utility files should be guarded in this way.\nDocumentation should not be guarded. Instead, write it as normal including the following snippet above the first example.\n~\u0026gt; **Warning:** This resource is in beta, and should be used with the terraform-provider-google-beta provider. See [Provider Versions](https://terraform.io/docs/providers/google/guides/provider_versions.html) for more details on beta resources. When registering the resource in provider.go.erb, the entry should be guarded:\n\u0026#34;google_monitoring_dashboard\u0026#34;: resourceMonitoringDashboard(), +\t\u0026lt;% unless version == \u0026#39;ga\u0026#39; -%\u0026gt; +\t\u0026#34;google_project_service_identity\u0026#34;: resourceProjectServiceIdentity(), +\t\u0026lt;% end -%\u0026gt; \u0026#34;google_service_networking_connection\u0026#34;: resourceServiceNetworkingConnection(), If this is a new service entirely, all service-specific entries like client factory initialization should be guarded as well. However, new services should generally be implemented using an alternate engine- either MMv1 or tpgtools/DCL.\nAdding beta field(s) # By contrast to beta resources, adding support for a beta field is much more involved as small snippets of code throughout a resource file must be annotated.\nTo begin with, add the field to the Schema of the resource with guards, i.e.:\n\u0026lt;% unless version == \u0026#39;ga\u0026#39; -%\u0026gt; \u0026#34;network_performance_config\u0026#34;: { Type: schema.TypeList, MaxItems: 1, Optional: true, ForceNew: true, Description: `Configures network performance settings for the instance. If not specified, the instance will be created with its default network performance configuration.`, Elem: \u0026amp;schema.Resource{ Schema: map[string]*schema.Schema{ \u0026#34;total_egress_bandwidth_tier\u0026#34;: { // ... }, }, }, }, \u0026lt;% end -%\u0026gt; Next, implement the d.Get/d.Set calls (for top level fields) or expanders/flatteners for nested fields within guards.\nEven if there are other guarded fields, it\u0026rsquo;s recommended that you add distinct guards per feature- that way, promotion (covered below) will be simpler as you\u0026rsquo;ll only need to remove lines rather that move them around.\nPromoting a beta feature # \u0026ldquo;Promoting\u0026rdquo; a beta feature- making it available in the GA google provider when the underlying feature or service has gone GA- requires removing the version guards placed previously, so that the previously beta-only code is generated in the google provider as well.\nFor all promotions, ensure that you remove the guards in:\nThe documentation for the resource or field The test(s) for the resource or field. For whole resource promotions, you\u0026rsquo;ll generally only need to remove the file-level guards and the guards on the resource registration in provider.go.erb.\nFor field promotions ensure that you remove the guards in:\nThe Resource schema The Resource CRUD methods (for top level fields) The Resource Expanders and Flatteners (for nested fields) When writing a changelog entry for a promotion, write it as if it was a new field or resource, and suffix it with (ga only). For example, if the google_container_cluster resource was promoted to GA in your change:\n\\`\\`\\`release-note:new-resource `google_container_cluster` (ga only) \\`\\`\\` Alternatively, for field promotions, you may use \u0026ldquo;{{service}}: promoted {{field}} in {{resource}} to GA\u0026rdquo;, i.e.\n\\`\\`\\`release-note:enhancement container: promoted `node_locations` field in google_container_cluster` to GA \\`\\`\\` "},{"id":9,"href":"/magic-modules/docs/how-to/add-handwritten-test/","title":"Add a handwritten test","section":"How To","content":" Add a handwritten test # For handwritten resources and generated resources that need to test update, handwritten tests must be added.\nTests are made up of a templated Terraform configuration where unique values like GCE names are passed in as arguments, and boilerplate to exercise that configuration.\nThe test boilerplate effectively does the following:\nRun terraform apply on the configuration, waiting for it to succeed and recording the results in Terraform state Run terraform plan, and fail if Terraform detects any drift Clear the resource from state and run terraform import on it Deeply compare the original state from terraform apply and the terraform import results, returning an error if any values are not identical Destroy all resources in the configuration using terraform destroy, waiting for the destroy command to succeed Call GET on the resource, and fail the test if it is still present Simple Tests # Terraform configurations are stored as string constants wrapped in Go functions like the following:\nfunc testAccComputeFirewall_basic(network, firewall string) string { return fmt.Sprintf(` resource \u0026#34;google_compute_network\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; auto_create_subnetworks = false } resource \u0026#34;google_compute_firewall\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; description = \u0026#34;Resource created for Terraform acceptance testing\u0026#34; network = google_compute_network.foobar.name source_tags = [\u0026#34;foo\u0026#34;] allow { protocol = \u0026#34;icmp\u0026#34; } } `, network, firewall) } For the most part, you can copy and paste a preexisting test case and modify it. For example, the following test case is a good reference:\nfunc TestAccComputeFirewall_noSource(t *testing.T) { t.Parallel() networkName := fmt.Sprintf(\u0026#34;tf-test-firewall-%s\u0026#34;, randString(t, 10)) firewallName := fmt.Sprintf(\u0026#34;tf-test-firewall-%s\u0026#34;, randString(t, 10)) vcrTest(t, resource.TestCase{ PreCheck: func() { testAccPreCheck(t) }, Providers: testAccProviders, CheckDestroy: testAccCheckComputeFirewallDestroyProducer(t), Steps: []resource.TestStep{ { Config: testAccComputeFirewall_noSource(networkName, firewallName), }, { ResourceName: \u0026#34;google_compute_firewall.foobar\u0026#34;, ImportState: true, ImportStateVerify: true, }, }, }) } func testAccComputeFirewall_noSource(network, firewall string) string { return fmt.Sprintf(` resource \u0026#34;google_compute_network\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; auto_create_subnetworks = false } resource \u0026#34;google_compute_firewall\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; description = \u0026#34;Resource created for Terraform acceptance testing\u0026#34; network = google_compute_network.foobar.name allow { protocol = \u0026#34;tcp\u0026#34; ports = [22] } } `, network, firewall) } Update tests # Inside of a test, additional steps can be added in order to transition between Terraform configurations, updating the stored state as it progresses. This allows you to exercise update behaviour. This modifies the flow from before:\nStart with an empty Terraform state For each Config and ImportState pair: Run terraform apply on the configuration, waiting for it to succeed and recording the results in Terraform state Run terraform plan, and fail if Terraform detects any drift Clear the resource from state and run terraform import on it Deeply compare the original state from terraform apply and the terraform import results, returning an error if any values are not identical Destroy all resources in the configuration using terraform destroy, waiting for the destroy command to succeed Call GET on the resource, and fail the test if it is still present For example:\nfunc TestAccComputeFirewall_disabled(t *testing.T) { t.Parallel() networkName := fmt.Sprintf(\u0026#34;tf-test-firewall-%s\u0026#34;, randString(t, 10)) firewallName := fmt.Sprintf(\u0026#34;tf-test-firewall-%s\u0026#34;, randString(t, 10)) vcrTest(t, resource.TestCase{ PreCheck: func() { testAccPreCheck(t) }, Providers: testAccProviders, CheckDestroy: testAccCheckComputeFirewallDestroyProducer(t), Steps: []resource.TestStep{ { Config: testAccComputeFirewall_disabled(networkName, firewallName), }, { ResourceName: \u0026#34;google_compute_firewall.foobar\u0026#34;, ImportState: true, ImportStateVerify: true, }, { Config: testAccComputeFirewall_basic(networkName, firewallName), }, { ResourceName: \u0026#34;google_compute_firewall.foobar\u0026#34;, ImportState: true, ImportStateVerify: true, }, }, }) } func testAccComputeFirewall_basic(network, firewall string) string { return fmt.Sprintf(` resource \u0026#34;google_compute_network\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; auto_create_subnetworks = false } resource \u0026#34;google_compute_firewall\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; description = \u0026#34;Resource created for Terraform acceptance testing\u0026#34; network = google_compute_network.foobar.name source_tags = [\u0026#34;foo\u0026#34;] allow { protocol = \u0026#34;icmp\u0026#34; } } `, network, firewall) } func testAccComputeFirewall_disabled(network, firewall string) string { return fmt.Sprintf(` resource \u0026#34;google_compute_network\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; auto_create_subnetworks = false } resource \u0026#34;google_compute_firewall\u0026#34; \u0026#34;foobar\u0026#34; { name = \u0026#34;%s\u0026#34; description = \u0026#34;Resource created for Terraform acceptance testing\u0026#34; network = google_compute_network.foobar.name source_tags = [\u0026#34;foo\u0026#34;] allow { protocol = \u0026#34;icmp\u0026#34; } disabled = true } `, network, firewall) } Testing Beta Features # If you worked with a beta feature and had to use beta version guards in a handwritten resource or set min_version: beta in a generated resource, you\u0026rsquo;ll want to version guard both the test case and configuration by enclosing them in ERB tags like below. Additionally, if the filename ends in .go, rename it to end in .go.erb.\n\u0026lt;% unless version == \u0026#39;ga\u0026#39; -%\u0026gt; // test case + config here \u0026lt;% end -%\u0026gt; Otherwise, tests using a beta feature are written exactly the same as tests using a GA one. Normally to use the beta provider, it\u0026rsquo;s necessary to specify provider = google-beta, as Terraform maps any resources prefixed with google_ to the google provider by default. However, inside the test framework, the google-beta provider has been aliased as the google provider and that is not necessary.\nNote: You may use version guards to test different configurations between the GA and beta provider tests, but it\u0026rsquo;s strongly recommended that you write different test cases instead, even if they\u0026rsquo;re slightly duplicative.\n"},{"id":10,"href":"/magic-modules/docs/how-to/add-handwritten-datasource/","title":"Add a handwritten datasource","section":"How To","content":" Add a handwritten datasource # Note: only handwritten datasources are currently supported\nDatasources are like terraform resources except they don\u0026rsquo;t create anything. They are simply read-only operations that will expose some sort of values needed for subsequent resource operations. If you\u0026rsquo;re adding a field to an existing datasource, check the Resource section. Everything there will be mostly consistent with the type of change you\u0026rsquo;ll need to make. For adding a new datasource there are 5 steps to doing so.\nCreate a new datasource declaration file and a corresponding test file Add Schema and Read operation implementation Add the datasource to the provider.go.erb index Implement a test which will create and resources and read the corresponding datasource. Add documentation. See: Add documentation for a handwritten data source For creating a datasource based off an existing resource you can make use of the schema directly. Otherwise implementing the schema directly, similar to normal resource creation, is the desired path.\n"},{"id":11,"href":"/magic-modules/docs/how-to/add-handwritten-iam/","title":"Add handwritten IAM resources","section":"How To","content":" Add handwritten IAM resources # Handwritten IAM support is only recommended for resources that cannot be managed using MMv1, including for handwritten resources, due to the need to manage tests and documentation by hand. This guidance goes through the motions of adding support for new handwritten IAM resources, but does not go into the details of the implementation as any new handwritten IAM resources are expected to be exceptional.\nIAM resources are implemented using an IAM framework, where you implement an interface for each parent resource supporting getIamPolicy/setIamPolicy and the associated IAM resources that target that parent resource- _member, _binding, and _policy- are created by the framework.\nTo add support for a new target, create a new file in mmv1/third_party/terraform/utils called iam_{{resource}}.go, and implement the ResourceIamUpdater, newResourceIamUpdaterFunc, iamPolicyModifyFunc, resourceIdParserFunc interfaces from https://github.com/GoogleCloudPlatform/magic-modules/blob/main/mmv1/third_party/terraform/utils/iam.go.erb in public types, alongside a public map[string]*schema.Schema containing all fields referenced in the resource.\nOnce your implementation is complete, add the IAM resources to provider.go inside the START non-generated IAM resources block, creating the concrete resource types using the ResourceIamMember, ResourceIamBinding, and ResourceIamPolicy functions. For example:\n\u0026#34;google_bigtable_instance_iam_binding\u0026#34;: ResourceIamBinding(IamBigtableInstanceSchema, NewBigtableInstanceUpdater, BigtableInstanceIdParseFunc), \u0026#34;google_bigtable_instance_iam_member\u0026#34;: ResourceIamMember(IamBigtableInstanceSchema, NewBigtableInstanceUpdater, BigtableInstanceIdParseFunc), \u0026#34;google_bigtable_instance_iam_policy\u0026#34;: ResourceIamPolicy(IamBigtableInstanceSchema, NewBigtableInstanceUpdater, BigtableInstanceIdParseFunc), Following that, write a test for each resource exercising create and update for both _policy and _binding, and create for _member. No special accommodations are needed for the IAM test compared to a normal Terraform resource test.\nDocumentation for IAM resources is done using single page per target resource, rather than a distinct page for each IAM resource level. As most of the page is standard, you can generally copy and edit an existing handwritten page such as https://github.com/GoogleCloudPlatform/magic-modules/blob/main/mmv1/third_party/terraform/website/docs/r/bigtable_instance_iam.html.markdown to write the documentation.\n"},{"id":12,"href":"/magic-modules/docs/how-to/update-handwritten-documentation/","title":"Update handwritten provider documentation","section":"How To","content":" Update handwritten provider documentation (for handwritten resource or datasource) # Note: If you want to find information about documentation for a generated resource, look at the MMv1 resource documentation page instead. The information on this page will not be relevant for resources that have generated documentation. How provider documentation works # For general information about how provider documentation works, see Provider Documentation. That page contains information about how documentation should be structured and how you can test changes to documentation.\nThis page includes only instructions on how to update the documentation for a handwritten resource or data source, with minimal background info.\nFinding the relevant file # Handwritten documentation is located in the website/docs folder, shown below.\nmmv1/third_party/terraform/website/docs/  guides/   ...  d/   ...  r/   ...  index.html.markdown The subfolder d corresponds to data sources, and r corresponds to resources, and each file inside creates a page in the official provider documentation. For example, if you needed to update existing documentation for the google_compute_instance resource you should search in the r folder for a file with a name starting compute_instance (i.e. the resource name with the provider name removed from the start). The file /docs/r/compute_instance.html.markdown is used to produce the page for the google_compute_instance resource in the official provider documentation.\nMaking changes # After finding the file you need, make the changes required for the issue you are working on.\nTesting your changes # Next, you should test your changes to the file. To do this, you can copy and paste the markdown into the Doc Preview Tool on the Registry website. This will help you identify any malformed markdown and check that it is rendered in the way you expect.\nOnce you are satified, include the markdown changes in your PR in the Magic Modules repo. When the downstream is generated from Magic Modules your handwritten files will be copied into the correct location within the website/docs folder in terraform-provider-google or terraform-provider-google-beta.\n"},{"id":13,"href":"/magic-modules/docs/how-to/add-handwritten-datasource-documentation/","title":"Add documentation for a handwritten data source","section":"How To","content":" Add documentation for a handwritten data source # Note: If you want to find information about documentation for a generated resource, look at the MMv1 resource documentation page instead. The information on this page will not be relevant for resources that have generated documentation. How provider documentation works # For general information about how provider documentation works, see Provider Documentation. That page contains information about how documentation should be structured and how you can test changes to documentation.\nThis page includes only instructions on how to add documentation for a new handwritten data source, with minimal background info.\nFinding the relevant file location # Handwritten documentation is located in the website/docs folder, shown below.\nmmv1/third_party/terraform/website/docs/  guides/   ...  d/   ...  r/   ...  index.html.markdown The subfolder d corresponds to data sources, and inside there is a file for each data source.\nCreating the new markdown file # Next you need to add the file for the new data source\u0026rsquo;s documentation. Create a new file inside the d folder. The filename should be the name of the data source with the google_ prefix removed. For example if you were adding a new data source google_foobar then you would need to create a new file with the name foobar.html.markdown.\nAdding contents # Pages within the documentation need to be consistent and contain the sections that users expect. Below is some guidance about the different sections to include and what their contents should be.\nFrontmatter # The top of the file needs to contain frontmatter, which is used to create the new documentation page\u0026rsquo;s title and manage how the page is linked to in the documentation\u0026rsquo;s sidebar navigation. It it not rendered but it is very important for the new page in the documentation to be generated and available to users.\nYou need to make sure your file\u0026rsquo;s frontmatter includes:\nsubcategory - This sets which section in the left-side navigation menu the new page is categorised into. page_title - This frontmatter is specific to files in the Guides section (/website/docs/guides) but we set it for all markdown files. description - A decription of the page. For example, here is the frontmatter from /website/docs/d/container_cluster.html.markdown (link to generated page):\n--- subcategory: \u0026#34;Kubernetes (Container) Engine\u0026#34; page_title: \u0026#34;Google: google_container_cluster\u0026#34; description: |- Get info about a Google Kubernetes Engine cluster. --- Page title and description # The next section in the markdown file is rendered as the first part of the page body.\nIt should contain:\nthe page title, as an H1 header a description general information about the data source The description can be as long or as short as necessary. The minimum information that\u0026rsquo;s included in this section are links to official documentation and the API reference pages. Other guidance, warnings, or explanations of concepts can be included here. To create pronounced warning or info sections, see the provider documentation page for info.\nFor example, here\u0026rsquo;s the title and opening description of /website/docs/d/cloud_run_locations.html.markdown (link to generated page):\n# google\\_cloud\\_run\\_locations Get Cloud Run locations available for a project. To get more information about Cloud Run, see: * [API documentation](https://cloud.google.com/run/docs/reference/rest/v1/projects.locations) * How-to Guides * [Official Documentation](https://cloud.google.com/run/docs/) Example usage # The next section includes one or more examples showing how a user may use the data source in their Terrform configuration. The examples can be basic and show what the minimum number of arguments are required, or they can be used to demonstrate more complex usage of the data source if necessary.\nFor example, here\u0026rsquo;s the example usage section from /website/docs/d/kms_crypto_key.html.markdown (link to generated page):\n## Example Usage ```hcl data \u0026#34;google_kms_key_ring\u0026#34; \u0026#34;my_key_ring\u0026#34; { name = \u0026#34;my-key-ring\u0026#34; location = \u0026#34;us-central1\u0026#34; } data \u0026#34;google_kms_crypto_key\u0026#34; \u0026#34;my_crypto_key\u0026#34; { name = \u0026#34;my-crypto-key\u0026#34; key_ring = data.google_kms_key_ring.my_key_ring.id } Argument reference # The argument reference section tells user about the fields in the schema which they can set via their Terraform configuration. The fields are listed using bullet points, and each field is marked with whether it is required or optional.\nFor example, this is the argument reference section from /website/docs/d/compute_backend_bucket.html.markdown:\n## Argument Reference The following arguments are supported: * `name` - (Required) Name of the resource. - - - * `project` - (Optional) The ID of the project in which the resource belongs. If it is not provided, the provider project is used. Nested blocks # If the data source contains a nested block we include the name of the nested block in the list of arguments and then link to a dedicated section below that describes all arguments within that block. If there are multiple levels of nesting in a block then this approach should be repeated.\nFor example in /website/docs/d/cloud_identity_group_membership.html.markdown the roles attribute is documented using this approach. To see it in action, view the attribute in the documentation.\nInside the list of arguments there is this entry, which contains a link to a target elsewhere on the page:\n* `roles` - The MembershipRoles that apply to the Membership. Structure is [documented below](#nested_roles). Under the list of arguments there are sections like this that contain an anchor tag that defines the target of the hyperlink above using the name attribute. These sections should be in the same order that the blocks\u0026rsquo; names are listed in the documentation.\n\u0026lt;a name=\u0026#34;nested_roles\u0026#34;\u0026gt;\u0026lt;/a\u0026gt;The `roles` block supports: * `name` - The name of the MembershipRole. One of OWNER, MANAGER, MEMBER. Attribute reference # Attributes are exported values that can be accessed from a data source (or resource) and are not set by the users Terraform configuration. They could be computed values, or values read from the API.\nIf the data source has the same attributes as its equivalent resource in the provider, you can just link to the documentation for the resource. This avoids duplicating information that already exists elsewhere.\nFor example the documentation for the google_storage_bucket data source links to the google_storage_bucket resource documentation (see here)\nIf there isn\u0026rsquo;t an equivalent resource in the provider, or the attributes are different, then document the attributes in a bulleted list as usual. Nested blocks are documented in the way previously described above.\n"},{"id":14,"href":"/magic-modules/docs/getting-started/run-provider-tests/","title":"Run provider tests","section":"Getting Started","content":" Run provider tests locally # Note: If you want to test changes you\u0026rsquo;ve made in Magic Modules, you need to first generate the provider you want to test. Setup # Tests generally assume the following environment variables must be set in order to run tests:\nGOOGLE_PROJECT GOOGLE_CREDENTIALS|GOOGLE_CLOUD_KEYFILE_JSON|GCLOUD_KEYFILE_JSON|GOOGLE_USE_DEFAULT_CREDENTIALS GOOGLE_REGION GOOGLE_ZONE Note that the credentials you provide must be granted wide permissions on the specified project. These tests provision real resources, and require permission in order to do so. Most developers on the team grant their test service account roles/editor or roles/owner on their project. Additionally, to ensure that your tests are performed in a region and zone with wide support for GCP features, GOOGLE_REGION should be set to us-central1 and GOOGLE_ZONE to us-central1-a.\nAdditional variable may be required for other tests, and should get flagged when running them by Go skipping the test and flagging in the output it was skipped, with a skip message explaining why. The most typical extra values required are those required for project creation:\nGOOGLE_ORG GOOGLE_BILLING_ACCOUNT Run unit tests # Unit tests (that is, tests that do not interact with the GCP API) are very fast and you can generally run them all if you have changed any of them:\nmake test Run acceptance tests # You can run tests against the provider you generated in the OUTPUT_PATH location. When running tests, specify which to run using TESTARGS, such as:\n# for ga provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google make testacc TEST=./google TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic\u0026#39; # for beta provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta make testacc TEST=./google-beta TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic\u0026#39; TESTARGS allows you to pass testing flags to go test. The most important is -run, which allows you to limit the tests that get run. There are 2000+ tests, and running all of them takes over 9 hours and requires a lot of GCP quota.\n-run is regexp-like, so multiple tests can be run in parallel by specifying a common substring of those tests (for example, TestAccContainerNodePool to run all node pool tests).\nDebugging tests # You can increase your test verbosity and redirect the output to a log file for analysis. This is often helpful in debugging issues.\n# for ga provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google TF_LOG=TRACE make testacc TEST=./google TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic\u0026#39; \u0026gt; output.log # for beta provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta TF_LOG=TRACE make testacc TEST=./google-beta TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic\u0026#39; \u0026gt; output.log You can also debug tests with Delve:\n# Navigate to the google package within your local GCP Terraform provider Git clone. cd $GOPATH/src/github.com/terraform-providers/terraform-provider-google/google # Execute the dlv command to launch the test. # Note that the --test.run flag uses the same regexp matching as go test --run. TF_ACC=1 dlv test -- --test.v --test.run TestAccComputeRegionBackendService_withCdnPolicy Type \u0026#39;help\u0026#39; for list of commands. (dlv) b google.TestAccComputeRegionBackendService_withCdnPolicy Breakpoint 1 set at 0x1de072b for github.com/terraform-providers/terraform-provider-google/google.TestAccComputeRegionBackendService_withCdnPolicy() ./resource_compute_region_backend_service_test.go:540 (dlv) c === RUN TestAccComputeRegionBackendService_withCdnPolicy \u0026gt; github.com/terraform-providers/terraform-provider-google/google.TestAccComputeRegionBackendService_withCdnPolicy() ./resource_compute_region_backend_service_test.go:540 (hits goroutine(7):1 total:1) (PC: 0x1de072b) 535: }, 536: }, 537: }) 538: } 539: =\u0026gt; 540: func TestAccComputeRegionBackendService_withCdnPolicy(t *testing.T) { 541: t.Parallel() 542: 543: var svc compute.BackendService 544: resource.Test(t, resource.TestCase{ 545: PreCheck: func() { testAccPreCheck(t) }, (dlv) Testing with different terraform versions # Tests will use whatever version of the terraform binary is found on your path. To test with multiple versions of terraform core, you must run the tests multiple times with different versions. You can use tfenv to manage your system terraform versions.\n"},{"id":15,"href":"/magic-modules/docs/getting-started/use-built-provider/","title":"Use built provider","section":"Getting Started","content":" Use built provider locally # Note: If you want to test changes you\u0026rsquo;ve made in Magic Modules, you need to first generate the provider you want to test. Sometimes, for example for manual testing, you may want to build the provider from source and use it with terraform.\nDeveloper Overrides # Note: Developer overrides are only available in Terraform v0.14 and later. By default Terraform will download providers from the public Registry, but there are several ways to override this behaviour and use providers from other sources. HashiCorp recommends developers use development overrides when debugging code changes in a provider.\nDeveloper overrides are defined in an explicit CLI configuration file. They allow you to use locally-built versions of providers without needing to change your Terraform configuration files or needing to run terraform init. There are also other features such as explicit warnings when overrides are in effect.\nIn the sections below we describe how to create a Terraform CLI configuration file, and how to make the CLI use the file via an environment variable.\nSetup # Choose your architecture below.\nMac (ARM64 and AMD64), Linux AMD64 First, you need to find the location where built provider binaries are created. To do this, run this command and make a note of the path value:\necho $GOPATH Next, create an empty configuration file. This could be in your $HOME directory or in a project directory; location does not matter. The extension .tfrc is required but the file name can be whatever you choose.\n# create an empty file touch ~/tf-dev-override.tfrc # open the file with a text editor of your choice, e.g: vi ~/tf-dev-override.tfrc Open the empty file with a text editor and paste in these contents:\nprovider_installation { # Developer overrides will stop Terraform from downloading the listed # providers their origin provider registries. dev_overrides { \u0026#34;hashicorp/google\u0026#34; = \u0026#34;\u0026lt;REPLACE-ME\u0026gt;/bin\u0026#34; \u0026#34;hashicorp/google-beta\u0026#34; = \u0026#34;\u0026lt;REPLACE-ME\u0026gt;/bin\u0026#34; } # For all other providers, install them directly from their origin provider # registries as normal. If you omit this, Terraform will _only_ use # the dev_overrides block, and so no other providers will be available. direct {} } Edit the file to replace \u0026lt;REPLACE-ME\u0026gt; with the output you saved from the first echo command, making sure to keep /bin at the end of the path. The full path is required and environment variables cannot be used. For example, /Users/MyUserName/go/bin is a valid path for a user called MyUserName.\nFinally, save the file.\nWindows (Vista and above) First, you need to find the location where built provider binaries are created. To do this, run this command and make a note of the path value:\necho %GOPATH% Next, create an empty configuration file. The location does not matter and could be in your home directory or a specific project directory. The extension .tfrc is required but the file name can be whatever you choose.\nIf you are unsure where to put the file, put it in the %APPDATA% directory (use $env:APPDATA in PowerShell to find its location on your system).\n# create an empty file type nul \u0026gt; \u0026#34;$($env:APPDATA)\\tf-dev-override.tfrc\u0026#34; # open the file with a text editor of your choice, e.g: notepad \u0026#34;$($env:APPDATA)\\tf-dev-override.tfrc\u0026#34; Open the empty file with a text editor and paste in these contents:\nprovider_installation { # Developer overrides will stop Terraform from downloading the listed # providers their origin provider registries. dev_overrides { \u0026#34;hashicorp/google\u0026#34; = \u0026#34;\u0026lt;REPLACE-ME\u0026gt;\\bin\u0026#34; \u0026#34;hashicorp/google-beta\u0026#34; = \u0026#34;\u0026lt;REPLACE-ME\u0026gt;\\bin\u0026#34; } # For all other providers, install them directly from their origin provider # registries as normal. If you omit this, Terraform will _only_ use # the dev_overrides block, and so no other providers will be available. direct {} } Edit the file to replace \u0026lt;REPLACE-ME\u0026gt; with the output you saved from the first echo command, making sure to keep \\bin at the end of the path. The full path is required and environment variables cannot be used. For example, C:\\Users\\MyUserName\\go\\bin is a valid path for a user called MyUserName.\nFinally, save the file.\nThis CLI configuration file you created in the steps above will allow Terraform to automatically use the binaries generated by the make build commands in the terraform-provider-google and terraform-provider-google-beta repositories instead of downloading the latest versions. All other providers will continue to be downloaded from the public Registry as normal.\nBuild provider # # ga provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google make build # beta provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta make build Using Terraform CLI developer overrides # To make Terraform use the configuration file you created, you need to set the TF_CLI_CONFIG_FILE environment variable to be a string containing the path to the configuration file (see the documentation here). The path can be either a relative or absolute path.\nAssuming that a configuration file was created at ~/tf-dev-override.tfrc, you can either export the environment variable or set it explicitly for each terraform command:\n# either export the environment variable for your session export TF_CLI_CONFIG_FILE=\u0026#34;~/tf-dev-override.tfrc\u0026#34; # OR, set the environment variable value per command TF_CLI_CONFIG_FILE=\u0026#34;~/tf-dev-override.tfrc\u0026#34; terraform plan To check that the developer override is working, run a terraform plan command and look for a warning near the start of the terminal output that looks like the example below. It is not necessary to run the terraform init command to use development overrides.\n Warning: Provider development overrides are in effect   The following provider development overrides are set in the CLI configuration:  - hashicorp/google in /Users/MyUserName/go/bin  - hashicorp/google-beta in /Users/MyUserName/go/bin   The behavior may therefore not match any released version of the provider and applying  changes may cause the state to become incompatible with published releases. Note: Developer overrides work without you needing to alter your Terraform configuration in any way. Download production providers # To stop using developer overrides, unset the TF_CLI_CONFIG_FILE environment variable or stop setting it in the commands you are executing.\nThis will then let Terraform resume normal behaviour of pulling published provider versions from the public Registry. Any version constraints in your Terraform configuration will come back into effect. Also, you may need to run terraform init to download the required version of the provider into your project directory if you haven\u0026rsquo;t already.\nAlternative: using a global CLI configuration file # If you do not want to use the TF_CLI_CONFIG_FILE environment variable, as described above, you can instead create a global version of the CLI configuration file. This configuration will be used automatically by Terraform. To do this, follow the guidance in the official documentation.\nIn this scenario you will need to remember to edit this file to swap between using developer overrides and using the production provider versions.\nPossible problems # Filesystem mirrors (particularly \u0026ldquo;implicit filesystem mirrors\u0026rdquo;) are used automatically by Terraform, so can interfere with the expected behaviour of Terraform if you\u0026rsquo;re not aware they\u0026rsquo;re present.\nTo stop using the filesystem mirror, you can run:\nrm -rf ~/.terraform.d/plugins/registry.terraform.io/hashicorp/ Another way to debug this is to run a Terraform command with the TF_LOG environment variable set to TRACE . Then, look for a log line similar to the below:\n[TRACE] getproviders.SearchLocalDirectory: found registry.terraform.io/hashicorp/google vX.X.X for darwin_arm64 at /Users/MyUserName/.terraform.d/plugins/registry.terraform.io/hashicorp/google/xxx More information # Filesystem mirrors # An alternative to developer overrides is to use filesystem mirrors, where Terraform can use locally built providers or published providers that you have downloaded to your local disk. More information about this approach is in the expandable section below.\nMore information Filesystem mirrors can used explicitly or implicitly by Terraform. Explicit filesystem mirrors can be defined via the CLI configuration file. In contrast, once implicit filesystem mirrors are created by a user they are discovered and used by Terraform automatically.\nFilesystem mirrors require providers\u0026rsquo; files to be saved with specific paths for them to work correctly. To help with this, you can use the terraform providers mirror command to download a published provider to your local filesystem with the required file path.\nImplied filesystem mirrors require manual cleanup if you want to revert back to using providers downloaded from the public Registry, and if an implied filesystem mirror is in place that a user is unaware of it can lead to confusing behaviour that is hard to debug. Other disadvantages compared to developer overrides include:\nNo warning in terminal output letting you know when your local files are in use. Need to set a version number for your local version of the provider which is compatible with your Terraform configuration\u0026rsquo;s version constraints Setup and cleanup required each time you swap to and from using them "},{"id":16,"href":"/magic-modules/docs/getting-started/contributing/","title":"Contributing","section":"Getting Started","content":" General contributing steps # Fork Magic Modules repository into your GitHub account if you haven\u0026rsquo;t done before.\nCheck the issue tracker to see whether your feature has already been requested.\nif there\u0026rsquo;s an issue and it\u0026rsquo;s already has a dedicated assignee, it indicates that someone may have already started to work on a solution. otherwise, you\u0026rsquo;re welcome to work on the issue. Check whether the resource you would like to work on already exists in the providers (google / google-beta or check the website).\nIf it exists, check the header of the downstream file to identify the type of tools used to generate the resource. For some resources, the code file, the test file and the documentation file may not be generated via the same tools. Generated resources like google_compute_address can be identified by looking in their Go source for an AUTO GENERATED CODE header as well as a Type. \u0026ldquo;Generated resources\u0026rdquo; typically refers to just the MMv1 type, and DCL type resources are considered \u0026ldquo;DCL-based\u0026rdquo;. (Currently DCL-related contribution are not supported) Handwritten resources like google_container_cluster can be identified if they have source code present under the mmv1/third_party/terraform/resources folder or by the absence of the AUTO GENERATED CODE header in their Go source. If not, decide which tool you would like to use to implement the resource. MMv1 is strongly preferred over handwriting the resource unless the resource can not be generated. Currently, only handwritten datasources are supported. Make the actual code change.\nThe How To section will guide you to the detailed instructions on how to make your change. Generate the providers that include your change.\nRun provider tests locally that are relevant to the change you made. (Testing the PR locally and pushing the commit to the PR only after the tests pass locally may significantly reduce back-and-forth in review.)\nPush your changes to your magic-modules repo fork and send a pull request from that branch to the main branch on magic-modules. A reviewer will be assigned automatically to your PR.\nWait until the the modules magician to generate downstream diff (which should take about 15 mins after creating the PR) to make sure all changes are generated correctly in downstream repos.\nWait for the VCR test results. Get to know general workflow for VCR tests 1. You submit your change. 1. The recorded tests are ran against your changes by the `modular-magician`. Tests will fail if: 1. Your PR has changed the HTTP request values sent by the provider 1. Your PR does not change the HTTP request values, but fails on the values returned in an old recording 1. The recordings are out of sync with the merge-base of your PR, and an unrelated contributor's change has caused a false positive 1. The `modular-magician` will leave a message indicating the number of passing and failing VCR tests. If there is a failure, the `modular-magician` user will leave a message indicating the \u0026quot;`Triggering VCR tests in RECORDING mode for the following tests that failed during VCR:`\u0026quot; marking which tests failed. 1. If a test does not appear related, it probably isn't! 1. The `modular-magician` will kick off a second test run targeting only the failed tests, this time hitting the live GCP APIs. If there are tests that fail at this point, a message stating `Tests failed during RECORDING mode:` will be left indicating the tests. 1. If a test that appears to be related to your change has failed here, it's likely your change has introduced an issue. You can view the debug logs for the test by clicking the \u0026quot;view\u0026quot; link beside the test case to attempt to debug what's going wrong. 1. If a test appears to be completely unrelated has failed, it's possible that a GCP API has changed in a way that broke the provider or our environment capped on a quota. Where possible, take a look at the logs and see if you can figure out what needs to be fixed related to your change. The false positive rate on these tests is extremely high between changes in the API, Cloud Build bugs, and eventual consistency issues in test recordings so we don\u0026rsquo;t expect contributors to wholly interpret the results- that\u0026rsquo;s the responsibility of your reviewer.\nIf your assigned reviewers does not reply / review within a week, gently ping them on github.\nAfter your PR is merged, it will be released to customers in around a week or two.\n"},{"id":17,"href":"/magic-modules/docs/getting-started/provider-documentation/","title":"Provider documentation","section":"Getting Started","content":" Provider documentation # The provider is documented on HashiCorp\u0026rsquo;s Terraform Registry, which includes information about individual resources and datasources, and includes guides to help users configure or upgrade the provider in their projects.\nThis document includes details about how provider documentation is used by the Terraform Registry, how it is made in the Magic Modules repo, and tools you can use when editing documentation.\nThere are other pages under How To that describe how to approach making additions to the documentation.\nHow documentation is used by the Terraform Registry # The provider\u0026rsquo;s documentation is rendered in the Terraform Registry using markdown files that are packaged into each release. The Registry allows users to browse past versions of the documentation, for example the documentation for v3.0.0.\nThere are 4 types of documentation page. There\u0026rsquo;s the index page, documentation for resources, documentation for data sources, and finally guide pages.\nFor the Registry to successfully render documentation page, the markdown files in each provider release need to follow some requirements, described below.\nDirectory structure # Files need to be saved in a specific directory.\nmmv1/third_party/terraform/website/docs/  guides/   ...  d/   ...  r/   ...  index.html.markdown Note that the Google provider uses a legacy version of this requirement - a website/docs/ folder.\nYAML frontmatter # Each file must include specific YAML frontmatter.\nsubcategory - for resource/data source pages - determines where the link to the page is located in the left-side navigation. page_title - for guide pages - sets the page title (as there isn\u0026rsquo;t a resource to name it after). Here\u0026rsquo;s an example. What information documentation needs to inlude # HashiCorp advice is to include these sections:\nTitle and description Example Usage section Argument Reference section Attribute Reference section In the Google provider we also include:\nTimeouts, describing configurable timeouts for a resource: see example Import, how to import a resource into Terraform state: see example User Project Overrides, whether or not direct user project overrides are supported: see example How do you test documentation changes? # You can copy and paste markdown into the Registry\u0026rsquo;s Doc Preview Tool to see how it will be rendered.\nThere currently isn\u0026rsquo;t a way to preview how frontmatter will be used to create the left-side navigation menu.\nWhat formatting is available # You can expect markdown to be rendered in a similar way to READMEs in GitHub. When in doubt, you can test how some markdown will be rendered using the testing tool in the Doc Preview Tool mentioned above.\nSomething useful to be aware of are callouts, that allow blue, yellow and red (warning) sections to be used for important information. To see how they\u0026rsquo;re rendered, paste the markdown below into the Doc Preview Tool.\n-\u0026gt; **Note** This callout is blue ~\u0026gt; **Note** This callout is yellow !\u0026gt; **Warning** This callout is red How to contribute to the provider documentation # Handwritten documentation # Terraform Provider Google (TPG) contains handwritten documentation for handwritten resources and data sources. For guidance on updating handwritten documentation, see:\nUpdate handwritten provider documentation Add documentation for a handwritten data source Generated documentation (mmv1) # The majority of resources in TPG are generated, and the information used to generate provider code is also used to generate documentation. For information about how documentation is generated, see:\nUpdate MMv1 resource documentation "},{"id":18,"href":"/magic-modules/docs/reference/api-yaml-resource/","title":"api.yaml resource ","section":"Reference","content":"FORCE MENU RENDER\n"},{"id":19,"href":"/magic-modules/docs/reference/terraform-yaml-resource/","title":"terraform.yaml resource ","section":"Reference","content":"FORCE MENU RENDER\n"}]