[{"id":0,"href":"/magic-modules/document/add-documentation/","title":"Add documentation","section":"Document","content":"Add documentation# Documentation is autogenerated based on the resource and [field(https://googlecloudplatform.github.io/magic-modules/develop/add-fields/] configurations. This page describes how to add documentation to resources and fields.\nFor more information about types of resources and the generation process overall, see How Magic Modules works.\nBefore you begin# Complete the steps in Set up your development environment to set up your environment and your Google Cloud project. Ensure that your magic-modules, terraform-provider-google, and terraform-provider-google-beta repositories are up to date. cd ~/magic-modules git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull Add documentation# MMv1 To preview the documentation:\nGenerate the providers Copy and paste the generated documentation into the Hashicorp Registry\u0026rsquo;s Doc Preview Tool to see how it is rendered. Handwritten Add or modify documentation files# Open the resource documentation in magic-modules/third_party/terraform/website/docs/r/ using an editor of your choice. The name of the file is the name of the resource without a google_ prefix. For example, for google_compute_instance, the file is called compute_instance.html.markdown Modify the documentation as needed according to Handwritten documentation style guide. Generate the providers Copy and paste the generated documentation into the Hashicorp Registry\u0026rsquo;s Doc Preview Tool to see how it is rendered. What\u0026rsquo;s next?# Add custom resource code Add tests Run tests "},{"id":1,"href":"/magic-modules/test/test/","title":"Add resource tests","section":"Test","content":"Add resource tests# This page describes how to add tests to a new resource in the google or google-beta Terraform provider.\nThe providers have two basic types of tests:\nUnit tests: test specific functions thoroughly. Unit tests do not interact with GCP APIs. Acceptance tests (aka VCR tests, or create and update tests): test that resources interact as expected with the APIs. Acceptance tests interact with GCP APIs, but should only test the provider\u0026rsquo;s behavior in constructing the API requests and parsing the responses. Acceptance tests are also called \u0026ldquo;VCR tests\u0026rdquo; because they use go-vcr to record and play back HTTP requests. This allows tests to run more quickly on PRs because the resources don\u0026rsquo;t actually need to be created, updated, or destroyed by the live API.\nFor more information about testing, see the official Terraform documentation.\nBefore you begin# Determine whether your resources is using MMv1 generation or handwritten. If you are not adding tests to an in-progress PR, ensure that your magic-modules, terraform-provider-google, and terraform-provider-google-beta repositories are up to date. cd ~/magic-modules git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull Add unit tests# A unit test verifies functionality that is not related to interactions with the API, such as diff suppress functions, validation functions, CustomizeDiff functions, and so on.\nUnit tests should be added to the appropriate folder in magic-modules/mmv1/third_party/terraform/services in the file called resource_PRODUCT_RESOURCE_test.go. (You may need to create this file if it does not already exist. Replace PRODUCT with the product name and RESOURCE with the resource name; it should match the name of the generated resource file.)\nUnit tests should be named like TestFunctionName - for example, TestDiskImageDiffSuppress would contain tests for the DiskImageDiffSuppress function.\nExample:\nfunc TestSignatureAlgorithmDiffSuppress(t *testing.T) { cases := map[string]struct { Old, New string ExpectDiffSuppress bool }{ \u0026#34;ECDSA_P256 equivalent\u0026#34;: { Old: \u0026#34;ECDSA_P256_SHA256\u0026#34;, New: \u0026#34;EC_SIGN_P256_SHA256\u0026#34;, ExpectDiffSuppress: true, }, // Additional cases excluded for brevity } for tn, tc := range cases { if signatureAlgorithmDiffSuppress(\u0026#34;signature_algorithm\u0026#34;, tc.Old, tc.New, nil) != tc.ExpectDiffSuppress { t.Errorf(\u0026#34;bad: %s, %q =\u0026gt; %q expect DiffSuppress to return %t\u0026#34;, tn, tc.Old, tc.New, tc.ExpectDiffSuppress) } } }Add a create test# A create test is an acceptance test that creates the target resource and immediately destroys it.\nNote: All resources should have a \u0026ldquo;basic\u0026rdquo; create test, which uses the smallest possible number of fields. Additional create tests can be used to ensure all fields on the resource are used in at least one test.\nMMv1 Add an entry to your RESOURCE_NAME.yaml file\u0026rsquo;s examples. The fields listed here are the most commonly-used. For a comprehensive reference, see MMv1 resource reference: examples ↗.\nexamples: # name must correspond to a configuration file that you\u0026#39;ll create in the next step. # The name should include the product name, resource name, and a basic description # of the test. This will be used to generate the test name and the documentation # header. - name: \u0026#34;PRODUCT_RESOURCE_basic\u0026#34; # primary_resource_id will be used for the Terraform resource id in the configuration file. primary_resource_id: \u0026#34;example\u0026#34; # vars contains key/value pairs of variables to inject into the configuration file. # These can be referenced in the configuration file as a key inside `{{$.Vars}}`. # All resource IDs (even for resources not under test) should be declared # with variables that contain a `-` or `_`; this will ensure that, in tests, # the resources are created with a `tf-test` prefix to allow automatic cleanup # of dangling resources and a random suffix to avoid name collisions. vars: network_name: \u0026#34;example-network\u0026#34; # test_vars_overrides contains key/value pairs of literal overrides for # variables used in tests. This can be used to call functions to # generate or determine a variable\u0026#39;s value – for example, bootstrapping # a shared network for your product to avoid test failures due to limits # on the default network. test_vars_overrides: network_name: \u0026#39;acctest.BootstrapSharedServiceNetworkingConnection(t, \u0026#34;PRODUCT-RESOURCE-network-config\u0026#34;)\u0026#39; # Set min_version: beta if the resource is not beta-only and any beta-only fields are being tested. min_version: beta Create a .tf.tmpl file in mmv1/templates/terraform/examples/. The name of the file should match the name of the example created in the previous step. For example, PRODUCT_RESOURCE_basic.tf.tmpl.\nIn that file, write the Terraform configuration for your test. This should include all of the required dependencies. For example, google_compute_subnetwork has a dependency on google_compute_network:\nresource \u0026#34;google_compute_subnetwork\u0026#34; \u0026#34;{{$.PrimaryResourceId}}\u0026#34; { name = \u0026#34;{{index $.Vars \u0026#34;subnetwork_name\u0026#34;}}\u0026#34; ip_cidr_range = \u0026#34;10.1.0.0/16\u0026#34; region = \u0026#34;us-central1\u0026#34; network = google_compute_network.network.name } resource \u0026#34;google_compute_network\u0026#34; \u0026#34;network\u0026#34; { name = \u0026#34;{{index $.Vars \u0026#34;network_name\u0026#34;}}\u0026#34; auto_create_subnetworks = false } If the resource or the example is beta-only:\nAdd provider = google-beta to every resource in the file. Handwritten This section assumes you\u0026rsquo;ve used the Add a resource guide to create your handwritten resource, and you have a working MMv1 config.\nNote: If not, you can create one now, or skip this guide and construct the test by hand. Writing tests by hand can sometimes be a better option if there is a similar test you can copy from.\nAdd the test in MMv1. Repeat for all the create tests you will need. Generate the beta provider. From the beta provider, copy and paste the generated *_generated_test.go file into the appropriate service folder inside magic-modules/mmv1/third_party/terraform/services as a new file call *_test.go. Modify the tests as needed. Replace all occurrences of github.com/hashicorp/terraform-provider-google-beta/google-beta with github.com/hashicorp/terraform-provider-google/google Remove the comments at the top of the file. Remove the Example suffix from all function names. If beta-only fields are being tested, do the following: Change the file suffix to .go.tmpl Wrap each beta-only test in a separate version guard: {{- if ne $.TargetVersionName \u0026quot;ga\u0026quot; -}}...{{- else }}...{{- end }} In each beta-only test, ensure that the TestCase sets ProtoV5ProviderFactories: acctest.ProtoV5ProviderBetaFactories(t) In each beta-only test, ensure that all Terraform resources in all configs have provider = google-beta set Add an update test# An update test is an acceptance test that creates the target resource and then makes updates to fields that are updatable. Updatable fields are fields that can be updated without recreating the entire resource; that is, they are not marked immutable in MMv1 or ForceNew in handwritten code.\nNote: All updatable fields must be covered by at least one update test. In most cases, only a single update test is needed to test all fields at once.\nMMv1 Generate the beta provider. From the beta provider, copy and paste the generated *_generated_test.go file into the appropriate service folder inside magic-modules/mmv1/third_party/terraform/services as a new file call *_test.go. Using an editor of your choice, delete the *DestroyProducer function, and all but one test. The remaining test should be the \u0026ldquo;full\u0026rdquo; test, or if there is no \u0026ldquo;full\u0026rdquo; test, the \u0026ldquo;basic\u0026rdquo; test. This will be the starting point for your new update test. Modify the TestAcc* test function to support updates. Change the suffix of the test function to _update. Copy the 2 TestStep blocks and paste them immediately after, so that there are 4 total test steps. Change the suffix of the first Config value to _full (or _basic). Change the suffix of the second Config value to _update. Add ConfigPlanChecks to the update step of the test to ensure the resource is updated in-place. The resulting test function would look similar to this: import \u0026#34;github.com/hashicorp/terraform-plugin-testing/plancheck\u0026#34; func TestAccPubsubTopic_update(t *testing.T) { ... acctest.VcrTest(t, resource.TestCase{ ... Steps: []resource.TestStep{ { Config: testAccPubsubTopic_full(...), }, { ... }, { Config: testAccPubsubTopic_update(...), ConfigPlanChecks: resource.ConfigPlanChecks{ PreApply: []plancheck.PlanCheck{ plancheck.ExpectResourceAction(\u0026#34;google_pubsub_topic.foo\u0026#34;, plancheck.ResourceActionUpdate), }, }, }, { ... }, }, }) } Modify the testAcc* Terraform template function to support updates. Copy the template function and paste it immediately after so that there are 2 template functions. Change the suffix of the first template function to _full (or _basic). Change the suffix of the second template function to _update. The resulting template functions would look similar to this: func testAccPubsubTopic_full(...) string { ... } func testAccPubsubTopic_update(...) string { ... } Modify the test as needed. Replace all occurrences of github.com/hashicorp/terraform-provider-google-beta/google-beta with github.com/hashicorp/terraform-provider-google/google Modify the template function ending in _update so that updatable fields are changed or removed. This may require additions to the context map in the test function. Remove the comments at the top of the file. If beta-only fields are being tested, do the following: Change the file suffix to .go.tmpl Wrap each beta-only test in a separate version guard: {{- if ne $.TargetVersionName \u0026quot;ga\u0026quot; -}}...{{- else }}...{{- end }} In each beta-only test, ensure that the TestCase sets ProtoV5ProviderFactories: acctest.ProtoV5ProviderBetaFactories(t) In each beta-only test, ensure that all Terraform resources in all configs have provider = google-beta set Handwritten Using an editor of your choice, open the existing *_test.go or *_test.go.tmpl file in the appropriate service folder inside magic-modules/mmv1/third_party/terraform/services which contains your create tests. Copy the TestAcc* test function for the existing \u0026ldquo;full\u0026rdquo; test. If there is no \u0026ldquo;full\u0026rdquo; test, use the \u0026ldquo;basic\u0026rdquo; test. This will be the starting point for your new update test. Modify the test function to support updates. Change the suffix of the test function to _update. Copy the 2 TestStep blocks and paste them immediately after, so that there are 4 total test steps. Change the suffix of the second Config value to _update. Add ConfigPlanChecks to the update step of the test to ensure the resource is updated in-place. The resulting test function would look similar to this: import \u0026#34;github.com/hashicorp/terraform-plugin-testing/plancheck\u0026#34; func TestAccPubsubTopic_update(t *testing.T) { ... acctest.VcrTest(t, resource.TestCase{ ... Steps: []resource.TestStep{ { Config: testAccPubsubTopic_full(...), }, { ... }, { Config: testAccPubsubTopic_update(...), ConfigPlanChecks: resource.ConfigPlanChecks{ PreApply: []plancheck.PlanCheck{ plancheck.ExpectResourceAction(\u0026#34;google_pubsub_topic.foo\u0026#34;, plancheck.ResourceActionUpdate), }, }, }, { ... }, }, }) } Add a Terraform template function to support updates. Copy the full (or basic) testAcc* template function. Change the suffix of the new template function to _update. The new template function would look similar to this: func testAccPubsubTopic_update(...) string { ... } Modify the test as needed. Modify the new template function so that updatable fields are changed or removed. This may require additions to the context map in the test function. Remove the comments at the top of the file. If beta-only fields are being tested, do the following: Change the file suffix to .go.tmpl Wrap each beta-only test in a separate version guard: {{- if ne $.TargetVersionName \u0026quot;ga\u0026quot; -}}...{{- else }}...{{- end }} In each beta-only test, ensure that the TestCase sets ProtoV5ProviderFactories: acctest.ProtoV5ProviderBetaFactories(t) In each beta-only test, ensure that all Terraform resources in all configs have provider = google-beta set Bootstrap API resources# Most acceptance tests run in a the default org and default test project, which means that they can conflict for quota, resource namespaces, and control over shared resources. You can work around these limitations with \u0026ldquo;bootstrapped\u0026rdquo; resources.\nCryptoKeys# There are a few functions provided for bootstrapping CryptoKeys, depending on your needs.\nBootstrapKMSKeyWithPurposeInLocationAndName(t *testing.T, purpose, locationID, keyShortName string) BootstrapKMSKeyWithPurposeInLocation(t *testing.T, purpose, locationID string) Uses a default key name based on the purpose. BootstrapKMSKeyWithPurpose(t *testing.T, purpose string) Uses global location and a key name based on the purpose. BootstrapKMSKeyInLocation(t *testing.T, locationID string) Uses ENCRYPT_DECRYPT for the purpose and the corresponding key name. BootstrapKMSKey(t *testing.T) Uses global location, ENCRYPT_DECRYPT for the purpose, and the corresponding key name for that purpose. Example usage:\nMMv1 examples: - name: service_resource_basic primary_resource_id: example vars: kms_key_name: \u0026#39;kms-key\u0026#39; test_vars_overrides: kms_key_name: \u0026#39;acctest.BootstrapKMSKey(t).CryptoKey.Name\u0026#39; Handwritten func TestAccProductResource_update(t *testing.T) { t.Parallel() context := map[string]interface{}{ \u0026#34;kms\u0026#34;: acctest.BootstrapKMSKey(t).CryptoKey.Name, // other variables } // rest of test } IAM resources# Specify member/role pairs that should always exist. {project_number} will be replaced with the default project\u0026rsquo;s project number. {organization_id} will be replaced with the \u0026ldquo;target\u0026rdquo; test organization\u0026rsquo;s ID – we don\u0026rsquo;t modify IAM in the main test org to avoid accidentally locking ourselves out.\nPermissions attached to resources created in a test should instead be provisioned with standard terraform resources.\nExample usage:\nMMv1 # Project-level IAM examples: - name: service_resource_basic primary_resource_id: example bootstrap_iam: - member: \u0026#34;serviceAccount:service-{project_number}@gcp-sa-healthcare.iam.gserviceaccount.com\u0026#34; role: \u0026#34;roles/bigquery.dataEditor\u0026#34;# Org-level IAM examples: - name: service_resource_basic primary_resource_id: example bootstrap_iam: - member: \u0026#34;serviceAccount:service-org-{organization_id}@gcp-sa-osconfig.iam.gserviceaccount.com\u0026#34; role: \u0026#34;roles/osconfig.serviceAgent\u0026#34; test_env_vars: org_id: ORG_TARGET Handwritten // Project-level IAM import ( \u0026#34;github.com/hashicorp/terraform-provider-google-beta/google-beta/acctest\u0026#34; ) func TestAccProductResource_update(t *testing.T) { t.Parallel() acctest.BootstrapIamMembers(t, []acctest.IamMember{ { Member: \u0026#34;serviceAccount:service-{project_number}@gcp-sa-pubsub.iam.gserviceaccount.com\u0026#34;, Role: \u0026#34;roles/cloudkms.cryptoKeyEncrypterDecrypter\u0026#34;, }, }) // rest of test }// Org-level IAM import ( \u0026#34;github.com/hashicorp/terraform-provider-google-beta/google-beta/acctest\u0026#34; \u0026#34;github.com/hashicorp/terraform-provider-google-beta/google-beta/envvar\u0026#34; ) func TestAccProductResource_update(t *testing.T) { t.Parallel() acctest.BootstrapIamMembers(t, []acctest.IamMember{ { Member: \u0026#34;serviceAccount:service-org-{organization_id}@gcp-sa-osconfig.iam.gserviceaccount.com\u0026#34;, Role: \u0026#34;roles/osconfig.serviceAgent\u0026#34;, }, }) context := map[string]string{ \u0026#34;org_id\u0026#34;: envvar.GetTestOrgTargetFromEnv(t), } // rest of test } Networks# Bootstrapping networks can be useful for two reasons:\nResources like google_service_networking_connection use a consumer network and create a complementing tenant network which we don\u0026rsquo;t control. These tenant networks never get cleaned up and they can accumulate to the point where a limit is reached for the organization. By reusing a consumer network across test runs, we can reduce the number of tenant networks that are needed. (Googlers: See b/146351146 for more context.) Bootstrap networks used in tests (gke clusters, dataproc clusters\u0026hellip;) to limit traffic to the default network (preventing conflicts). When creating a bootstrapped network in a test, you can specify an identifier. Note that if the network is being used for a google_service_networking_connection, you should use an identifier unique to the test to avoid race conditions where multiple tests attempt to modify the connection at once.\nYou can also bootstrap one or more subnetworks within a bootstrapped network if necessary, to avoid subnetwork-level quotas and race conditions.\nExample usage:\nMMv1 examples: - name: service_resource_basic primary_resource_id: example vars: network_name: \u0026#39;default\u0026#39; subnetwork_name: \u0026#39;default\u0026#39; test_vars_overrides: network_name: \u0026#39;acctest.BootstrapSharedTestNetwork(t, \u0026#34;network-identifier\u0026#34;)\u0026#39; subnetwork_name: \u0026#39;acctest.BootstrapSubnet(t, \u0026#34;subnet-identifier\u0026#34;, acctest.BootstrapSharedTestNetwork(t, \u0026#34;network-identifier\u0026#34;))\u0026#39; Handwritten func TestAccProductResource_update(t *testing.T) { t.Parallel() networkName := subnetName := context := map[string]interface{}{ \u0026#34;network_name\u0026#34;: acctest.BootstrapSharedTestNetwork(t, \u0026#34;network-identifier\u0026#34;), \u0026#34;subnetwork_name\u0026#34;: acctest.BootstrapSubnet(t, \u0026#34;subnet-identifier\u0026#34;, acctest.BootstrapSharedTestNetwork(t, \u0026#34;network-identifier\u0026#34;)), // other variables } // rest of test } Create test projects# If bootstrapping doesn\u0026rsquo;t work or isn\u0026rsquo;t an option for some reason, you can also work around project quota issues or test project-global resources by creating a new test project. You will also need to enable any necessary APIs and wait for their enablement to propagate.\nimport ( \u0026#34;testing\u0026#34; \u0026#34;github.com/hashicorp/terraform-plugin-testing/helper/resource\u0026#34; \u0026#34;github.com/hashicorp/terraform-provider-google-beta/google-beta/acctest\u0026#34; \u0026#34;github.com/hashicorp/terraform-provider-google-beta/google-beta/envvar\u0026#34; ) func TestAccProductResourceName_update(t *testing.T) { t.Parallel() context := map[string]interface{}{ \u0026#34;random_suffix\u0026#34;: acctest.RandString(t, 10), \u0026#34;billing_account\u0026#34;: envvar.GetTestBillingAccountFromEnv(t), \u0026#34;org_id\u0026#34;: envvar.GetTestOrgFromEnv(t), } acctest.VcrTest(t, resource.TestCase{ // ... // Add ExternalProviders so you can use `time_sleep` ExternalProviders: map[string]resource.ExternalProvider{ \u0026#34;time\u0026#34;: {}, }, Steps: []resource.TestStep{ { testAccProductResourceName_update1(context), }, // ... }, }) } func testAccProductResourceName_update1(context map[string]interface{}) string { return accest.Nprintf(` // Set up a test project resource \u0026#34;google_project\u0026#34; \u0026#34;project\u0026#34; { project_id = \u0026#34;tf-test%{random_suffix}\u0026#34; name = \u0026#34;tf-test%{random_suffix}\u0026#34; org_id = \u0026#34;%{org_id}\u0026#34; billing_account = \u0026#34;%{billing_account}\u0026#34; deletion_policy = \u0026#34;DELETE\u0026#34; } // Enable APIs in a deterministic order to avoid inconsistent VCR recordings resource \u0026#34;google_project_service\u0026#34; \u0026#34;servicenetworking\u0026#34; { project = google_project.project.project_id service = \u0026#34;servicenetworking.googleapis.com\u0026#34; } resource \u0026#34;google_project_service\u0026#34; \u0026#34;compute\u0026#34; { project = google_project.project.project_id service = \u0026#34;compute.googleapis.com\u0026#34; depends_on = [google_project_service.servicenetworking] } // wait for API enablement resource \u0026#34;time_sleep\u0026#34; \u0026#34;wait_120_seconds\u0026#34; { create_duration = \u0026#34;120s\u0026#34; depends_on = [google_project_service.compute] } resource \u0026#34;google_product_resource\u0026#34; \u0026#34;example\u0026#34; { // ... depends_on = [time_sleep.wait_120_seconds] } `, context) }Skip tests in VCR replaying mode# Acceptance tests are run in VCR replaying mode on PRs (using pre-recorded HTTP requests and responses) to reduce the time it takes to present results to contributors. However, not all resources or tests are possible to run in replaying mode. Incompatible tests should be skipped during VCR replaying mode. They will still run in our nightly test suite.\nSkip a generated test Skipping acceptance tests that are generated from example files can be achieved by adding skip_vcr: true in the example\u0026rsquo;s YAML:\nexamples: - name: \u0026#39;bigtable_app_profile_anycluster\u0026#39; ... # bigtable instance does not use the shared HTTP client, this test creates an instance skip_vcr: trueIf you skip a test in VCR mode, include a code comment explaining the reason for skipping (for example, a link to a GitHub issue.)\nSkip a handwritten test Skipping acceptance tests that are handwritten can be achieved by adding acctest.SkipIfVcr(t) at the start of the test:\nfunc TestAccPubsubTopic_update(t *testing.T) { acctest.SkipIfVcr(t) // See: https://github.com/hashicorp/terraform-provider-google/issues/9999 acctest.VcrTest(t, resource.TestCase{ ... }) }If you skip a test in VCR mode, include a code comment explaining the reason for skipping (for example, a link to a GitHub issue.)\nReasons that tests are skipped in VCR replaying mode# Problem How to fix/Other info Skip in VCR replaying? Incorrect or insufficient data is present in VCR recordings to replay tests. Tests will fail with Requested interaction not found errors during REPLAYING mode Make sure that you\u0026rsquo;re not introducing randomness into the test, e.g. by unnecessarily using the random provider to set a resource\u0026rsquo;s name. If you cannot avoid this issue you should skip the test, but try to ensure that it cannot be fixed first. Bigtable acceptance tests aren\u0026rsquo;t working in VCR mode. Requested interaction not found errors are seen during Bigtable tests run in REPLAYING mode Currently the provider uses a separate client than the rest of the provider to interact with the Bigtable API. As HTTP traffic to the Bigtable API doesn\u0026rsquo;t go via the shared client it cannot be recorded in RECORDING mode. Skip the test in VCR for Bigtable. Using multiple provider aliases doesn\u0026rsquo;t work in VCR. You may have two instances of the google provider in the test config but one of them doesn\u0026rsquo;t seem to be using its provider arguments - for example, using the wrong default project. See this GitHub issue: https://github.com/hashicorp/terraform-provider-google/issues/20019 . The problem is that, due to how the VCR system works, one provider instance will be configured and the other will be forced to reuse the first instance\u0026rsquo;s configuration, despite them being given different provider arguments. Skip the test in VCR is using aliases is unavoidable. Using multiple versions of the google/google-beta provider in a single test isn\u0026rsquo;t working in VCR. Unexpected test failures may occur during tests in REPLAYING mode where ExternalProviders is used to pull in past versions of the google/google-beta provider. When ExternalProviders is used to pulling in other versions of the provider, any HTTP traffic through the external provider will not be recorded. If the HTTP traffic produces an unexpected result or returns an API error then the test will fail in REPLAYING mode. Skip the test in VCR when testing the current provider behaviour versus previous released versions. Some additional things to bear in mind are that VCR tests in REPLAYING mode will still interact with GCP APIs somewhat. For example:\nWhen the provider is configured it will use credentials to obtain access tokens from GCP Some acceptance tests use bootstrapping functions that ensure long-lived resources are present in a testing project before the provider is tested. These tests can still run in VCR replaying mode; however, REPLAYING mode can\u0026rsquo;t be used as a way to completely avoid HTTP traffic generally or with GCP APIs.\nWhat\u0026rsquo;s next?# Run your tests\nReferences# Official Terraform documentation on Acceptance Tests MMv1 resource reference: examples ↗ "},{"id":2,"href":"/magic-modules/code-review/create-pr/","title":"Create a pull request","section":"Code review","content":"Create a pull request (PR)# Requirements# Make sure your branch contains a single self-contained change. For example: If you are adding multiple resources to the provider, only put one resource in each PR - even if the product requires all resources to be present before it can be meaningfully used. If you are adding a few fields and also fixing a bug, create one PR for adding the new fields and a separate PR for the bugs. Follow the instructions at Creating a pull request to create a pull request to merge your branch into GoogleCloudPlatform/magic-modules. Make sure the PR body includes the text Fixes GITHUB_ISSUE_LINK. once per issue resolved by your PR. Replace GITHUB_ISSUE_LINK with a link to a GitHub issue from the provider issue tracker. Write release notes Code review# A reviewer will automatically be assigned to your PR. Creating a new pull request or pushing a new commit automatically triggers our CI pipelines and workflows. After CI starts, downstream diff generation takes about 10 minutes; VCR tests can take up to 2 hours. If you are a community contributor, some tests will only run after approval from a reviewer. While convenient, relying on CI to test iterative changes to PRs often adds extreme latency to reviews if there are errors in test configurations or at runtime. We strongly recommend you test your changes locally before pushing even after the initial change. VCR tests will first attempt to play back recorded HTTP requests (REPLAYING mode). If any tests fail, they will run in RECORDING mode to generate a new cassette; then, the same tests will run again in REPLAYING mode to detect any nondeterministic behavior in the test (which can cause flaky tests.) If your assigned reviewer does not respond to changes on a pull request within two US business days, ping them on the pull request. TIP: Speeding up review:\nTest your changes locally before pushing to iterate faster. You can push them and test in parallel as well. New CI runs will preempt old ones where possible. Resolve failed status checks quickly Directly ask your reviewer for help if you don\u0026rsquo;t know how to proceed. If there are failed checks they may only check in if there\u0026rsquo;s no progress after a couple days. Self-review your PR or ask someone else familiar with Terraform to review Troubleshoot status check failures# Provider unit tests or VCR tests# VCR test failures that do not immediately seem related to your PR are most likely safe to ignore unless your reviewer says otherwise.\nReview the \u0026ldquo;diff generation\u0026rdquo; report to make sure the generated code looks as expected.\nCheck out the generated code for your PR to run tests and iterate locally. For handwritten code or custom code, you can iterate directly in the provider and then copy the changes to your magic-modules branch once you have resolved the issue.\nterraform-provider-google cd $GOPATH/src/github.com/hashicorp/terraform-provider-google git checkout -- . \u0026amp;\u0026amp; git clean -f google/ google-beta/ website/ git remote add modular-magician https://github.com/modular-magician/terraform-provider-google.git git fetch modular-magician git checkout modular-magician/auto-pr-PR_NUMBER make test make lint make testacc TEST=./google/services/container TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic$$\u0026#39;Replace PR_NUMBER with your PR\u0026rsquo;s ID.\nterraform-provider-google-beta cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta git checkout -- . \u0026amp;\u0026amp; git clean -f google/ google-beta/ website/ git remote add modular-magician https://github.com/modular-magician/terraform-provider-google-beta.git git fetch modular-magician git checkout modular-magician/auto-pr-PR_NUMBER make test make lint make testacc TEST=./google/services/container TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic$$\u0026#39;Replace PR_NUMBER with your PR\u0026rsquo;s ID.\n"},{"id":3,"href":"/magic-modules/best-practices/immutable-fields/","title":"Immutable fields","section":"Best practices","content":"Immutable fields# Note: This page covers best practices guidance for the Terraform provider for Google Cloud, which is used to ensure a consistent UX for Terraform users across providers or GCP users across the Google provider. Generally, this guidance should be followed and exceptions should be clearly demarcated / discussed.\nForceNew in a Terraform resource schema attribute that indicates that a field is immutable – that is, that a change to the field requires the resource to be destroyed and recreated.\nThis is necessary and required for cases where a field can\u0026rsquo;t be updated in-place, so that Terraform\u0026rsquo;s core workflow of aligning real infrastructure with configuration can be achieved. If a field or resource can never be updated in-place and is not marked with ForceNew, that is considered a bug in the provider.\nSome fields or resources may be possible to update in place, but only under specific conditions. In these cases, you can treat the field as updatable - that is, do not mark it as ForceNew; instead, implement standard update functionality. Then, call diff.ForceNew inside a CustomizeDiff if the appropriate conditions to allow update in place are not met. Any CustomizeDiff function like this must be thoroughly unit tested. Making a field conditionally updatable like this is considered a good and useful enhancement in cases where recreation is costly and conditional updates do not introduce undue complexity.\nIn complex cases, it is better to mark the field ForceNew to ensure that users can apply their configurations successfully.\nSafeguarding against deletion# See Deletion behaviors for some mitigations against accidental deletion or other means to safeguard against deletion.\n"},{"id":4,"href":"/magic-modules/reference/resource/","title":"MMv1 resource reference","section":"Reference","content":"MMv1 resource reference# This page documents commonly-used properties for resources. For a full list of available properties, see resource.go ↗.\nBasic# name# API resource name.\ndescription# Resource description. Used in documentation.\nExample:\ndescription: | This is a multi-line description of a resource. All multi-line descriptions must follow this format of using a vertical bar followed by a line-break, with the remaining description being indented.references# Links to reference documentation for a resource. Contains two attributes:\nguides: Link to quickstart in the API\u0026rsquo;s Guides section api: Link to the REST API reference for the resource Example:\nreferences: guides: \u0026#39;Create and connect to a database\u0026#39;: \u0026#39;https://cloud.google.com/alloydb/docs/quickstart/create-and-connect\u0026#39; api: \u0026#39;https://cloud.google.com/alloydb/docs/reference/rest/v1/projects.locations.backups\u0026#39;min_version: beta# Marks the field (and any subfields) as beta-only. Ensure a beta version block is present in provider.yaml.\ndocs# Inserts styled markdown into the header of the resource\u0026rsquo;s page in the provider documentation. Can contain two attributes:\nwarning: Warning text which will be displayed at the top of the resource docs on a yellow background. note: Note text which will be displayed at the top of the resource docs on a blue background. Example:\ndocs: warning: | This is a multi-line warning and will be displayed on a yellow background. note: | This is a multi-line note and will be displayed on a blue background.API interactions# base_url# URL for the resource\u0026rsquo;s standard List method. Terraform field names enclosed in double curly braces are replaced with the field values from the resource at runtime.\nbase_url: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames\u0026#39;self_link# URL for the resource\u0026rsquo;s standard Get method. Terraform field names enclosed in double curly braces are replaced with the field values from the resource at runtime.\nself_link: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames/{{name}}\u0026#39;immutable# If true, the resource and all its fields are considered immutable - that is, only creatable, not updatable. Individual fields can override this for themselves and their subfields with update_url if they have a custom update method in the API.\nSee Best practices: Immutable fields for more information.\nDefault: false\nExample:\nimmutable: truetimeouts# Overrides one or more timeouts, in minutes. All timeouts default to 20.\nExample:\ntimeouts: insert_minutes: 40 update_minutes: 40 delete_minutes: 40create_url# URL for the resource\u0026rsquo;s standard Create method, including query parameters. Terraform field names enclosed in double curly braces are replaced with the field values from the resource at runtime.\nExample:\ncreate_url: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames?resourceId={{name}}\u0026#39;create_verb# Overrides the HTTP verb used to create a new resource. Allowed values: 'POST', 'PUT', 'PATCH'.\nDefault: 'POST'\ncreate_verb: \u0026#39;PATCH\u0026#39;update_url# Overrides the URL for the resource\u0026rsquo;s standard Update method. If unset, the self_link URL is used by default. Terraform field names enclosed in double curly braces are replaced with the field values from the resource at runtime.\nupdate_url: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames/{{name}}\u0026#39;update_verb# The HTTP verb used to update a resource. Allowed values: 'POST', 'PUT', 'PATCH'.\nDefault: 'PUT'.\nExample:\nupdate_verb: \u0026#39;PATCH\u0026#39;update_mask# If true, the resource sets an updateMask query parameter listing modified fields when updating the resource. If false, it doesn\u0026rsquo;t.\nDefault: false\nExample:\nupdate_mask: truedelete_url# Overrides the URL for the resource\u0026rsquo;s standard Delete method. If unset, the self_link URL is used by default. Terraform field names enclosed in double curly braces are replaced with the field values from the resource at runtime.\nExample:\ndelete_url: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames/{{name}}\u0026#39;delete_verb# Overrides the HTTP verb used to delete a resource. Allowed values: 'POST', 'PUT', 'PATCH', 'DELETE'.\nDefault: 'DELETE'\nExample:\ndelete_verb: \u0026#39;POST\u0026#39;exclude_delete# If true, deleting the resource will only remove it from the Terraform state and will not call an API. If false, deleting the resource will run the standard deletion behavior and/or any custom code related to deletion. This should be used if the resource can never be deleted in the API, and there is no other reasonable action to take on deletion. See Deletion behaviors for more information.\nexclude_delete: trueautogen_async# If true, code for handling long-running operations is generated along with the resource. If false, that code isn\u0026rsquo;t generated and must be handwritten.\nDefault: false\nautogen_async: trueasync# Sets parameters for handling operations returned by the API. Can contain several attributes:\nactions: Overrides which API calls return operations. Default: ['create', 'update', 'delete'] operation.base_url: This should always be set to '{{op_id}}' unless you know that\u0026rsquo;s wrong. result.resource_inside_response: If true, the provider sets the resource\u0026rsquo;s Terraform ID after the resource is created, taking into account values that are set by the API at create time. This is only possible when the completed operation\u0026rsquo;s JSON includes the created resource in the \u0026ldquo;response\u0026rdquo; field. If false, the provider sets the resource\u0026rsquo;s Terraform ID before the resource is created, based only on the resource configuration. Default: false. Example:\nasync: actions: [\u0026#39;create\u0026#39;, \u0026#39;update\u0026#39;, \u0026#39;delete\u0026#39;] operation: base_url: \u0026#39;{{op_id}}\u0026#39; result: resource_inside_response: trueerror_retry_predicates# An array of function names that determine whether an error is retryable.\nerror_retry_predicates: - \u0026#39;transport_tpg.IamMemberMissing\u0026#39;error_abort_predicates# An array of function names that determine whether an error is not retryable.\nerror_abort_predicates: - \u0026#39;transport_tpg.Is429QuotaError\u0026#39;IAM resources# iam_policy# Allows configuration of generated IAM resources. Supports the following common attributes – for a full reference, see iam_policy.rb ↗:\nparent_resource_attribute: Name of the field on the terraform IAM resources which references the parent resource. method_name_separator: Character preceding setIamPolicy in the full URL for the API method. Usually :. fetch_iam_policy_verb: HTTP method for getIamPolicy. Usually 'POST'. Allowed values: 'GET', 'POST'. Default: 'GET' set_iam_policy_verb: HTTP method for getIamPolicy. Usually 'POST'. Allowed values: 'POST', 'PUT'. Default: 'POST' import_format: Must match the parent resource\u0026rsquo;s import_format (or self_link if import_format is unset), but with the parent_resource_attribute value substituted for the final field. allowed_iam_role: Valid IAM role that can be set by generated tests. Default: 'roles/viewer' iam_conditions_request_type: If IAM conditions are supported, set this attribute to indicate how the conditions should be passed to the API. Allowed values: 'QUERY_PARAM', 'REQUEST_BODY', 'QUERY_PARAM_NESTED'. Note: 'QUERY_PARAM_NESTED' should only be used if the query param field contains a . min_version: beta: Marks IAM support as beta-only. Example:\niam_policy: parent_resource_attribute: \u0026#39;cloud_function\u0026#39; method_name_separator: \u0026#39;:\u0026#39; fetch_iam_policy_verb: :POST import_format: - \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames/{{cloud_function}}\u0026#39;, - \u0026#39;{{cloud_function}}\u0026#39; allowed_iam_role: \u0026#39;roles/viewer\u0026#39; iam_conditions_request_type: :REQUEST_BODY min_version: betaResource behavior# custom_code# Injects arbitrary logic into a generated resource. For more information, see Add custom resource code.\nmutex# All resources (of all kinds) that share a mutex value will block rather than executing concurrent API requests. Terraform field names enclosed in double curly braces are replaced with the field values from the resource at runtime.\nExample:\nmutex: \u0026#39;alloydb/instance/{{name}}\u0026#39;Sweeper# Sweepers are a testing infrastructure mechanism that automatically clean up resources created during tests. They run before tests start and can be run manually to clean up dangling resources. Sweepers help prevent test failures due to resource quota limits and reduce cloud infrastructure costs by removing test resources that were not properly cleaned up.\nSweeper generation is enabled by default, except in the following conditions which require customization here:\nResources with custom deletion code Resources with parent-child relationships (unless the parent relationship is configured) Resources with complex URL parameters that aren\u0026rsquo;t simple region/project parameters Define the sweeper block in a resource to override these exclusions and enable sweeper generation for that resource.\nexclude_sweeper# If set to true, no sweeper will be generated for this resource. This is useful for resources that cannot or should not be automatically cleaned up.\nDefault: false\nExample:\nexclude_sweeper: truesweeper# Configures how test resources are swept (cleaned up) after tests. The sweeper system helps ensure resources created during tests are properly removed, even when tests fail unexpectedly. All fields within the sweeper block are optional, with reasonable defaults provided when not specified. See sweeper.go ↗ for the implementation.\nidentifier_field: Specifies which field in the API resource object should be used to identify resources for deletion. If not specified, defaults to \u0026ldquo;name\u0026rdquo; if present in the resource, otherwise falls back to \u0026ldquo;id\u0026rdquo;.\nprefixes: Specifies name prefixes that identify resources eligible for sweeping. Resources whose names start with any of these prefixes will be deleted. By default, resources with the tf-test- prefix are automatically eligible for sweeping even if no prefixes are specified.\nurl_substitutions: Allows customizing URL parameters when listing resources. Each map entry represents a set of key-value pairs to substitute in the URL template. This is commonly used to specify regions to sweep in. If not specified, the sweeper will only run in the default region (us-central1) and zone (us-central1-a).\ndependencies: Lists other resource types that must be swept before this one. This ensures proper cleanup order for resources with dependencies. If not specified, no dependencies are assumed.\nparent: Configures sweeping for resources that depend on parent resources (like a nodepool that belongs to a cluster).\nRequired fields:\nresource_type: The type of the parent resource (for example, \u0026ldquo;google_container_cluster\u0026rdquo;) child_field: The field in your resource that references the parent (for example, \u0026ldquo;cluster\u0026rdquo;) At least one of parent_field or template is required Options for getting parent reference:\nparent_field: The field from parent to use (typically \u0026ldquo;name\u0026rdquo; or \u0026ldquo;id\u0026rdquo;) template: A template string like \u0026ldquo;projects/{{project}}/locations/{{location}}/clusters/{{value}}\u0026rdquo; Options for processing the parent field value:\nparent_field_extract_name: When set to true, extracts just the resource name from a self_link URL by taking the portion after the last slash. This is useful when the parent field contains a fully-qualified resource URL (like \u0026ldquo;https://www.googleapis.com/compute/v1/projects/my-project/global/networks/my-network\" or \u0026ldquo;projects/my-project/zones/us-central1-a/instances/my-instance\u0026rdquo;) but you only need the final resource name component (\u0026ldquo;my-network\u0026rdquo; or \u0026ldquo;my-instance\u0026rdquo;).\nparent_field_regex: A regex pattern with a capture group to extract a specific portion of the parent field value. This is useful when you need more control over extracting parts of complex resource identifiers. The pattern must contain at least one capture group (in parentheses), and the first capture group\u0026rsquo;s match will be used as the extracted value.\nquery_string: Allows appending additional query parameters to the resource\u0026rsquo;s delete URL when performing delete operations. Format should include the starting character, for example, \u0026ldquo;?force=true\u0026rdquo; or \u0026ldquo;\u0026amp;verbose=true\u0026rdquo;. If not specified, no additional query parameters are added.\nensure_value: Specifies a field that must be set to a specific value before deletion. Used for resources that have fields like \u0026lsquo;deletionProtectionEnabled\u0026rsquo; that must be explicitly disabled before the resource can be deleted. All fields within the ensure_value block are required except include_full_resource:\nfield: The API field name that needs to be updated before deletion. Can include dot notation for nested fields (for example, \u0026ldquo;settings.deletionProtectionEnabled\u0026rdquo;).\nvalue: The required value that field must be set to before deletion. For boolean fields use \u0026ldquo;true\u0026rdquo; or \u0026ldquo;false\u0026rdquo;, for integers use string representation, for string fields use the exact string value required.\ninclude_full_resource: Determines whether to send the entire resource object with the updated field (true) or to send just the field that needs updating (false). Some APIs require the full resource to be sent in update operations. Default: false.\nExamples:\nBasic sweeper configuration:\nsweeper: prefixes: - \u0026#34;tf-test-\u0026#34; - \u0026#34;tmp-\u0026#34;Sweeper with parent-child relationship (basic):\nsweeper: dependencies: # sweep google_compute_instance before attempting to sweep this resource - \u0026#34;google_compute_instance\u0026#34; parent: resource_type: \u0026#34;google_container_cluster\u0026#34; parent_field: \u0026#34;name\u0026#34; child_field: \u0026#34;cluster\u0026#34;Sweeper with parent_field_extract_name:\nsweeper: parent: resource_type: \u0026#34;google_compute_network\u0026#34; parent_field: \u0026#34;selfLink\u0026#34; # Contains: \u0026#34;projects/my-project/global/networks/my-network\u0026#34; parent_field_extract_name: true # Extracts just \u0026#34;my-network\u0026#34; child_field: \u0026#34;network\u0026#34;Sweeper with parent template and pre-deletion field update:\nsweeper: parent: resource_type: \u0026#34;google_container_cluster\u0026#34; template: \u0026#34;projects/{{project}}/locations/{{location}}/clusters/{{value}}\u0026#34; parent_field: \u0026#34;displayName\u0026#34; # Provides the value for {{value}} child_field: \u0026#34;cluster\u0026#34; ensure_value: field: \u0026#34;deletionProtection\u0026#34; value: \u0026#34;false\u0026#34; include_full_resource: falseSweeper with URL substitutions for multiple regions:\nsweeper: url_substitutions: - collection_id: default_collection region: global - collection_id: default_collection region: euSweeper with URL substitutions specifying only regions:\nsweeper: identifier_field: \u0026#34;displayName\u0026#34; url_substitutions: - region: \u0026#34;us-central1\u0026#34; - region: \u0026#34;us-east1\u0026#34; - region: \u0026#34;europe-west1\u0026#34;Fields# virtual_fields# Contains a list of virtual_fields. By convention, these should be fields that do not get sent to the API, and are instead used to modify the behavior of a Terraform resource such as deletion_protection.\nparameters# Contains a list of fields. By convention, these should be the fields that are part URL parameters such as location and name.\nproperties# Contains a list of fields. By convention, these should be fields that aren\u0026rsquo;t part of the URL parameters.\nExample:\nproperties: - name: \u0026#39;fieldOne\u0026#39; type: StringExamples# examples# A list of configurations that are used to generate documentation and tests. Each example supports the following common attributes – for a full reference, see examples.go ↗:\nname: snake_case name of the example. This corresponds to the configuration file in mmv1/templates/terraform/examples (excluding the .go.tmpl suffix) and is used to generate the test name and the documentation header. primary_resource_id: The id of the resource under test. This is used by tests to automatically run additional checks. Configuration files should reference this to avoid getting out of sync. For example: resource \u0026quot;google_compute_address\u0026quot; \u0026quot;\u0026quot;{{$.PrimaryResourceId}}\u0026quot; { bootstrap_iam: specify member/role pairs that should always exist. {project_number} will be replaced with the default project\u0026rsquo;s project number, and {organization_id} will be replaced with the \u0026ldquo;target\u0026rdquo; test organization\u0026rsquo;s ID. This avoids race conditions when modifying the global IAM permissions. Permissions attached to resources created in a test should instead be provisioned with standard terraform resources. vars: Key/value pairs of variables to inject into the configuration file. These can be referenced in the configuration file with {{index $.Vars \u0026quot;key\u0026quot;}}. All resource IDs (even for resources not under test) should be declared with variables that contain a - or _; this will ensure that, in tests, the resources are created with a tf-test prefix to allow automatic cleanup of dangling resources and a random suffix to avoid name collisions. test_env_vars: Key/value pairs of variable names and special values indicating variables that should be pulled from the environment during tests. These will receive a neutral default value in documentation. Common special values include: PROJECT_NAME, REGION, ORG_ID, ORG_TARGET (a separate test org for testing certain org-level resources such as IAM), BILLING_ACCT, SERVICE_ACCT (the test runner service account). test_vars_overrides: Key/value pairs of literal overrides for variables used in tests. This can be used to call functions to generate or determine a variable\u0026rsquo;s value. min_version: Set this to beta if the resource is in the google provider but the example will only work with the google-beta provider (for example, because it includes a beta-only field.) ignore_read_extra: Properties to not check on import. This should be used in cases where a property will not be set on import, for example write-only fields. exclude_test: If set to true, no test will be generated based on this example. exclude_docs: If set to true, no documentation will be generated based on this example. exclude_import_test: If set to true, no import test will be generated for this example. skip_vcr: See Skip tests in VCR replaying mode for more information about this flag. skip_test: If not empty, the test generated based on this example will always be skipped. In most cases, the value should be a link to a ticket explaining the issue that needs to be resolved before the test can be unskipped. external_providers: A list of external providers that are needed for the testcase. This does add some latency to the testcase, so only use if necessary. Common external providers: random, time. Example:\nexamples: - name: service_resource_basic primary_resource_id: example bootstrap_iam: - member: \u0026#34;serviceAccount:service-{project_number}@gcp-sa-healthcare.iam.gserviceaccount.com\u0026#34; role: \u0026#34;roles/bigquery.dataEditor\u0026#34; - member: \u0026#34;serviceAccount:service-org-{organization_id}@gcp-sa-osconfig.iam.gserviceaccount.com\u0026#34; role: \u0026#34;roles/osconfig.serviceAgent\u0026#34; vars: dataset_id: \u0026#34;my-dataset\u0026#34; network_name: \u0026#34;my-network\u0026#34; test_env_vars: org_id: \u0026#34;ORG_ID\u0026#34; test_vars_overrides: network_name: \u0026#39;acctest.BootstrapSharedServiceNetworkingConnection(t, \u0026#34;service-resource-network-config\u0026#34;)\u0026#39; min_version: \u0026#34;beta\u0026#34; ignore_read_extra: - \u0026#39;foo\u0026#39; exclude_test: true exclude_docs: true exclude_import_test: true skip_vcr: true skip_test: \u0026#34;https://github.com/hashicorp/terraform-provider-google/issues/20574\u0026#34; external_providers: - \u0026#34;time\u0026#34;"},{"id":5,"href":"/magic-modules/develop/set-up-dev-environment/","title":"Set up your development environment","section":"Develop","content":"Set up your development environment# Before you start adding or updating a Terraform resource using magic-modules, you must first set up your environment by installing the necessary tools. This page explains the steps for setting up your development environment.\nInstall the gcloud CLI.\nIn the Google Cloud console, on the project selector page, select or create a Google Cloud project.\nNote: If you don\u0026rsquo;t already have a project to use for testing changes to the Terraform providers, create a project instead of selecting an existing poject. After you finish these steps, you can delete the project, removing all resources associated with the project.\nGo to project selector Make sure that billing is enabled for your Google Cloud project. Learn how to check if billing is enabled on a project.\nInstall git\nInstall go\nAdd the following values to your environment settings such as .bashrc:\n# Add GOPATH variable for convenience export GOPATH=$(go env GOPATH) # Add Go binaries to PATH export PATH=$PATH:$(go env GOPATH)/bin Install terraform\nClone the magic-modules repository\ncd ~ git clone https://github.com/GoogleCloudPlatform/magic-modules.git Run the following command from the root of your cloned magic-modules repository.\ncd magic-modules ./scripts/doctorExpected output if everything is installed properly:\nCheck for go in path... found! Check for git in path... found! Check for terraform in path... found! Check for make in path... found! What\u0026rsquo;s next# Learn how to add a resource Learn how to add custom resource code Learn how to add a datasource Learn how to promote a resource to GA "},{"id":6,"href":"/magic-modules/breaking-changes/breaking-changes/","title":"Types of breaking changes","section":"Breaking changes","content":"Types of breaking changes# A \u0026ldquo;breaking change\u0026rdquo; is any change that requires an end user to modify a previously-valid configuration after a provider upgrade. In this context, a \u0026ldquo;valid configuration\u0026rdquo; is one that:\nIs considered syntactically correct by terraform validate Does not return an error during terraform apply Creates, updates, deletes, or does not modify resources Only manages resources that have not been altered with other tools, such as gcloud or Cloud Console. This document lists many types of breaking changes but may not be entirely comprehensive. Some types of changes that would normally be \u0026ldquo;breaking\u0026rdquo; may have specific mitigating circumstances that make them non-breaking.\nFor more information, see Make a breaking change.\nProvider-level breaking changes# Changing fundamental provider behavior such as: authentication environment variable usage restricting retry behavior Resource-level breaking changes# Removing or renaming a resource or datasource Changing resource ID format Terraform uses resource ID to read resource state from the API. Modification of the ID format will break the ability to parse the IDs from any deployments. Removing or altering resource import ID formats Automation written by end users may rely on specific import formats. Changes to default resource behavior Changing resource deletion behavior In limited cases changes may be permissible if the prior behavior could never succeed. Changing resource deletion to skip deleting the resource by default if delete was previously called Changing resource deletion to specify a force flag Adding a new field with a default different from the API default If an API default is expected to change- a breaking change for the API- use default_from_api which will avoid sending a value and safely take the server default in Terraform Field-level breaking changes# Removing or renaming a field Changing field output type Between primitive types, like changing a String to an Integer Between complex types like changing a List to a Set. Changing the field type between primitive and complex data types is not possible. For this scenario, field renames are preferred. Making an optional field required Adding a required field to a pre-existing resource at any level of nesting, unless it is being added at the same time as an optional ancestor Adding an \u0026ldquo;ExactlyOneOf\u0026rdquo; constraint that causes one or more previously-optional fields to be required or conflict with each other Making a settable field read-only For MMv1 resources, adding output: true to an existing field. For handwritten resources, adding Computed: true to a field that does not have Optional: true set. Even if there is no valid scenario where a field can be set, changing it to read-only may be a breaking change for modules that depend on the provider. Removing support for API-side defaults For MMv1 resources, removing default_from_api: true. For handwritten resources, altering a field schema with Computed: true + Optional: true to only have Optional: true. Adding or changing a default value Default values in Terraform are used to replace null values in configuration at plan/apply time and do not respect previously-configured values by the user. Even in major releases, these changes are often undesirable, as their impact is extremely broad.\nWhen a default is changed, every user that has not specified an explicit value in their configuration will see Terraform propose changing the value of the field including if the change will destroy and recreate the resource due to changing an immutable value. Default changes in the provider are comparable in impact to default changes in an API, and modifying examples and modules may achieve the intended effect with a smaller blast radius.\nAdding an optional field with a default value and force new to a pre-existing resource at any level of nesting, unless it is being added at the same time as an optional ancestor This can be allowed if there is a confirmed API-level default that matches the schema default Please work with your reviewer and ensure this scenario is debugged carefully to avoid a destructive permadiff Modifying how field data is stored in state For example, changing the case of a value returned by the API in a flattener or decorder Removing diff suppression from a field. For MMv1 resources, removing diff_suppress_func from a field. For handwritten resources, removing DiffSuppressFunc from a field. Removing update support from a field. Making validation more strict# Increasing the minimum number of items in an array For MMv1 resources, increasing min_size on an Array field. For handwritten resources, increasing MinItems on an Array field. Decreasing the maximum number of items in an array For MMv1 resources, decreasing max_size on an Array field. For handwritten resources, decreasing MaxItems on an Array field. Adding validation to a field that previously had no validation For MMv1 resources, adding validation to a field. For handwritten resources, adding ValidateFunc to a field. "},{"id":7,"href":"/magic-modules/develop/add-resource/","title":"Add a resource","section":"Develop","content":"Add a resource# This page describes how to add a new resource to the google or google-beta Terraform provider using MMv1 and/or handwritten code.\nFor more information about types of resources and the generation process overall, see How Magic Modules works.\nBefore you begin# Complete the steps in Set up your development environment to set up your environment and your Google Cloud project. Ensure that your magic-modules, terraform-provider-google, and terraform-provider-google-beta repositories are up to date. cd ~/magic-modules git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull Add a resource# MMv1 Using an editor of your choice, in the appropriate product folder, create a file called RESOURCE_NAME.yaml. Replace RESOURCE_NAME with the name of the API resource you are adding support for. For example, a configuration file for NatAddress would be called NatAddress.yaml.\nCopy the following template into the new file:\n# Copyright 2026 Google Inc. # Licensed under the Apache License, Version 2.0 (the \u0026#34;License\u0026#34;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \u0026#34;AS IS\u0026#34; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. --- # API resource name name: \u0026#39;ResourceName\u0026#39; # Resource description for the provider documentation. description: | RESOURCE_DESCRIPTION references: guides: # Link to quickstart in the API\u0026#39;s Guides section. For example: # \u0026#39;Create and connect to a database\u0026#39;: \u0026#39;https://cloud.google.com/alloydb/docs/quickstart/create-and-connect\u0026#39; \u0026#39;QUICKSTART_TITLE\u0026#39;: \u0026#39;QUICKSTART_URL\u0026#39; # Link to the REST API reference for the resource. For example, # https://cloud.google.com/alloydb/docs/reference/rest/v1/projects.locations.backups api: \u0026#39;API_REFERENCE_URL\u0026#39; # Marks the resource as beta-only. Ensure a beta version block is present in # provider.yaml. # min_version: beta # URL for the resource\u0026#39;s standard List method. https://google.aip.dev/132 # Terraform field names enclosed in double curly braces are replaced with # the field values from the resource at runtime. base_url: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames\u0026#39; # URL for the resource\u0026#39;s standard Get method. https://google.aip.dev/131 # Terraform field names enclosed in double curly braces are replaced with # the field values from the resource at runtime. self_link: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames/{{name}}\u0026#39; # If true, the resource and all its fields are considered immutable - that is, # only creatable, not updatable. Individual fields can override this if they # have a custom update method in the API. immutable: true # URL for the resource\u0026#39;s standard Create method, including query parameters. # https://google.aip.dev/133 # Terraform field names enclosed in double curly braces are replaced with # the field values from the resource at runtime. create_url: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames?resourceId={{name}}\u0026#39; # Overrides the URL for the resource\u0026#39;s standard Update method. (If unset, the # self_link URL is used by default.) https://google.aip.dev/134 # Terraform field names enclosed in double curly braces are replaced with # the field values from the resource at runtime. # update_url: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames/{{name}}\u0026#39; # The HTTP verb used to update a resource. Allowed values: :POST, :PUT, :PATCH. Default: :PUT. update_verb: \u0026#39;PATCH\u0026#39; # If true, the resource sets an `updateMask` query parameter listing modified # fields when updating the resource. If false, it does not. update_mask: true # If true, code for handling long-running operations is generated along with # the resource. If false, that code is not generated. autogen_async: true # Sets parameters for handling operations returned by the API. async: # Overrides which API calls return operations. Default: [\u0026#39;create\u0026#39;, # \u0026#39;update\u0026#39;, \u0026#39;delete\u0026#39;] # actions: [\u0026#39;create\u0026#39;, \u0026#39;update\u0026#39;, \u0026#39;delete\u0026#39;] operation: base_url: \u0026#39;{{op_id}}\u0026#39; parameters: - name: \u0026#39;location\u0026#39; type: String required: true immutable: true url_param_only: true description: | LOCATION_DESCRIPTION - name: \u0026#39;name\u0026#39; type: String required: true immutable: true url_param_only: true description: | NAME_DESCRIPTION properties: # Fields go here Modify the template as needed to match the API resource\u0026rsquo;s documented behavior.\nDelete all remaining comments in the resource configuration (including attribute descriptions) that were copied from the above template.\nNote: The template includes the most commonly-used fields. For a comprehensive reference, see MMv1 resource reference ↗.\nHandwritten Warning: Handwritten resources are more difficult to develop and maintain. New handwritten resources will only be accepted if implementing the resource in MMv1 would require entirely overriding two or more CRUD methods.\nAdd the resource in MMv1. Generate the beta provider From the beta provider, copy the files generated for the resource to the following locations: Resource: Copy to the appropriate service folder inside magic-modules/mmv1/third_party/terraform/services Documentation: magic-modules/mmv1/third_party/terraform/website/docs/r Tests: Copy to the appropriate service folder inside magic-modules/mmv1/third_party/terraform/services, and remove _generated from the filename Sweepers: Put to the appropriate service folder inside magic-modules/mmv1/third_party/terraform/services, and add _sweeper suffix to the filename Metadata: Copy *_meta.yaml to the appropriate service folder inside magic-modules/mmv1/third_party/terraform/services, and remove _generated from the filename Modify the Go code as needed. Replace all occurrences of github.com/hashicorp/terraform-provider-google-beta/google-beta with github.com/hashicorp/terraform-provider-google/google Remove the Example suffix from all test function names. Remove the comments at the top of the file. If any of the added Go code (including any imports) is beta-only, change the file suffix to .go.tmpl and wrap the beta-only code in a version guard: {{- if ne $.TargetVersionName \u0026quot;ga\u0026quot; -}}...{{- else }}...{{- end }}. If the whole resource is beta-only, wrap everything except package declarations. Otherwise, individually wrap each logically-related block of code in a version guard (field, test, etc) rather than grouping adjacent version-guarded sections - it\u0026rsquo;s easier to read and easier to modify as things move out of beta. Register the resource handwrittenResources in magic-modules/mmv1/third_party/terraform/provider/provider_mmv1_resources.go.tmpl Add a version guard for any beta-only resources. Optional: Complete other handwritten tasks that require the MMv1 configuration file. Add resource tests Add IAM support Delete the MMv1 configuration file. What\u0026rsquo;s next?# Add a field to an existing resource Add IAM support Add documentation Add custom resource code Add tests Run tests "},{"id":8,"href":"/magic-modules/convert/add-new-resource-tgc/","title":"Add TGC conversion","section":"Convert","content":"Add TGC conversion# This method of adding TGC support is currently experimental and not officially supported. We recommended this path only for core contributors. terraform-google-conversion (TGC) consumes a Terraform plan and uses it to build Cloud Asset Inventory (CAI) Assets. These built assets only exist in memory locally.\nTGC supports only those GCP resources that are available in both the Terraform provider and Cloud Asset Inventory.\nBefore you begin# Getting a Terraform resource name from a GCP resource name# The first step in determining if a GCP resource is supported is to identify the corresponding Terraform resource. You can often do this by searching for the GCP resource name in the Terraform google provider documentation.\nGetting the CAI asset type of a GCP resource# The second step in determining if a GCP resource is supported is to verify its inclusion in the Cloud Asset Inventory (CAI). You can complete this by searching for the resource\u0026rsquo;s asset type within CAI\u0026rsquo;s list of supported asset types.\nAdding support# Adding support for a resource has 4 steps:\nMake changes to Magic Modules to add resource conversion code. Generate terraform-google-conversion. Run tests locally. Make PRs for Magic Modules with your changes. Each of these is discussed in more detail below.\n1. Adding a resource to TGC# MMv1 Magic Modules uses a shared code base to generate terraform-google-conversion and the google and google-beta Terraform providers. Most Terraform resources are represented as yaml files which are grouped by product. Each product has a product.yaml file (which defines the basic product information) and Resource.yaml files (which defines any resource-specific information). A Resource.yaml file can specify include_in_tgc_next: true to enable converters autogeneration, or exclude_resource: true to skip autogeneration for both converters and the providers.\nAuto-generating converters code based on yaml files is strongly preferred.\nHandwritten Handwritten converters# If autogenerated converter are not possible, you can instead place three handwritten files in the specific Product folder in the mmv1/third_party/tgc_next/pkg/services folder.\nResource.go file# The Resource.go file defines the resource, providing its CAI asset type, Terraform schema name, resource schema, and supporting utility functions.\n// The type comes from https://cloud.google.com/asset-inventory/docs/supported-asset-types const ProductResourceAssetType string = \u0026#34;whatever.googleapis.com/asset-type\u0026#34; // ProductResourceSchemaName is the TF resource schema name for the Resource resource within Product. const ProductResourceSchemaName string = \u0026#34;google_product_resource\u0026#34; // Copy the resource schema from [google](https://github.com/hashicorp/terraform-provider-google) Terraform provider func ResourceGoogleProject() *schema.Resource { return \u0026amp;schema.Resource{ SchemaVersion: 1, Schema: map[string]*schema.Schema{ ... } } }You will also need to add an entry to tgc_next/provider/provider_mmv1_resources.go.tmpl, which is used to generate pkg/provider/provider_mmv1_resources.go. Each entry in provider_mmv1_resources.go.tmpl maps a terraform resource name to a function that returns the resource schema - in this case:\n// ... \u0026#34;google_product_resource\u0026#34;: product.ResourceName(), // ...Resource_tfplan2cai.go file# Most resources will only need a resource converter with a conversion func. For example, Resource resource within Product, this might look like:\nfunc resourceConverterProductResource() ResourceConverter { return ResourceConverter{ Convert: GetProductResourceCaiObject, } } func GetProductResourceCaiObject(d TerraformResourceData, config *Config) ([]Asset, error) { // This function does basic conversion of a Terraform resource to a CAI Asset. // The asset path (name) will substitute in variables from the Terraform resource. // The format should match what is specified at https://cloud.google.com/asset-inventory/docs/supported-asset-types name, err := assetName(d, config, \u0026#34;//whatever.googleapis.com/projects/{{project}}/whatevers/{{name}}\u0026#34;) if err != nil { return []Asset{}, err } if obj, err := GetProductResourceApiObject(d, config); err == nil { return []Asset{{ Name: name, Type: ProductResourceAssetType, Resource: \u0026amp;AssetResource{ Version: \u0026#34;v1\u0026#34;, // or whatever the correct version is DiscoveryDocumentURI: \u0026#34;https://www.googleapis.com/path/to/rest/api/docs\u0026#34;, DiscoveryName: \u0026#34;Whatever\u0026#34;, // The term used to refer to this resource by the official documentation Data: obj, }, }}, nil } else { return []Asset{}, err } } func GetProductResourceApiObject(d TerraformResourceData, config *Config) (map[string]interface{}, error) { obj := make(map[string]interface{}) // copy values from the terraform resource to obj // return any errors encountered // ... return obj, nil }You will also need to add an entry to tgc_next/tfplan2cai/resource_converters.go.tmpl, which is used to generate pkg/tfplan2cai/converters/resource_converters.go. Each entry in resource_converters.go.tmpl maps a terraform resource name to a function that returns a ResourceConverter - in this case:\n// ... \u0026#34;google_product_resource\u0026#34;: product.ResourceTfplan2caiConverter(), // ...Resource_cai2hcl.go file# Most resources will only need a resource converter with a conversion func in the handwritten Resource_cai2hcl.go file. For the Resource resource within Product, this might look like:\n// ProductResourceConverter for the Resource resource within Product. type ProductResourceConverter struct { name string schema map[string]*schema.Schema } // NewProductResourceConverter returns an HCL converter for compute instance. func NewProductResourceConverter(provider *schema.Provider) common.Converter { schema := provider.ResourcesMap[ProductResourceSchemaName].Schema return \u0026amp;ProductResourceConverter{ name: ProductResourceSchemaName, schema: schema, } } // Convert converts asset to HCL resource blocks. func (c *ProductResourceConverter) Convert(assets []*caiasset.Asset) ([]*common.HCLResourceBlock, error) { var blocks []*common.HCLResourceBlock for _, asset := range assets { if asset == nil { continue } if asset.Resource != nil \u0026amp;\u0026amp; asset.Resource.Data != nil { block, err := c.convertResourceData(asset) if err != nil { return nil, err } blocks = append(blocks, block) } } return blocks, nil } func (c *ProductResourceConverter) convertResourceData(asset *caiasset.Asset) (*common.HCLResourceBlock, error) { if asset == nil || asset.Resource == nil || asset.Resource.Data == nil { return nil, fmt.Errorf(\u0026#34;asset resource data is nil\u0026#34;) } hclData := make(map[string]interface{}) // copy values from the CAI asset to hclData // return any errors encountered // ... ctyVal, err := common.MapToCtyValWithSchema(hclData, c.schema) if err != nil { return nil, err } return \u0026amp;common.HCLResourceBlock{ Labels: []string{c.name, \u0026#34;Whatever\u0026#34;}, Value: ctyVal, }, nil }You will also need to add an entry to tgc_next/cai2hcl/resource_converters.go.tmpl, which is used to generate pkg/cai2hcl/converters/resource_converters.go. Each entry in resource_converters.go.tmpl maps a CAI asset type to a function that returns a ResourceConverter - in this case:\n// ... \u0026#34;alloydb.googleapis.com/Backup\u0026#34;: { \u0026#34;Default\u0026#34;: alloydb.NewAlloydbBackupCai2hclConverter(provider), }, // ... 2. Generate terraform-google-conversion# To generate terraform-google-conversion code locally, run the following from the root of the magic-modules repository:\nmake tgc OUTPUT_PATH=\u0026#34;/path/to/your/terraform-google-conversion\u0026#34;3. Run tests locally# Before you begin# Set the following environment variable: export WRITE_FILES=true Please request the necessary permission for the GCS bucket cai_assets_metadata, which stores the nightly test metadata required to run the integration tests.\nEnsure you have the correct Go version installed. Follow Before you begin and Setup your development environment from the Magic Modules documentation.\nRun unit tests# To run the unit tests locally, run the following from the root of the terraform-google-conversion repository:\nmake test-localRun integration tests# In the following examples, the resource being tested is google_alloydb_backup.\nTo run the integration tests for the added resource locally, run the following from the root of the terraform-google-conversion repository:\nmake test-integration-local TESTPATH=./test/services/alloydb TESTARGS=\u0026#39;-run=TestAccAlloydbBackup\u0026#39; \u0026gt; alloydbBackup.logTo run one integration test for the added resource locally, run the following from the root of the terraform-google-conversion repository:\nmake test-integration-local TESTPATH=./test/services/alloydb TESTARGS=\u0026#39;-run=TestAccAlloydbBackup/TestAccAlloydbBackup_alloydbBackupBasicTestExample\u0026#39; \u0026gt; alloydbBackup.logThe core integration tests in terraform-google-conversion mirror the naming of the corresponding acceptance tests in the Terraform provider. This testing process uses a crucial round-trip validation method:\nTest Input Data\nThe input for each equivalent integration test combines two elements:\nThe original Terraform resource configuration from the acceptance test step.\nThe Cloud Asset Inventory (CAI) data exported from the actual resources provisioned during the nightly execution of the Terraform provider tests.\nTest File Generation (WRITE_FILES Flow)\nBy setting the environment variable WRITE_FILES, running the integration tests locally generates a series of files in the service folder, detailing the entire conversion cycle.\nFor example, running TestAccAlloydbBackup_alloydbBackupBasicTestExample successfully creates five files for each step:\nFile Content Conversion Step File 1 (.tf) Original Terraform configuration (raw_config) File 2 (.json) CAI Assets exported from the resource (export_assets) Input for CAI to HCL File 3 (export.tf) Converted Terraform configuration (export_config) from File 2 cai2hcl File 4 (roundtrip.json) CAI Assets (roundtrip_assets) converted from File 3 tfplan2cai File 5 (roundtrip.tf) Final Terraform configuration (roundtrip_config) from File 4 cai2hcl The integration tests pass only when two conditions are met:\nEvery field in the original raw_config must exist within the generated export_config. The export_config and the final roundtrip_config must contain the same sets of fields. Address integration test failures# To resolve integration test failures, you need to apply the correct override configuration to the Resource.yaml file, based on the root cause of the data mismatch or failure.\nTest Specific Overrides\nThese rules are applied when a specific test cannot be reliably executed or fails due to expected differences in zero values.\nIgnore Zero Values (in raw_config)\nAdd tgc_test_ignore_extra to the resource example in Resource.yaml. This tells the test to ignore fields that have a zero value in the original Terraform configuration (raw_config) but retain a value in the exported CAI assets (export_assets).\nSkip the Entire Test\nAdd tgc_skip_test:REASON to the resource example in Resource.yaml, providing a brief explanation for why the test is being skipped.\nResource-specific Overrides\nThese rules address mismatches in how the resource is identified or where it is converted.\nFix CAI Resource Kind Mismatch\nIf the CAI asset type differs from the Terraform API resource kind (api_resource_type_kind), add the correct cai_resource_kind to the Resource.yaml file.\nIgnore Default Terraform Encoder\nIf the default Terraform encoding applied during conversion is causing issues, disable it by adding tgc_ignore_terraform_encoder: true to the Resource.yaml file.\nIgnore Default Terraform Decoder\nIf the default Terraform decoding applied during conversion is causing issues, disable it by adding tgc_ignore_terraform_decoder: true to the Resource.yaml file.\nCustom Decoder (CAI → GET API object Mismatch)\nThis is used when the value of a field in a CAI asset is different from the value required in the final API object during cai2hcl.\nAdd the tgc_decoder file path to the field in Resource.yaml.\nImplement the custom Go code in the corresponding file under mmv1/templates/tgc_next/decoders.\nCustom Encoder (CREATE API object -\u0026gt; CAI Mismatch)\nThis is used when the value of a field in a CAI asset is different from the value needed in the API object when the resource is first created during tfplan2cai.\nAdd the tgc_encoder file path to the field in Resource.yaml.\nImplement the custom Go code in the corresponding file under mmv1/templates/tgc_next/encoders.\nField-Specific Overrides\nThese rules are used when custom code is required because the field values or structure change during the tfplan2cai or cai2hcl conversion process.\nIgnore Field Missing in CAI\nIf a field is present in the Terraform resource but not supported or exported by Cloud Asset Inventory (CAI), add is_missing_in_cai: true to that specific field\u0026rsquo;s definition in the Resource.yaml file.\nIgnore Default Terraform Custom Flatten\nIf the default flattening logic is incorrect for TGC, disable it by adding tgc_ignore_terraform_custom_flatten: true to the field definition.\nTGC Specific Expander / Flattener\nFor custom tfplan2cai conversion logic, add custom_tgc_expand to the field.\nFor custom cai2hcl conversion logic, add custom_tgc_flatten to the field.\n4. Make PRs# Now that you have your code working locally, open a PR for Magic Modules.\nFor the Magic Modules PR, check the build results within presubmit-generate-diffs. Click through the build links, and find the results of tgc-test, tgc-test-integration-* - the other checks only matter if you\u0026rsquo;re also making changes to the terraform provider.\nIf tgc-test fails, make sure you can run the unit tests successfully locally. If any of tgc-test-integration-* fails, make sure you can run the integration tests successfully locally.\n"},{"id":9,"href":"/magic-modules/contribution-process/","title":"Contribution process","section":"Overview","content":"Contribution process# This page explains how you can contribute code and documentation to the\tmagic-modules repository.\nBefore you begin# Familiarize yourself with GitHub flow Fork the Magic Modules repository into your GitHub account Set up your development environment Check whether the feature you want to work on has already been requested in the issue tracker. If there\u0026rsquo;s an issue and it already has a dedicated assignee, this indicates that someone might have already started to work on a solution. Otherwise, you\u0026rsquo;re welcome to work on the issue. Contribute code# Set up your development environment Create a new branch for your change Make the code change. For example: Add a resource Add resource tests Add a datasource Promote to GA Make a breaking change Generate the providers that include your change. Run provider tests locally that are relevant to the change you made Create a pull request (PR) Make changes in response to code review After your change is merged# After your change is merged, it can take a week or longer to be released to customers.\n"},{"id":10,"href":"/magic-modules/best-practices/deletion-behaviors/","title":"Deletion behaviors","section":"Best practices","content":"Deletion behaviors# Note: This page covers best practices guidance for the Terraform provider for Google Cloud, which is used to ensure a consistent UX for Terraform users across providers or GCP users across the Google provider. Generally, this guidance should be followed and exceptions should be clearly demarcated / discussed.\nMitigating data loss risk via deletion_protection# Some resources, such as databases, have a significant risk of unrecoverable data loss if the resource is accidentally deleted due to a change to a ForceNew field. For these resources, the best practice is to add a deletion_protection field that prevents the resource from being deleted if enabled.\ndeletion_protection fields generally need to be added with a default of false that can be changed to true in the next major release, because adding deletion protection is a major behavioral change. Exceptions to this are:\nThe API has a deletion protection field that defaults to enabled on the API side The deletion_protection field is being added at the same time as the resource If the API has a deletion protection field, the corresponding Terraform field name should match the API field\u0026rsquo;s name and type. For example, if the API has an enum field called what_to_do_on_delete with values DELETE and PROTECT, the Terraform field should do the same.\nA resource can have up to two deletion_protection fields (with different names): one that represents a field in the API, and one that is only in Terraform. This could happen because the API added its field after deletion_protection already existed in Terraform; it could also happen because a separate field was added in Terraform to make sure that deletion_protection is enabled by default. In either case, they should be reconciled into a single field (that defaults to enabled and whose name matches the API field) in the next major release.\nResources that do not have a significant risk of unrecoverable data loss or similar critical concern will not be given deletion_protection fields.\nSee Client-side fields for information about adding deletion_protection fields.\nNote: The previous best practice was a field called force_delete that defaulted to false. This is still present on some resources for backwards-compatibility reasons, but deletion_protection is preferred going forward.\nDeletion policy# Some resources need to let users control the actions taken add deletion time. For these resources, the best practice is to add a deletion_policy enum field that defaults to an empty string and allows special values that control the deletion behavior.\nOne common example is ABANDON, which is useful if the resource is safe to delete from Terraform but could cause problems if deleted from the API - for example, google_bigtable_gc_policy deletion can fail in replicated instances. ABANDON indicates that attempts to delete the resource should remove it from state without actually deleting it.\nSee Client-side fields for information about adding deletion_policy fields.\nExclude deletion# Some resources do not support deletion in the API and can only be removed from state. For these resources, the best practice is to set exclude_delete: true on the resource.\n"},{"id":11,"href":"/magic-modules/document/handwritten-docs-style-guide/","title":"Handwritten docs style guide","section":"Document","content":"Handwritten documentation style guide# This document describes the style guide for handwritten documentation for resources and data sources. MMv1-based resources will automatically generate documentation that matches this style guide.\nFile name and location# Handwritten documentation lives in:\nData sources: magic-modules/third_party/terraform/website/docs/d/ Resources: magic-modules/third_party/terraform/website/docs/r/ The name of the file is the name of the resource without a google_ prefix. For example, for google_compute_instance, the file is called compute_instance.html.markdown\nYAML frontmatter# Every resource or datasource documentation page must include YAML frontmatter which sets subcategory (where the page will be displayed in the left sidebar).\n--- subcategory: Cloud Foobar ---Callouts# Use callouts for important information.\n-\u0026gt; **Note** This callout is blue ~\u0026gt; **Note** This callout is yellow !\u0026gt; **Warning** This callout is redSections# Every resource or datasource documentation page must include the following sections as described in Hashicorp\u0026rsquo;s Documenting Providers: Resource/Data Source Headers\nTitle and description. Include a general description of the resource or data source and links to the official product usage documentation and REST API reference. Example:\n# google\\_cloud\\_run\\_locations Get Cloud Run locations available for a project. To get more information about Cloud Run, see: * [API documentation](https://cloud.google.com/run/docs/reference/rest/v1/projects.locations) * How-to Guides * [Official Documentation](https://cloud.google.com/run/docs/)For beta-only resources or data sources, add the following snippet at the end of this section:\nResource ~\u0026gt; **Warning:** This resource is in beta, and should be used with the terraform-provider-google-beta provider. See [Provider Versions](../guides/provider_versions.html.markdown) for more details on beta resources. Data source ~\u0026gt; **Warning:** This data source is in beta, and should be used with the terraform-provider-google-beta provider. See [Provider Versions](../guides/provider_versions.html.markdown) for more details on beta resources. Example Usage. Include a minimal set of examples showing how to use the resource or data source.\nArgument Reference. List settable fields on the datasource. For example:\n## Argument Reference The following arguments are supported: * `name` - (Required) Name of the resource. - - - * `project` - (Optional) The ID of the project in which the resource belongs. If it is not provided, the provider project is used. * `beta_field` - (Optional, [Beta](../guides/provider_versions.html.markdown)) This field is in beta. * `roles` - The MembershipRoles that apply to the Membership. Structure is [documented below](#nested_roles). \u0026lt;a name=\u0026#34;nested_roles\u0026#34;\u0026gt;\u0026lt;/a\u0026gt;The `roles` block supports: * `name` - The name of the MembershipRole. One of OWNER, MANAGER, MEMBER. Attribute Reference. List all output-only fields.\n## Attribute Reference In addition to the arguments listed above, the following computed attributes are exported: * `create_time` - (Output) The time when the repository was created. Note: If a data source is a read-only version of a resource, instead provide a link to the resource documentation to avoid duplicating information:\n## Attribute Reference See [google_FOOBAR](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/FOOBAR#argument-reference) for details of the available attributes. If relevant, also include the following sections:\nTimeouts (example) Import (example) User Project Overrides (example) "},{"id":12,"href":"/magic-modules/breaking-changes/make-a-breaking-change/","title":"Make a breaking change","section":"Breaking changes","content":"Make a breaking change# A \u0026ldquo;breaking change\u0026rdquo; is any change that requires an end user to modify any previously-valid configuration after a provider upgrade. For more information, see Types of breaking changes.\nThe google and google-beta providers are both considered \u0026ldquo;stable surfaces\u0026rdquo; for the purpose of releases, which means that neither provider allows breaking changes except during major releases, which are typically yearly.\nTerraform users rely on the stability of Terraform providers (including the Google Cloud provider and other major providers.) Even as part of a major release, breaking changes that are overly broad and/or have little benefit to users can cause deeply negative reactions and significantly delay customers upgrading to the new major version.\nBreaking changes may cause significant churn for users by forcing them to update their configurations. It also causes churn in tooling built on top of the providers, such as:\nTerraform modules that use google or google-beta resources Policy tools like gcloud terraform vet There may also be churn in customer policies Config Connector Pulumi GCP Classic This page covers the general process to make a breaking change. It does not include exact, comprehensive details on how to make every potential breaking change. Breaking changes are complicated; the exact process and implementation may vary drastically depending on the implementation of the impacted resource or field and the change being made.\nIn minor releases# If a breaking change fixes a bug that impacts all configurations that include a field or resource, it is generally allowed in a minor release. For example:\nRemoving update support from a field if that field is not actually updatable in the API. Marking a field required if omitting the field always causes an API error. Changing a List to a Set where the field is unordered and the order returned from the API changes unpredictably. The following types of changes can be made if the default behavior stays the same and new behavior can be enabled with a flag:\nMajor resource-level or field-level behavioural changes In the 7.0.0 major release# The general process for contributing a breaking change to the 7.0.0 major release is:\nMake the main branch forwards-compatible with the major release Add deprecations and warnings to the main branch of magic-modules Add upgrade guide entries to the FEATURE-BRANCH-major-release-7.0.0 branch of magic-modules Make the breaking change on FEATURE-BRANCH-major-release-7.0.0 These are covered in more detail in the following sections. The upgrade guide and the actual breaking change will be merged only after both are completed.\nMake the main branch forwards-compatible with the major release# What forwards-compatibility means will vary depending on the breaking change. For example:\nIf a required field is being removed, make the field optional on the main branch. If a field is being renamed, the new field must be added to the main branch Add deprecations and warnings to the main branch of magic-modules# Deprecations and warnings must be actionable at the time that they are added to the main branch, and they must be added prior to the 7.0.0 major release. Every deprecation or warning should be surfaced to users of the provider at runtime as well as in documentation.\nField deprecation (due to removal or rename)# MMv1 Set deprecation_message on the field. For example:\n- name: \u0026#39;apiFieldName\u0026#39; type: String description: | MULTILINE_FIELD_DESCRIPTION deprecation_message: \u0026#39;`api_field_name` is deprecated and will be removed in a future major release. Use `other_field_name` instead.\u0026#39;Replace the second sentence with an appropriate short description of the replacement path and/or the reason for deprecation.\nThe deprecation message will automatically show up in the resource documentation.\nHandwritten Set Deprecated on the field. For example:\n\u0026#34;api_field_name\u0026#34;: { Type: schema.String, Deprecated: \u0026#34;`api_field_name` is deprecated and will be removed in a future major release. Use `other_field_name` instead.\u0026#34;, ... }Replace the second sentence with an appropriate short description of the replacement path and/or the reason for deprecation.\nUpdate the documentation for the field to include the deprecation notice. For example:\n* `api_field_name` - (Optional, [Beta](../guides/provider_versions.html.markdown), Deprecated) FIELD_DESCRIPTION. `api_field_name` is deprecated and will be removed in a future major release. Use `other_field_name` instead. Resource deprecation (due to removal or rename)# MMv1 Set deprecation_message on the resource. For example:\ndeprecation_message: \u0026gt;- `google_RESOURCE_NAME` is deprecated and will be removed in a future major release. Use `google_OTHER_RESOURCE_NAME` instead.Replace RESOURCE_NAME with the name of the resource (excluding the google_ prefix). Replace the second sentence with an appropriate short description of the replacement path and/or the reason for deprecation.\nThe deprecation message will automatically show up in the resource documentation.\nHandwritten Set DeprecationMessage on the field. For example:\nreturn \u0026amp;schema.Resource{ ... DeprecationMessage: \u0026#34;`google_RESOURCE_NAME` is deprecated and will be removed in a future \u0026#34; + \u0026#34;major release. Use `google_OTHER_RESOURCE_NAME` instead.\u0026#34;, ... }Replace RESOURCE_NAME with the name of the resource (excluding the google_ prefix). Replace the second sentence with an appropriate short description of the replacement path and/or the reason for deprecation.\nAdd a warning to the resource documentation stating that the resource is deprecated. For example:\n~\u0026gt; **Warning:** `google_RESOURCE_NAME` is deprecated and will be removed in a future major release. Use `google_OTHER_RESOURCE_NAME` instead. Other breaking changes# Other breaking changes should be called out in the docs for the impacted field or resource. It is also great to log warnings at runtime if possible.\nMake the change on FEATURE-BRANCH-major-release-7.0.0# When working on your breaking change, make sure that your base branch is FEATURE-BRANCH-major-release-7.0.0. This means that you will follow the standard contribution process with the following changes:\nBefore you start, check out and sync your local magic-modules and provider repositories with the upstream major release branches. cd ~/magic-modules git checkout FEATURE-BRANCH-major-release-7.0.0 git pull --ff-only origin FEATURE-BRANCH-major-release-7.0.0 cd $GOPATH/src/github.com/hashicorp/terraform-provider-google git checkout FEATURE-BRANCH-major-release-7.0.0 git pull --ff-only origin FEATURE-BRANCH-major-release-7.0.0 cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta git checkout FEATURE-BRANCH-major-release-7.0.0 git pull --ff-only origin FEATURE-BRANCH-major-release-7.0.0 Make sure that any deprecation notices and warnings that you added in previous sections are present on the major release branch. Changes to the main branch will be merged into the major release branch every Monday. Make the breaking change. Add the upgrade guide entries to version_7_upgrade.html.markdown. Entries should focus on the changes that users need to make when upgrading to 7.0.0, rather than how to write configurations after upgrading. See Terraform provider for Google Cloud 6.0.0 Upgrade Guide and other upgrade guides for examples. Remove any deprecation notices and warnings (including in documentation) not already removed by the breaking change. When you create your pull request, change the base branch to FEATURE-BRANCH-major-release-7.0.0 To resolve merge conflicts with git rebase or git merge, use FEATURE-BRANCH-major-release-7.0.0 instead of main. What\u0026rsquo;s next?# Run tests\n"},{"id":13,"href":"/magic-modules/reference/field/","title":"MMv1 field reference","section":"Reference","content":"MMv1 field reference# This page documents commonly-used properties for fields. For a full list of available properties, see type.go ↗.\nShared properties# name# Specifies the name of the field within Terraform. By default this will also be the key for the field in the API request message, if a separate api_name is not declared using the corresponding property.\ntype# Sets the expected data type of the field. All valid types are declared here.\nmin_version: beta# Marks the field (and any subfields) as beta-only. Ensure a beta version block is present in provider.yaml. Do not use if an ancestor field (or the overall resource) is already marked as beta-only.\nimmutable# If true, the field is considered immutable - that is, only settable on create. If unset or false, the field is considered to support update-in-place.\nImmutability is not inherited from field to field: subfields are still considered to be updatable in place by default. However, if the overall resource has immutable set to true, all its fields are considered immutable. Individual fields can override this for themselves and their subfields with update_url if they have a custom update method in the API.\nSee Best practices: Immutable fields for more information.\nExample:\nimmutable: trueupdate_url# If set, changes to the field\u0026rsquo;s value trigger a separate call to a specific API method for updating the field\u0026rsquo;s value. Even if the overall resource is marked immutable, the field and its subfields are not considered immutable unless explicitly marked as such.\nTerraform field names enclosed in double curly braces are replaced with the field values from the resource at runtime.\nExample:\nupdate_url: \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames/{{name}}/setFieldName\u0026#39;update_verb# If update_url is also set, overrides the verb used to update this specific field. Allowed values: \u0026lsquo;POST\u0026rsquo;, \u0026lsquo;PUT\u0026rsquo;, \u0026lsquo;PATCH\u0026rsquo;. Default: Resource\u0026rsquo;s update_verb (which defaults to \u0026lsquo;PUT\u0026rsquo; if unset).\nExample:\nupdate_verb: \u0026#39;POST\u0026#39;required# If true, the field is required. If unset or false, the field is optional.\nExample:\nrequired: trueoutput# If true, the field is output-only - that is, it cannot be configured by the user. If unset or false, the field is configurable.\nExample:\noutput: truesensitive# If true, the field is considered \u0026ldquo;sensitive\u0026rdquo;, which means that its value will be obscured in Terraform output such as plans. If false, the value will not be obscured. Either way, the value will still be stored in plaintext in Terraform state. See Handling Sensitive Values in State for more information.\nSensitive fields are often not returned by the API (because they are sensitive). In this case, the field will also need to use ignore_read or a custom_flatten function.\nExample:\nsensitive: truewrite_only# Set to true to enable write-only functionality for this field. If true, the Write-only Arguments will be automatically generated by the code generator ([field_name]_wo and [field_name]_wo_version). The base field will automatically be marked as sensitive so that the value is obscured in Terraform output but it will still be stored in state. (This is necessary for compatibility with Terraform \u0026lt;v1.11.) The write-only version of the field will be obscured in Terraform output and won\u0026rsquo;t be stored in state. See Ephemerality in Resources - Use Write-only arguments for more information.\nExample:\nwrite_only: trueWarning: This field cannot be used in combination with exactly_one_of on multiple write-only fields. This is planned to be fixed in the future.\nwrite_only_legacy (deprecated)# If true, the field is considered \u0026ldquo;write-only\u0026rdquo;, which means that its value will be obscured in Terraform output as well as not be stored in state. This field is meant to replace sensitive as it doesn\u0026rsquo;t store the value in state. See Ephemerality in Resources - Use Write-only arguments for more information.\nWrite-only fields are only supported in Terraform v1.11+. Because the provider supports earlier Terraform versions, write only fields must be paired with (mutually exclusive) sensitive fields covering the same functionality for compatibility with those older versions. This field cannot be used in conjunction with immutable or sensitive.\nNote: Due to write-only not being read from the API, it is not possible to update the field directly unless a sidecar field is used. (e.g. password as a write-only field and password_wo_version as an immutable field meant for updating).\nExample:\nwrite_only_legacy: trueDeprecated: This field is deprecated and will be removed in a future release.\nignore_read# If true, the provider sets the field\u0026rsquo;s value in the resource state based only on the user\u0026rsquo;s configuration. If false or unset, the provider sets the field\u0026rsquo;s value in the resource state based on the API response. Only use this attribute if the field cannot be read from GCP due to either API or provider constraints.\nignore_read is current not supported inside arrays of nested objects. See tpg#23630 for details and workarounds.\nExample: YAML\nignore_read: truedefault_value# Sets a client-side default value for the field. This should be used if the API has a default value that applies in all cases and is stable. Removing or changing a default value is a breaking change. If unset, the field defaults to an \u0026ldquo;empty\u0026rdquo; value (such as zero, false, or an empty string).\nExample:\ndefault_value: DEFAULT_VALUEdefault_from_api# If true, and the field is either not set or set to an \u0026ldquo;empty\u0026rdquo; value (such as zero, false, or empty strings), the provider accepts any value returned from the API as the value for the field. If false, and the field is either not set or set to an \u0026ldquo;empty\u0026rdquo; value, the provider treats the field\u0026rsquo;s default_value as the value for the field and shows a diff if the API returns any other value for the field. This attribute is useful for complex or frequently-changed API-side defaults, but provides less useful information at plan time than default_value and causes the provider to ignore user configurations that explicitly set the field to an \u0026ldquo;empty\u0026rdquo; value.\nExample:\ndefault_from_api: truesend_empty_value# If true, the provider sends \u0026ldquo;empty\u0026rdquo; values (such as zero, false, or empty strings) to the API if set explicitly in the user\u0026rsquo;s configuration. If false, \u0026ldquo;empty\u0026rdquo; values cause the field to be omitted entirely from the API request. This attribute is useful for fields where the API would behave differently for an \u0026ldquo;empty\u0026rdquo; value vs no value for a particular field - for example, boolean fields that have an API-side default of true.\nIf true simulataneously with default_from_api, the provider will send empty values explicitly set in configuration. If the field is unset, the provider will accept API values as the default as usual with default_from_api.\nDue to a bug, NestedObject fields will currently be sent as null if unset (rather than being omitted.)\nExample:\nsend_empty_value: trueconflicts# Specifies a list of fields (excluding the current field) that cannot be specified at the same time as the current field. Must be set separately on all listed fields. Not supported within lists of nested objects.\nExample:\n- name: \u0026#39;fieldOne\u0026#39; type: String conflicts: - field_two - nested_object.0.nested_fieldrequired_with# Specifies a list of fields (excluding the current field) that must all be specified if at least one is specified. Must be set separately on all listed fields. Not supported within lists of nested objects.\nExample:\n- name: \u0026#39;fieldOne\u0026#39; type: String required_with: - field_two - nested_object.0.nested_fieldexactly_one_of# Specifies a list of fields (including the current field) of which exactly one must be set. Must be set separately on all listed fields. Not supported within lists of nested objects.\nExample:\n- name: \u0026#39;fieldOne\u0026#39; type: String exactly_one_of: - field_one - field_two - nested_object.0.nested_fieldat_least_one_of# Specifies a list of fields (including the current field) that cannot be specified at the same time (but at least one of which must be set). Must be set separately on all listed fields. Not supported within lists of nested objects.\nExample:\n- name: \u0026#39;fieldOne\u0026#39; type: String at_least_one_of: - field_one - field_two - nested_object.0.nested_fielddiff_suppress_func# Specifies the name of a diff suppress function to use for this field. In many cases, a custom flattener is preferred because it will allow the user to see a clearer diff when the field actually is being changed. See Fix diffs for more information and best practices.\nThe function specified can be a provider-specific function (for example, tgpresource.CaseDiffSuppress) or a function defined in resource-specific custom code.\nExample:\n- name: \u0026#39;fieldOne\u0026#39; type: String diff_suppress_func: \u0026#39;tpgresource.CaseDiffSuppress\u0026#39;validation# In many cases, it is better to avoid client-side validation. See Best practices: Validation for more information.\nControls the value set for the field\u0026rsquo;s ValidateFunc.\nFor Enum fields, this will override the default validation (that the provided value is one of the enum values). If you need additional validation on top of an enum, ensure that the supplied validation func also verifies the enum values are correct.\nThis property has two mutually exclusive child properties:\nfunction: The name of a validation function to use for validation. The function can be a Terraform-provided function (for example, validation.IntAtLeast(0)), a provider-specific function (for example, verify.ValidateBase64String), or a function defined in resource-specific custom code. regex: A regex string to check values against. This can only be used on simple String fields. It is equivalent to function: verify.ValidateRegexp(REGEX_STRING). validation is not supported for Array fields (including sets); however, individual elements in the array can be validated using item_validation.\nExample: Provider-specific function\n- name: \u0026#39;fieldOne\u0026#39; type: String validation: function: \u0026#39;verify.ValidateBase64String\u0026#39;Example: Regex\n- name: \u0026#39;fieldOne\u0026#39; type: String validation: regex: \u0026#39;^[a-zA-Z][a-zA-Z0-9_]*$\u0026#39;is_set# If true, the field is a Set rather than an Array. Set fields represent an unordered set of unique elements. set_hash_func may be used to customize the hash function used to index elements in the set, otherwise the schema default function will be used. Adding this property to an existing field is usually a breaking change.\n- name: \u0026#39;fieldOne\u0026#39; type: Array is_set: trueset_hash_func# Specifies a function for hashing elements in a Set field. If unspecified, schema.HashString will be used if the elements are strings, otherwise schema.HashSchema. The hash function should be defined in custom_code.constants.\nset_hash_func: functionNameapi_name# Specifies a name to use for communication with the API that is different than the name of the field in Terraform. In general, setting an api_name is not recommended, because it makes it more difficult for users and maintainers to understand how the resource maps to the underlying API.\n- name: \u0026#39;fieldOne\u0026#39; type: String api_name: otherFieldNameurl_param_only# If true, the field is not sent in the resource body, and the provider does not read the field value from the API response. If unset or false, the field is sent in the resource body, and the provider reads the field value from the API response.\nurl_param_only: trueEnum properties# enum_values# Enum only. If the allowed values may change in the future, use a String field instead and link to API documentation stating the current allowed values in the String field\u0026rsquo;s description. See Best practices: Validation for more information.\nDo not include UNSPECIFIED values in this list.\nEnums will validate that the provided field is in the allowed list unless a custom validation is provided.\nExample:\nenum_values: - \u0026#39;VALUE_ONE\u0026#39; - \u0026#39;VALUE_TWO\u0026#39;Array properties# item_type# Array only. Sets the expected type of the items in the array. Primitives should use the name of the primitive class as a string; other types should define the attributes of the nested type.\nExample: Primitive value\nitem_type: type: StringExample: Enum value\nitem_type: type: Enum description: \u0026#39;required but unused\u0026#39; values: - \u0026#39;VALUE_ONE\u0026#39; - \u0026#39;VALUE_TWO\u0026#39;Example: Nested object\nitem_type: type: NestedObject properties: - name: \u0026#39;FIELD_NAME\u0026#39; type: String description: | MULTI_LINE_FIELD_DESCRIPTIONmin_size# Array only. Validates that the array has at least this many items in it.\nIn many cases, it is better to avoid client-side validation. See Best practices: Validation for more information.\nExample:\n- name: \u0026#39;fieldOne\u0026#39; type: Array item_type: type: String min_size: 1max_size# Array only. Validates that the array has at most this many items in it.\nIn many cases, it is better to avoid client-side validation. See Best practices: Validation for more information.\nExample:\n- name: \u0026#39;fieldOne\u0026#39; type: Array item_type: type: String max_size: 10item_validation# Array only. Controls the ValidateFunc used to validate individual items in the array. Behaves like validation.\nIn many cases, it is better to avoid client-side validation. See Best practices: Validation for more information.\nFor arrays of enums, this will override the default validation (that the provided value is one of the enum values). If you need additional validation on top of an enum, ensure that the supplied validation func also verifies the enum values are correct.\nExample: Provider-specific function\n- name: \u0026#39;fieldOne\u0026#39; type: Array item_type: type: String item_validation: function: \u0026#39;verify.ValidateBase64String\u0026#39;Example: Regex\n- name: \u0026#39;fieldOne\u0026#39; type: Array item_type: type: String item_validation: regex: \u0026#39;^[a-zA-Z][a-zA-Z0-9_]*$\u0026#39;Example: Enum\n- name: \u0026#39;fieldOne\u0026#39; type: Array item_type: type: Enum description: \u0026#39;required but unused\u0026#39; values: - \u0026#39;VALUE_ONE\u0026#39; - \u0026#39;VALUE_TWO\u0026#39; item_validation: function: \u0026#39;customFunction\u0026#39;NestedObject properties# properties# NestedObject only. Defines fields nested inside the current field.\nExample:\nproperties: - name: \u0026#39;FIELD_NAME\u0026#39; type: String description: | MULTI_LINE_FIELD_DESCRIPTION"},{"id":14,"href":"/magic-modules/test/run-tests/","title":"Run tests","section":"Test","content":"Run tests# Before you begin# Generate the modified provider(s)\nSet up application default credentials for Terraform\ngcloud auth application-default login export GOOGLE_USE_DEFAULT_CREDENTIALS=true Set the following environment variables:\nexport GOOGLE_PROJECT=PROJECT_ID export GOOGLE_REGION=us-central1 export GOOGLE_ZONE=us-central1-aReplace PROJECT_ID with the ID of the Google Cloud project you are using for testing.\nOptional: Some tests may require additional variables to be set, such as:\nGOOGLE_ORG GOOGLE_BILLING_ACCOUNT Run automated tests# GA Provider Run unit tests and linters\ncd $GOPATH/src/github.com/hashicorp/terraform-provider-google make test make lint Run acceptance tests for only modified resources. (Full test runs can take over 9 hours.) See Go\u0026rsquo;s documentation for more information about -run and other flags.\nmake testacc TEST=./google/services/container TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic$$\u0026#39;To run all tests matching, e.g., TestAccContainerNodePool*, omit the trailing $$:\nmake testacc TEST=./google/services/container TESTARGS=\u0026#39;-run=TestAccContainerNodePool\u0026#39; Note: Acceptance tests create actual infrastructure which can incur costs. Acceptance tests may not clean up after themselves if interrupted, so you may want to check for stray resources and / or billing charges.\nOptional: Save verbose test output (including API requests and responses) to a file for analysis.\nTF_LOG=DEBUG make testacc TEST=./google/services/container TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic$$\u0026#39; \u0026gt; output.log Optional: Debug tests with Delve. See dlv test documentation for information about available flags.\ncd google TF_ACC=1 dlv test -- --test.v --test.run TestAccComputeRegionBackendService_withCdnPolicy Beta Provider Run unit tests and linters\ncd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta make test make lint Run acceptance tests for only modified resources. (Full test runs can take over 9 hours.) See Go\u0026rsquo;s documentation for more information about -run and other flags.\nmake testacc TEST=./google-beta/services/container TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic$$\u0026#39;To run all tests matching, e.g., TestAccContainerNodePool*, omit the trailing $$:\nmake testacc TEST=./google-beta/services/container TESTARGS=\u0026#39;-run=TestAccContainerNodePool\u0026#39; Note: Acceptance tests create actual infrastructure which can incur costs. Acceptance tests may not clean up after themselves if interrupted, so you may want to check for stray resources and / or billing charges.\nOptional: Save verbose test output to a file for analysis.\nTF_LOG=DEBUG make testacc TEST=./google-beta/services/container TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic$$\u0026#39; \u0026gt; output.log Optional: Debug tests with Delve. See dlv test documentation for information about available flags.\ncd google-beta TF_ACC=1 dlv test -- --test.v --test.run TestAccComputeRegionBackendService_withCdnPolicy Troubleshooting acceptance tests# After applying this test step, the plan was not empty.# This indicates that the returned values from the API (which will be displayed on the left) are different than what is in the configuration (displayed on the right). Fields which are listed as \u0026ldquo;known after apply\u0026rdquo; are not the cause of the diff and can be ignored in terms of resolving the issue.\nSee Fix diffs for more information on potential causes and fixes.\nBlocks of type \u0026ldquo;FIELD_NAME\u0026rdquo; are not expected here# The field called FIELD_NAME does not exist; this is either because it has not been implemented or because the test is running for the google provider and the field is only implemented in the google-beta provider. See Add resource tests for information on using version guards to exclude beta-only fields from GA tests, or Promote from beta to GA for information on how to promote fields that were accidentally made beta-only.\nProvider produced inconsistent result after apply \u0026hellip; Root object was present, but now absent.# This indicates that after an apply to create or update a resource, the resource was not present in Terraform state. This generally means one of a few things:\nAPI is eventually consistent or returns an Operation The URL for reads was built incorrectly. The exact fix will depend on why this is happening. Run the test with the TF_LOG=DEBUG environment variable and check whether the read URL matches what you expect. There is a call to unset the resource\u0026rsquo;s id (d.SetId(\u0026quot;\u0026quot;)) somewhere it shouldn\u0026rsquo;t be. The fix is to remove that extraneous call. This is rare. Error: Inconsistent dependency lock file# Tests require all of the providers they use (except the one actually being tested) to be explicitly stated. This error generally means one of a few things:\nIf the error mentions provider registry.terraform.io/hashicorp/google: Beta-only test: This indicates that one of the google_* resources in the test doesn\u0026rsquo;t have provider = google-beta set resource \u0026#34;google_compute_instance\u0026#34; \u0026#34;beta-instance\u0026#34; { provider = google-beta # ... } GA+beta test: This indicates that the wrong setting is being used for ProtoV5ProviderFactories on a handwritten test case. Should be: acctest.VcrTest(t, resource.TestCase{ // ... ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories(t), If the error mentions provider registry.terraform.io/hashicorp/google-beta: Beta-only test: This indicates that the wrong setting is being used for ProtoV5ProviderFactories on a handwritten test case. Should be: acctest.VcrTest(t, resource.TestCase{ // ... ProtoV5ProviderFactories: acctest.ProtoV5ProviderBetaFactories(t), GA+beta test: This indicates that one of the google_* resources in the test has provider = google-beta set. provider = google-beta can\u0026rsquo;t be set unless the test is beta-only. If the error mentions some other provider: The test relies on an external provider, such as time, and that is not explicitly declared For MMv1 example-based tests, use examples.external_providers. For Handwritten tests, use TestCase.ExternalProviders: acctest.VcrTest(t, resource.TestCase{ ExternalProviders: map[string]resource.ExternalProvider{ \u0026#34;time\u0026#34;: {}, }, // ... } Optional: Test with different terraform versions# Tests will use whatever version of the terraform binary is found on your PATH. If you are testing a change that you know only impacts certain terraform versions, follow these steps:\nInstall tfenv.\nInstall the version of terraform you want to test.\ntfenv install VERSIONReplace VERSION with the version you want to test.\nRun automated tests following the earlier section.\nOptional: Test manually# For manual testing, you can build the provider from source and run terraform apply to verify the behavior.\nBefore you begin# Configure Terraform to use locally-built binaries for google and google-beta instead of downloading the latest versions.\nDeveloper overrides (Mac / Linux) Find the location where built provider binaries are created. To do this, run this command and make a note of the path value:\ngo env GOBIN ## If the above returns nothing, then run the command below and add \u0026#34;/bin\u0026#34; to the end of the output path. go env GOPATH Create an empty configuration file.\n## create an empty file touch ~/tf-dev-override.tfrc ## open the file with a text editor of your choice, e.g: vi ~/tf-dev-override.tfrcOpen the empty file with a text editor and paste in these contents:\nprovider_installation { # Developer overrides will stop Terraform from downloading the listed # providers their origin provider registries. dev_overrides { \u0026#34;hashicorp/google\u0026#34; = \u0026#34;GO_BIN_PATH/bin\u0026#34; \u0026#34;hashicorp/google-beta\u0026#34; = \u0026#34;GO_BIN_PATH/bin\u0026#34; } # For all other providers, install them directly from their origin provider # registries as normal. If you omit this, Terraform will _only_ use # the dev_overrides block, and so no other providers will be available. direct {} } Edit the file to replace GO_BIN_PATH with the path you saved from the first step, making sure to keep /bin at the end of the path.\nPlease note: the full path is required and environment variables cannot be used. For example, \u0026quot;/Users/UserName/go/bin\u0026quot; is a valid path for a user called UserName, but \u0026quot;~/go/bin\u0026quot; or \u0026quot;$HOME/go/bin\u0026quot; will not work.\nSave the file.\nDeveloper overrides (Windows) Find the location where built provider binaries are created. To do this, run this command and make a note of the path value:\necho %GOPATH% Create an empty configuration file in the %APPDATA% directory (use $env:APPDATA in PowerShell to find its location on your system).\n## create an empty file type nul \u0026gt; \u0026#34;$($env:APPDATA)\\tf-dev-override.tfrc\u0026#34; ## open the file with a text editor of your choice, e.g: notepad \u0026#34;$($env:APPDATA)\\tf-dev-override.tfrc\u0026#34;Open the empty file with a text editor and paste in these contents:\nprovider_installation { # Developer overrides will stop Terraform from downloading the listed # providers their origin provider registries. dev_overrides { \u0026#34;hashicorp/google\u0026#34; = \u0026#34;GO_BIN_PATH\\bin\u0026#34; \u0026#34;hashicorp/google-beta\u0026#34; = \u0026#34;GO_BIN_PATH\\bin\u0026#34; } # For all other providers, install them directly from their origin provider # registries as normal. If you omit this, Terraform will _only_ use # the dev_overrides block, and so no other providers will be available. direct {} } Edit the file to replace GO_BIN_PATH with the output you saved from the first step, making sure to keep \\bin at the end of the path.\nPlease note: The full path is required and environment variables cannot be used. For example, C:\\Users\\UserName\\go\\bin is a valid path for a user called UserName.\nSave the file.\nRun manual tests# Generate the provider(s) you want to test\nBuild the provider(s) you want to test\n## google provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google make build ## google-beta provider cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta make build Create a new directory and a main.tf file with your resource and its dependencies.\nIn the new directory, run terraform plan as follows:\nTF_CLI_CONFIG_FILE=\u0026#34;$HOME/tf-dev-override.tfrc\u0026#34; terraform planReplace the TF_CLI_CONFIG_FILE value with the full path to your developer overrides file.\nOptional: Verify that developer overrides are working by looking for output like the following near the start of the output:\n│ Warning: Provider development overrides are in effect │ │ The following provider development overrides are set in the CLI configuration: │ - hashicorp/google in /Users/UserName/go/bin │ - hashicorp/google-beta in /Users/UserName/go/bin │ │ The behavior may therefore not match any released version of the provider and applying │ changes may cause the state to become incompatible with published releases. Run terraform apply with developer overrides.\nTF_CLI_CONFIG_FILE=\u0026#34;$HOME/tf-dev-override.tfrc\u0026#34; terraform apply Optional: Save verbose terraform apply output (including API requests and responses) to a file for analysis.\nTF_LOG=DEBUG TF_LOG_PATH=output.log TF_CLI_CONFIG_FILE=\u0026#34;$HOME/tf-dev-override.tfrc\u0026#34; terraform apply Run Tests with VCR Locally# VCR tests record HTTP request/response interactions in cassettes and replay them in future runs without calling the real API.\nRunning tests in REPLAYING mode locally can sometimes be useful. In particular, it can allow you to test more quickly, cheaply, and without spinning up real infrastructure, once you\u0026rsquo;ve got an initial recording.\nIt can also be helpful for debugging tests that seem to work locally, but fail in CI in replaying mode.\nVCR is controlled via two variables:\nVCR_MODE: REPLAYING or RECORDING mode VCR_PATH: Path where recorded cassettes are stored. Ensure both variables are configured to properly trigger VCR tests locally.\nIf you don\u0026rsquo;t already have an existing cassette that\u0026rsquo;s up to date, first do a run in RECORDING mode:\nVCR_PATH=$HOME/.vcr/ VCR_MODE=RECORDING make testacc TEST=./google/services/alloydb TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic$$\u0026#39;Now run the same test again in REPLAYING mode:\nVCR_PATH=$HOME/.vcr/ VCR_MODE=REPLAYING make testacc TEST=./google/services/alloydb TESTARGS=\u0026#39;-run=TestAccContainerNodePool_basic$$\u0026#39;Cleanup# To stop using developer overrides, stop setting TF_CLI_CONFIG_FILE in the commands you are executing.\nTerraform will resume its normal behaviour of pulling published provider versions from the public Registry. Any version constraints in your Terraform configuration will come back into effect. Also, you may need to run terraform init to download the required version of the provider into your project directory if you haven\u0026rsquo;t already.\nWhat\u0026rsquo;s next?# Create a pull request\n"},{"id":15,"href":"/magic-modules/code-review/release-notes/","title":"Write release notes","section":"Code review","content":"Write release notes# This guide explains best practices for composing accurate, end-user focused release notes for Magic Modules pull requests.\nEvery pull request must have at least one release note block in the opening comment. Release note blocks have the following format:\n```release-note:TYPE CONTENT ```Replace TYPE with the correct release note type, and CONTENT with a release note written according to the guidelines in the following sections.\nGeneral guidelines# Do Don\u0026rsquo;t Only have one CONTENT line per release note block. Use multiple blocks if there are multiple related changes in a single PR. Don\u0026rsquo;t add multiple lines to a single release note block. Avoid combining multiple distinct types of changes into one release block. If a change only affects the google-beta provider add (beta) to the end of the release note. If a change only affects the google provider add (ga) to the end of the release note. Don\u0026rsquo;t add either suffix if the change affects both providers. Set an appropriate release note type. Don\u0026rsquo;t leave the type as REPLACEME. Type-specific guidelines and examples# New field(s) Write your release note in the following format:\n```release-note:enhancement PRODUCT: added `FIELD_1`, `FIELD_2`, and `FIELD_N` fields to `RESOURCE_NAME` resource ```Replace PRODUCT, FIELD_*, and RESOURCE_NAME according to the pull request content. For example:\n```release-note:enhancement compute: added `foo_bar` field to `google_compute_foo` resource ``` New resource Write your release note in the following format:\n```release-note:new-resource `RESOURCE_NAME` ```Replace RESOURCE_NAME according to the pull request content. For example:\n```release-note:new-resource `google_compute_new_resource` ``` New datasource Write your release note in the following format:\n```release-note:new-datasource `DATASOURCE_NAME` ```Replace DATASOURCE_NAME according to the pull request content. For example:\n```release-note:new-datasource `google_compute_new_datasource` ``` Other Choose a release note type# For each release note block, choose an appropriate type from the following list:\nenhancement : New features on existing resources bug : Bug fix deprecation : A field/resource is being marked as deprecated (not being removed) breaking-change : Changes that require users to change their configuration note : General type for other notes that might be relevant to users but don\u0026rsquo;t fit into another category none : Changes where there is no user impact, like test fixes, website updates and CI changes. Release notes of this type should be empty. Guidelines# Do Don\u0026rsquo;t Use past tense to describe the end state after the change is released. Start with a verb. For example, \u0026ldquo;added\u0026hellip;\u0026rdquo;, \u0026ldquo;fixed\u0026hellip;\u0026rdquo;, or \u0026ldquo;resolved\u0026hellip;\u0026rdquo;. You can use future tense to describe future changes, such as saying that a deprecated field will be removed in a future version. Don\u0026rsquo;t use present or future tense to describe changes that are included in the pull request. Write user-focused release notes. For example, reference specific impacted terraform resource and field names, and discuss changes in behavior users will experience. Avoid API field/resource/feature names. Avoid implementation details. Avoid language that requires understanding of provider internals. However, in case of substantial refactorings like API version changes or engine changes (tpgtools/DCL -\u0026gt; MMv1, handwritten \u0026lt;\u0026gt; MMv1) do cover the change so users can quickly identify the release if they are affected by the change. Surround resource or field names with backticks. Don\u0026rsquo;t use resource or field names without punctuation or with other punctuation like quotation marks. Use impersonal third person. Don\u0026rsquo;t use \u0026ldquo;I\u0026rdquo;, \u0026ldquo;you\u0026rdquo;, etc. If the pull request impacts a specific product, begin your release note with that product name followed by a colon. Use lower case for the first letter after the colon. For example, cloudrun: added... For MMv1 resources, use the folder name that contains the yaml files as the product name; for handwritten or tpgtools resources, use the API subdomain; for broad cross-product changes, use provider. Don\u0026rsquo;t begin your release note with the full resource name. Don\u0026rsquo;t add backticks around the product name. Don\u0026rsquo;t capitalize the first letter after the colon. Examples# ```release-note:bug cloudrun: fixed perma-diff in `google_cloud_run_service` ``````release-note:deprecation container: deprecated `region` and `zone` on `google_container_unicorn`. Use `location` instead. ``` "},{"id":16,"href":"/magic-modules/develop/add-fields/","title":"Add a field to an existing resource","section":"Develop","content":"Add a field to an existing resource# This page describes how to add a field to an existing resource in the google or google-beta Terraform provider using MMv1 and/or handwritten code. In general, Terraform resources should implement all configurable fields and all read-only fields. Even fields that seem like they would not be useful in Terraform (like update time or etag) often end up being requested by users, so it\u0026rsquo;s usually easier to just add them all at once. However, optional or read-only fields can be omitted when adding a resource if they would require significant additional work to implement.\nFor more information about types of resources and the generation process overall, see How Magic Modules works.\nBefore you begin# Complete the steps in Set up your development environment to set up your environment and your Google Cloud project. Ensure the resource to which you want to add the fields exists in the provider. Ensure that your magic-modules, terraform-provider-google, and terraform-provider-google-beta repositories are up to date. cd ~/magic-modules git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull Add fields# MMv1 For each API field, copy the following template into the resource\u0026rsquo;s properties attribute. Be sure to indent appropriately. Simple - name: \u0026#39;API_FIELD_NAME\u0026#39; type: String description: | MULTILINE_FIELD_DESCRIPTION min_version: beta immutable: true required: true output: true conflicts: - field_one - nested_object.0.nested_field exactly_one_of: - field_one - nested_object.0.nested_fieldReplace String in the field type with one of the following options:\nString Integer Boolean Double KeyValuePairs (string -\u0026gt; string map) KeyValueLabels (for standard resource \u0026rsquo;labels\u0026rsquo; field) KeyValueAnnotations (for standard resource \u0026lsquo;annotations\u0026rsquo; field) Enum - name: \u0026#39;API_FIELD_NAME\u0026#39; type: Enum description: | MULTILINE_FIELD_DESCRIPTION min_version: beta immutable: true required: true output: true conflicts: - field_one - nested_object.0.nested_field exactly_one_of: - field_one - nested_object.0.nested_field enum_values: - \u0026#39;VALUE_ONE\u0026#39; - \u0026#39;VALUE_TWO\u0026#39; ResourceRef - name: \u0026#39;API_FIELD_NAME\u0026#39; type: ResourceRef description: | MULTILINE_FIELD_DESCRIPTION min_version: beta immutable: true required: true output: true conflicts: - field_one - nested_object.0.nested_field exactly_one_of: - field_one - nested_object.0.nested_field resource: \u0026#39;ResourceName\u0026#39; imports: \u0026#39;name\u0026#39; Array - name: \u0026#39;API_FIELD_NAME\u0026#39; type: Array description: | MULTILINE_FIELD_DESCRIPTION min_version: beta immutable: true required: true output: true conflicts: - field_one - nested_object.0.nested_field exactly_one_of: - field_one - nested_object.0.nested_field # Array of primitives item_type: type: String # Array of nested objects item_type: type: NestedObject properties: - name: \u0026#39;FIELD_NAME\u0026#39; type: String description: | MULTI_LINE_FIELD_DESCRIPTION NestedObject - name: \u0026#39;API_FIELD_NAME\u0026#39; type: NestedObject description: | MULTILINE_FIELD_DESCRIPTION min_version: beta immutable: true required: true output: true conflicts: - field_one - nested_object.0.nested_field exactly_one_of: - field_one - nested_object.0.nested_field properties: - name: \u0026#39;FIELD_NAME\u0026#39; type: String description: | MULTI_LINE_FIELD_DESCRIPTION Map - name: \u0026#39;API_FIELD_NAME\u0026#39; type: Map description: | MULTILINE_FIELD_DESCRIPTION key_name: \u0026#39;key_name\u0026#39; # Map of primitive values value_type: type: Integer # Map of complex values value_type: type: NestedObject properties: - name: \u0026#39;FIELD_NAME\u0026#39; type: String description: | MULTI_LINE_FIELD_DESCRIPTIONThis type is used for general-case string -\u0026gt; non-string type mappings, use \u0026ldquo;KeyValuePairs\u0026rdquo; for string -\u0026gt; string mappings. Complex maps can\u0026rsquo;t be represented natively in Terraform, and this type is transformed into an associative array (TypeSet) with the key merged into the object alongside other top-level fields.\nFor key_name, provide a domain-appropriate field name. For example, a map that references a specific type of resource would generally use the singular resource kind as the key name (such as \u0026ldquo;topic\u0026rdquo; for PubSub Topic).\nModify the field configuration according to the API documentation and behavior. Note: The templates in this section only include the most commonly-used fields. For a comprehensive reference, see MMv1 field reference. For information about modifying the values sent and received for a field, see Modify the API request or response.\nHandwritten Add the field to the handwritten resource\u0026rsquo;s schema. The new field(s) should mirror the API\u0026rsquo;s structure to ease predictability and maintenance. However, if there is an existing related / similar field in the resource that uses a different convention, follow that convention instead. Enum fields in the API should be represented as TypeString in Terraform for forwards-compatibility. Link to the API documentation of allowed values in the field description. Terraform field names should always use snake case ↗. See Schema Types ↗ and Schema Behaviors ↗ for more information about field schemas. Add handling for the new field in the resource\u0026rsquo;s Create method and Update methods. \u0026ldquo;Expanders\u0026rdquo; convert Terraform resource data to API request data. For top level fields, add an expander. If the field is set or has changed, call the expander and add the resulting value to the API request. For other fields, add logic to the parent field\u0026rsquo;s expander to add the field to the API request. Use a nested expander for complex logic. Add handling for the new field in the resource\u0026rsquo;s Read method. \u0026ldquo;Flatteners\u0026rdquo; convert API response data to Terraform resource data. For top level fields, add a flattener. Call d.Set() on the flattened API response value to store it in Terraform state. For other fields, add logic to the parent field\u0026rsquo;s flattener to convert the value from the API response to the Terraform state value. Use a nested flattener for complex logic. If any of the added Go code (including any imports) is beta-only, change the file suffix to .go.tmpl and wrap the beta-only code in a version guard: {{- if ne $.TargetVersionName \u0026quot;ga\u0026quot; -}}...{{- else }}...{{- end }}. Add a new guard rather than adding the field to an existing guard; it is easier to read. What\u0026rsquo;s next?# Add IAM support Add documentation Add custom resource code Add tests Run tests "},{"id":17,"href":"/magic-modules/best-practices/labels-and-annotations/","title":"Labels and annotations","section":"Best practices","content":"Add labels and annotations support# Note: This page covers best practices guidance for the Terraform provider for Google Cloud, which is used to ensure a consistent UX for Terraform users across providers or GCP users across the Google provider. Generally, this guidance should be followed and exceptions should be clearly demarcated / discussed.\nThe new labels model and the new annotations model are introduced in Terraform provider for Google Cloud 5.0.0.\nThere are now three label-related fields with the new labels model:\nThe labels field is now non-authoritative and only manages the label keys defined in your configuration for the resource. The terraform_labels cannot be specified directly by the user. It merges the labels defined in the resource\u0026rsquo;s configuration and the default labels configured in the provider block. If the same label key exists on both the resource level and provider level, the value on the resource will override the provider-level default. The output-only effective_labels will list all the labels present on the resource in GCP, including the labels configured through Terraform, the system, and other clients. There are now two annotation-related fields with the new annotations model:\nThe annotations field is now non-authoritative and only manages the annotation keys defined in your configuration for the resource. The output-only effective_annotations will list all the annotations present on the resource in GCP, including the annotations configured through Terraform, the system, and other clients. This document describes how to add labels and annotations field to resources to support the new models.\nLabels support# When adding a new labels field, please make the changes below to support the new labels model. Otherwise, it has to wait for the next major release to make the changes.\nMMv1 resources# Use the type KeyValueLabels for the standard resource labels field. The standard resource labels field could be the top level labels field or the nested labels field inside the top level metadata field. Don\u0026rsquo;t add default_from_api: true to this field or don\u0026rsquo;t use this type for other labels fields in the resource. KeyValueLabels will add all of changes required for the new model automatically.\n- name: \u0026#39;labels\u0026#39; type: KeyValueLabels description: | The labels associated with this dataset. You can use these to organize and group your datasets. In the handwritten acceptance tests, add labels and terraform_labels to ImportStateVerifyIgnore if labels field is in the configuration.\nImportStateVerifyIgnore: []string{\u0026#34;labels\u0026#34;, \u0026#34;terraform_labels\u0026#34;}, In the corresponding data source, after the resource read method, call the function tpgresource.SetDataSourceLabels(d) to make labels and terraform_labels have all of the labels on the resource.\nerr = resourceArtifactRegistryRepositoryRead(d, meta) if err != nil { return err } if err := tpgresource.SetDataSourceLabels(d); err != nil { return err } Handwritten resources# Add tpgresource.SetLabelsDiff to CustomizeDiff of the resource. CustomizeDiff: customdiff.All( tpgresource.SetLabelsDiff, ), Add labels field and add more attributes (such as ForceNew: true,, Set: schema.HashString,) to this field if necessary. \u0026#34;labels\u0026#34;: { Type: schema.TypeMap, Optional: true, Elem: \u0026amp;schema.Schema{Type: schema.TypeString}, Description: `A set of key/value label pairs to assign to the project. **Note**: This field is non-authoritative, and will only manage the labels present in your configuration. Please refer to the field \u0026#39;effective_labels\u0026#39; for all of the labels present on the resource.`, }, Add output only field terraform_labels and add more attributes (such as Set: schema.HashString,) to this field if necessary. Don\u0026rsquo;t add ForceNew:true, to this field. \u0026#34;terraform_labels\u0026#34;: { Type: schema.TypeMap, Computed: true, Description: `The combination of labels configured directly on the resource and default labels configured on the provider.`, Elem: \u0026amp;schema.Schema{Type: schema.TypeString}, }, Add output only field effective_labels and add more attributes (such as ForceNew: true,, Set: schema.HashString,) to this field if necessary. \u0026#34;effective_labels\u0026#34;: { Type: schema.TypeMap, Computed: true, Description: `All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Terraform, other clients and services.`, Elem: \u0026amp;schema.Schema{Type: schema.TypeString}, }, In the create method, use the value of effective_labels in API request. In the update method, use the value of effective_labels in API request. In the read mehtod, set labels, terraform_labels and effective_labels to state. if err := tpgresource.SetLabels(res.Labels, d, \u0026#34;labels\u0026#34;); err != nil { return fmt.Errorf(\u0026#34;Error setting labels: %s\u0026#34;, err) } if err := tpgresource.SetLabels(res.Labels, d, \u0026#34;terraform_labels\u0026#34;); err != nil { return fmt.Errorf(\u0026#34;Error setting terraform_labels: %s\u0026#34;, err) } if err := d.Set(\u0026#34;effective_labels\u0026#34;, res.Labels); err != nil { return fmt.Errorf(\u0026#34;Error setting effective_labels: %s\u0026#34;, err) } In the handwritten acceptance tests, add labels and terraform_labels to ImportStateVerifyIgnore. In the corresponding data source, after the resource read method, call the function tpgresource.SetDataSourceLabels(d) to make labels and terraform_labels have all of the labels on the resource. Add the documentation for these label-related fields. Annotations support# When adding a new annotations field, please make the changes below below to support the new annotations model. Otherwise, it has to wait for the next major release to make the breaking changes.\nMMv1 resources# Use the type KeyValueAnnotations for the standard resource annotations field. The standard resource annotations field could be the top level annotations field or the nested annotations field inside the top level metadata field. Don\u0026rsquo;t add default_from_api: true to this field or don\u0026rsquo;t use this type for other annotations fields in the resource. KeyValueAnnotations will add all of changes required for the new model automatically.\n- name: \u0026#39;annotations\u0026#39; type: KeyValueAnnotations description: | Client-specified annotations. This is distinct from labels. In the handwritten acceptance tests, add annotations to ImportStateVerifyIgnore if annotations field is in the configuration.\nImportStateVerifyIgnore: []string{\u0026#34;annotations\u0026#34;}, In the corresponding data source, after the resource read method, call the function tpgresource.SetDataSourceAnnotations(d) to make annotations have all of the annotations on the resource.\nerr = resourceSecretManagerSecretRead(d, meta) if err != nil { return err } if err := tpgresource.SetDataSourceLabels(d); err != nil { return err } if err := tpgresource.SetDataSourceAnnotations(d); err != nil { return err } Handwritten resources# Add tpgresource.SetAnnotationsDiff to CustomizeDiff of the resource. Add annotations field and add more attributes (such as ForceNew: true,, Set: schema.HashString,) to this field if necessary. Add output only field effective_annotations and add more attributes (such as ForceNew: true,, Set: schema.HashString,) to this field if necessary. In the create method, use the value of effective_annotations in API request. In the update method, use the value of effective_annotations in API request. In the read mehtod, set annotations, and effective_annotations to state. In the handwritten acceptance tests, add annotations to ImportStateVerifyIgnore. In the corresponding data source, after the resource read method, call the function tpgresource.SetDataSourceAnnotations(d) to make annotations have all of the labels on the resource. Add the documentation for these annotation-related fields. "},{"id":18,"href":"/magic-modules/reference/make-commands/","title":"make commands","section":"Reference","content":"make commands reference# magic-modules# make / make provider# Generates the code for the downstream google and google-beta providers into the OUTPUT_PATH, overriding and deleting any local changes.\nNote: Generation works best if the downstream provider has a commit checked out corresponding to the latest main branch commit that is present in your magic-modules working branch. This can generally be identified based on matching commit messages.\nExamples:\nmake provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; make provider VERSION=beta OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google-beta\u0026#34; # Only generate a specific product (plus all common files) make provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; PRODUCT=pubsub # Only generate only a specific resources for a product make provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; PRODUCT=pubsub RESOURCE=Topic # Only generate common files, including all third_party code make provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; PRODUCT=doesnotexistArguments# OUTPUT_PATH: Required. The location you are generating provider code into. VERSION: Required. The version of the provider you are building into. Valid values are ga and beta. PRODUCT: Limits generations to the specified folder within mmv1/products or tpgtools/api. Handwritten files from mmv1/third_party/terraform are always generated into the downstream regardless of this setting, so you can provide a non-existent product name to generate only handwritten code. Required if RESOURCE is specified. Using PRODUCT skips the pre-generation cleanup step. This is considered advanced usage; recommend running a full, clean build (make provider without PRODUCT) beforehand if repositories may be out of sync. SKIP_CLEAN: If set to true, skips the default pre-generation cleanup of OUTPUT_PATH during a full provider build. Has no effect if PRODUCT is specified (as cleanup is already skipped). Example: make provider VERSION=ga OUTPUT_PATH=... SKIP_CLEAN=true. RESOURCE: Limits generation to the specified resource within a particular product. For mmv1 resources, matches the resource\u0026rsquo;s name field (set in its configuration file).For tpgtools resources, matches the terraform resource name. ENGINE: Modifies make provider to only generate code using the specified engine. Valid values are mmv1 or tpgtools. (Providing tpgtools will still generate any prerequisite mmv1 files required for tpgtools.) Cleaning up old files# Magic Modules will only generate on top of whatever is in the downstream repository. This means that, from time to time, you may end up with stale files or changes in your downstream that cause compilation or tests to fail.\nYou can clean up by running the following command in your downstream repositories:\ngit checkout -- . \u0026amp;\u0026amp; git clean -f google/ google-beta/ website/Container-based environment# This approach is in beta and still collecting feedback. Please file an issue if you encounter challenges.\n./scripts/make-in-container.sh runs make with the provided arguments inside a container with all necessary dependencies preinstalled. It uses Docker if available and Podman otherwise. Like make, this script must be run in the root of a magic-modules repository clone.\nIf you run into any problems, please file an issue.\nBefore you begin# Ensure that GOPATH is set on your host machine.\nprintenv | grep GOPATHIf not, add export GOPATH=$HOME/go to your terminal\u0026rsquo;s startup script and restart your terminal.\nClone the google and google-beta provider repositories with the following commands:\ngit clone https://github.com/hashicorp/terraform-provider-google.git $GOPATH/src/github.com/hashicorp/terraform-provider-google git clone https://github.com/hashicorp/terraform-provider-google-beta.git $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta Example# To build the google provider, run the following command in the root of a magic-modules repository clone:\n./scripts/make-in-container.sh \\ terraform VERSION=ga \\ OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34;"},{"id":19,"href":"/magic-modules/code-review/review-pr/","title":"Review a pull request","section":"Code review","content":"Review a pull request# This page provides guidelines for reviewing a Magic Modules pull request (PR).\nSpecial cases# The following types of PRs may require additional scrutiny and/or multiple reviewers.\nDCL to MMv1 migrations Adding multi-actor fields (fields whose values can be altered as a side effect of changes made to a different resource) Review# Read the PR description to understand the context and ensure the PR either is linked to a GitHub issue or an internal bug if not, check the issue tracker to see whether the feature has already been requested and add the issues in the description, if any. \u0026ldquo;Fixes {github_issue_link}\u0026rdquo; is preferred if an external issue is available because it will auto-close the issue when the PR is merged. However, there\u0026rsquo;s no need to create an external issue solely for this purpose. establishes clear context itself via title or description. If the PR adds any new resource, ensure that the resource does not already exist in the GA provider or beta provider Read through all the changes in the PR, generated code in the downstreams and the API documentation to ensure that: the resource schema added in the PR matches the API structure. the features are added in the correct version features only available in beta are not included in the GA google provider. features added to the GA provider are also included in the beta provider \u0026ndash; beta should be a strict superset of GA. no breaking changes are introduced without a valid justification. Add the override-breaking-change label if there is a valid justification. remember to check for changes in default behaviour like changing the flags on delete! verify the change fully resolves the linked issues, if any. If it does not, change the \u0026ldquo;Fixes\u0026rdquo; message to \u0026ldquo;Part of\u0026rdquo;. Check the tests added/modified to ensure that: all fields added/updated in the PR appear in at least one test. It is advisable to test updating from a non-zero value to a zero value if feasible. all mutable fields are tested in at least one update test. all resources in the acceptance tests have a tf-test or tf_test prefix in their primary id field. all handwritten test Config steps include import steps following them all related tests pass in GA for features promoted from beta to GA. Note: Presubmit VCR tests do not run in GA. Manual testing is required for promoted GA features.\nnewly added or modified diff suppress functions are tested in at least one unit test. the linked issue (if any) is covered by at least one test that reproduces the issue for example - a bugfix should test the bug (or explain why it\u0026rsquo;s not feasible to do so in the description, including manual results when possible) and an enhancement should test the new behaviour(s). all related PR presubmit tests have been completed successfully, including: terraform-provider-breaking-change-test terraform-provider-google-build-and-unit-tests terraform-provider-google-beta-build-and-unit-tests VCR-test Note: Some acceptance tests may be skipped in VCR and manual testing is required.\na significant number of preexisting tests have not been modified. Changing old tests often indicates a change is backwards incompatible. Check documentation to ensure resource-level and field-level documentation are generated correctly for MMv1-based resource documentation is added manually for handwritten resources. Check if release notes capture all changes in the PR, and are correctly formatted following the guidance in write release notes before merging the PR. "},{"id":20,"href":"/magic-modules/reference/metadata/","title":"MMv1 metadata reference","section":"Reference","content":"MMv1 metadata reference# This page documents all properties for metadata. Metadata does not impact the provider itself, but is used by Google internally for coverage metrics.\nRequired# resource# The name of the Terraform resource. For example, \u0026ldquo;google_cloudfunctions2_function\u0026rdquo;.\ngeneration_type# The generation method used to create the Terraform resource. For example, \u0026ldquo;mmv1\u0026rdquo;, \u0026ldquo;dcl\u0026rdquo;, \u0026ldquo;handwritten\u0026rdquo;.\napi_service_name# The base name of the API used for this resource. For example, \u0026ldquo;cloudfunctions.googleapis.com\u0026rdquo;.\napi_version# The version of the API used for this resource. For example, \u0026ldquo;v2\u0026rdquo;.\napi_resource_type_kind# The API \u0026ldquo;resource type kind\u0026rdquo; used for this resource. For example, \u0026ldquo;Function\u0026rdquo;.\nOptional# cai_asset_name_format# The custom CAI asset name format for this resource is typically specified (for example, //cloudsql.googleapis.com/projects/{{project}}/instances/{{name}}). This should only have a value if it\u0026rsquo;s different than the Terraform resource ID format.\napi_variant_patterns# The API URL patterns used by this resource that represent variants. For example, \u0026ldquo;folders/{folder}/feeds/{feed}\u0026rdquo;. Each pattern must match the value defined in the API exactly. The use of api_variant_patterns is only meaningful when the resource type has multiple parent types available.\nfields# The list of fields used by this resource. Each field can contain the following attributes:\napi_field: Required for fields that aren\u0026rsquo;t provider-only. The name of the field in the REST API, including the path. For example, \u0026ldquo;buildConfig.source.storageSource.bucket\u0026rdquo;. field: The name of the field in Terraform, including the path. For example, \u0026ldquo;build_config.source.storage_source.bucket\u0026rdquo;. Must be provided if and only if the field is provider-only or the Terraform field name can\u0026rsquo;t be derived from the API name. provider_only: If true, the field is only present in the provider. This primarily applies for virtual fields and url-only parameters. When set to true, field should be set and api_field should be left empty. Default: false. json: If true, this is a JSON field which \u0026ldquo;covers\u0026rdquo; all child API fields. As a special case, JSON fields which cover an entire resource can have api_field set to *. "},{"id":21,"href":"/magic-modules/develop/add-iam-support/","title":"Add IAM support","section":"Develop","content":"Add IAM support# This page covers how to add IAM resources in Terraform if they are supported by a particular API resource (indicated by setIamPolicy and getIamPolicy methods in the API documentation for the resource).\nFor more information about types of resources and the generation process overall, see How Magic Modules works.\nBefore you begin# Complete the steps in Set up your development environment to set up your environment and your Google Cloud project. Ensure that your magic-modules, terraform-provider-google, and terraform-provider-google-beta repositories are up to date. cd ~/magic-modules git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull Add IAM support# MMv1 IAM support for MMv1-generated resources is configured within the ResourceName.yaml file, and will create the google_product_resource_iam_policy, google_product_resource_iam_binding, google_product_resource_iam_member resource, website, and test files for that resource target when an iam_policy block is present.\nAdd the following top-level block to ResourceName.yaml directly above parameters. iam_policy: # Name of the field on the terraform IAM resources which references # the parent resource. Update to match the parent resource\u0026#39;s name. parent_resource_attribute: \u0026#39;resource_name\u0026#39; # Character preceding setIamPolicy in the full URL for the API method. # Usually `:` method_name_separator: \u0026#39;:\u0026#39; # HTTP method for getIamPolicy. Usually \u0026#39;POST\u0026#39;. fetch_iam_policy_verb: \u0026#39;POST\u0026#39; # Overrides the HTTP method for setIamPolicy. Default: \u0026#39;POST\u0026#39; # set_iam_policy_verb: \u0026#39;POST\u0026#39; # Must match the parent resource\u0026#39;s `import_format` (or `self_link` if # `import_format` is unset), but with the `parent_resource_attribute` # value substituted for the final field. import_format: - \u0026#39;projects/{{project}}/locations/{{location}}/resourcenames/{{resource_name}}\u0026#39; # If IAM conditions are supported, set this attribute to indicate how the # conditions should be passed to the API. Allowed values: \u0026#39;QUERY_PARAM\u0026#39;, # \u0026#39;REQUEST_BODY\u0026#39;, \u0026#39;QUERY_PARAM_NESTED\u0026#39;. Note: \u0026#39;QUERY_PARAM_NESTED\u0026#39; should # only be used if the query param field contains a `.` # iam_conditions_request_type: \u0026#39;REQUEST_BODY\u0026#39; # Marks IAM support as beta-only # min_version: beta Modify the template as needed to match the API resource\u0026rsquo;s documented behavior. These are the most commonly-used fields. For a comprehensive reference, see MMv1 resource reference: iam_policy ↗. Delete all remaining comments in the IAM configuration (including attribute descriptions) that were copied from the above template. Handwritten Warning: IAM support for handwritten resources should be implemented using MMv1. New handwritten IAM resources will only be accepted if they cannot be implemented using MMv1.\nAdd support in MMv1# Follow the MMv1 directions in Add a resource to create a skeleton ResourceName.yaml file for the handwritten resource, but set only the following top-level fields: name description (required but unused) base_url (set to URL of IAM parent resource) self_link (set to same value as base_url) id_format (set to same value as base_url) import_format (including base_url value) exclude_resource (set to true) properties Follow the MMv1 directions in Add fields to add only the fields used by base_url. Follow the MMv1 directions in this section to add IAM support. Convert to handwritten (not usually necessary)# Generate the beta provider From the beta provider, copy the files generated for the IAM resources to the following locations: Resource: Copy to the appropriate service folder inside magic-modules/mmv1/third_party/terraform/services Documentation: magic-modules/mmv1/third_party/terraform/website/docs/r Tests: In the appropriate service folder inside magic-modules/mmv1/third_party/terraform/services Modify the Go code as needed. Replace all occurrences of github.com/hashicorp/terraform-provider-google-beta/google-beta with github.com/hashicorp/terraform-provider-google/google Remove the comments at the top of the file. If any of the added Go code is beta-only: Change the file suffix to .go.tmpl Wrap each beta-only code block (including any imports) in a separate version guard: {{- if ne $.TargetVersionName \u0026quot;ga\u0026quot; -}}...{{- else }}...{{- end }} Register the binding, member, and policy resources handwrittenIAMResources in magic-modules/mmv1/third_party/terraform/provider/provider_mmv1_resources.go.tmpl Add a version guard for any beta-only resources. Add documentation# MMv1 Documentation is autogenerated based on the resource and field configurations. To preview the documentation:\nGenerate the providers Copy and paste the generated documentation into the Hashicorp Registry\u0026rsquo;s Doc Preview Tool to see how it is rendered. Handwritten Add or modify documentation files# Open the resource documentation in magic-modules/third_party/terraform/website/docs/r/ using an editor of your choice. The name of the file is the name of the resource without a google_ prefix. For example, for google_compute_instance, the file is called compute_instance.html.markdown Modify the documentation as needed according to Handwritten documentation style guide. Generate the providers Copy and paste the generated documentation into the Hashicorp Registry\u0026rsquo;s Doc Preview Tool to see how it is rendered. What\u0026rsquo;s next?# Add documentation Add custom resource code Add tests Run tests "},{"id":22,"href":"/magic-modules/best-practices/common-resource-patterns/","title":"Common resource patterns","section":"Best practices","content":"Common resource patterns# Singletons# Singletons are resources – often config or settings objects – that can only exist once. In some cases, it may be possible to create and delete the resource (but only one can exist at a time); in other cases the resource always exists and can only be read and updated.\nImplementing resources like this may require some or all of the following:\nIf there isn\u0026rsquo;t a create endpoint, set the create_url to point to the update endpoint. If there is a create endpoint, add pre-create custom code that implements \u0026ldquo;acquire-on-create\u0026rdquo; logic. The custom code should check whether the resource already exists with a read request, and if it does, run the update logic and return early. For example, see mmv1/templates/terraform/pre_create/firebasehosting_site.go.tmpl. Note: The main disadvantage of \u0026ldquo;acquire-on-create\u0026rdquo; logic is that users will not be presented with a diff between the resource\u0026rsquo;s old and new states – because from the terraform perspective, the resource is only being created. Please upvote https://github.com/hashicorp/terraform/issues/19017 to request better support for this workflow. If there is no delete endpoint, set exclude_delete: true at the top level of the resource. Tests for singletons can run into issues because they are modifying a shared state. To avoid the problems this can cause, ensure that the tests create dedicated parent resources instead of modifying the default test environment. If there need to be multiple test cases, make sure they either have individual parent resources, or that they run serially, like TestAccAccessContextManager.\n"},{"id":23,"href":"/magic-modules/reference/ruby-go-changes/","title":"Ruby to Go Migration","section":"Reference","content":"What has changed in the MMv1 Go migration# The Magic Modules code generator has been rewritten from Ruby to Go. For experienced contributors, this reference document lists what the expected changes are to the previous development workflow in Ruby.\nYAML changes# .yaml files within mmv1/products have had adjustments to the attribute typing. The initial Ruby lines !ruby/object:Api::Type::\u0026lt;TYPE\u0026gt; have been removed and replaced with a simpler type: \u0026lt;TYPE\u0026gt; line.\nOld Ruby YAML\n- !ruby/object:Api::Type::String name: \u0026#39;apiFieldName\u0026#39; description: | MULTILINE_FIELD_DESCRIPTIONNew Go YAML\n- name: \u0026#39;apiFieldName\u0026#39; type: String description: | MULTI_LINE_FIELD_DESCRIPTIONTemplate .erb file changes# Template files have all been converted Embedded Ruby (ERB) templates to Go\u0026rsquo;s text/template format. All .erb files are replaced with equivalent .tmpl files. The MMv1 resource objects are passed to the Go templates for referencing, similar to the previous Ruby templates. For the list of available variables and functions within the templates, please reference:\ntext/template standard library mmv1/api/resource.go mmv1/google/template_utils.go Common templating snippets# Version guards# Old Ruby template\n\u0026lt;% unless version == \u0026#39;ga\u0026#39; -%\u0026gt; // Go code here \u0026lt;% end -%\u0026gt;New Go template\n{{- if ne $.TargetVersionName \u0026#34;ga\u0026#34; }} // Go code here {{- end }}Example .tf.erb variables# Old Ruby template pubsub_topic_basic.tf.erb\nresource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;\u0026lt;%= ctx[:primary_resource_id] %\u0026gt;\u0026#34; { name = \u0026#34;\u0026lt;%= ctx[:vars][\u0026#39;topic_name\u0026#39;] %\u0026gt;\u0026#34; labels = { foo = \u0026#34;bar\u0026#34; } message_retention_duration = \u0026#34;86600s\u0026#34; }New Go template pubsub_topic_basic.tf.tmpl\nresource \u0026#34;google_pubsub_topic\u0026#34; \u0026#34;{{$.PrimaryResourceId}}\u0026#34; { name = \u0026#34;{{index $.Vars \u0026#34;topic_name\u0026#34;}}\u0026#34; labels = { foo = \u0026#34;bar\u0026#34; } message_retention_duration = \u0026#34;86600s\u0026#34; }Advanced: MMv1-specific generator command# Most contributors should use the make commands referenced in make-commands reference page to generate the downstream google and google-beta providers. The input for these commands have not changed, and have already been correctly switched over to use the new Go engine.\nSome advanced contributors may be used to running the MMv1 generator commands. These commands have changed from Ruby\u0026rsquo;s bundle exec to go run.\nThese are not generally recommended to use\nOld Ruby MMv1 generator command in mmv1/:\nbundle exec compiler -e terraform -o \u0026lt;output directory\u0026gt; -v \u0026lt;version\u0026gt; -f \u0026lt;MMv1 provider\u0026gt; -p \u0026lt;products/productfolder\u0026gt;New Go MMv1 generator command in mmv1/:\ngo run . --output \u0026lt;output directory\u0026gt; --version \u0026lt;version\u0026gt; --provider \u0026lt;MMv1 provider\u0026gt;Advanced: MMv1 generator code locations# Most previous Ruby compiler code has parallel Go code placed the same file locations. For example, the Go replacements for mmv1/compiler.rb and mmv1/provider/terraform.rb are mmv1/main.go and mmv1/provider/terraform.go respectively.\n"},{"id":24,"href":"/magic-modules/best-practices/validation/","title":"Validation","section":"Best practices","content":"Validation# There are a number of ways to add client-side validation to resources. The benefit of client-side validation is that errors can be surfaced at plan time, instead of partway through a (potentially very long) apply process, allowing for faster iteration. However, the tradeoff is that client-side validation can get out of sync with server-side validation, creating additional maintenance burden for the provider and preventing users from accessing the latest features without upgrading.\nClient-side validation is generally discouraged due to the low positive impact of an individual validation rule and outsized negative impact when client-side validation and API capabilities drift, requiring both provider changes and users to update. Client-side validation may be added in cases where it is extremely unlikely to change, covered below.\nThe following sections cover best practices for specific types of client-side validation.\nURL segments# If a resource URL looks like:\nprojects/{project}/folders/{folder}/resource/{resource_id}Adding validation for the last part of the path (resource_id) may be safe if there are specific restrictions that aren\u0026rsquo;t going to change, such as following an external RFC or other spec/standard. However, if the API was ever less restrictive (or becomes less restrictive later), resources created with other tools and then imported into Terraform may be impossible to actually manage with Terraform (without deleting \u0026amp; recreating them) because the ID which was valid in the API violates the more restrictive validation in the provider.\nEnum# Enums are generally okay if they are exhaustive of all possible values for a clearly defined domain where new values are extremely unlikely. Otherwise, it is better to use a string field and add a link to the API documentation as a reference for the possible values.\nInter-field relationships# conflicts, required_with, exactly_one_of, and at_least_one_of are often safe to add. However, if there is a chance that the API validation will relax in the future (such as two fields no longer being required together, or two fields no longer conflicting) it\u0026rsquo;s better to not add the restriction in the first place.\nImmutable facts# It is safe to validate things that will definitely always be true about an API. For example, a node_count field will most likely always need to be non-negative. That is safe to validate. However, validating a max value for node_count may not be safe, because the API might increase the allowed values in the future.\n"},{"id":25,"href":"/magic-modules/develop/add-handwritten-datasource/","title":"Add a datasource","section":"Develop","content":"Add a datasource# Note: only handwritten datasources are currently supported\nDatasources are like terraform resources except they don\u0026rsquo;t create anything. They are simply read-only operations that will expose some sort of values needed for subsequent resource operations. If you\u0026rsquo;re adding a field to an existing datasource, check the Resource section. Everything there will be mostly consistent with the type of change you\u0026rsquo;ll need to make. For adding a new datasource there are 5 steps to doing so.\nCreate a new datasource declaration file and a corresponding test file Add Schema and Read operation implementation If there is labels field with type KeyValueLabels in the corresponding resource, in the datasource Read operation implementation, after the resource read method, call the function tpgresource.SetDataSourceLabels(d) to make labels and terraform_labels have all of the labels on the resource. If there is annotations field with type KeyValueAnnotations in the corresponding resource, in the datasource Read operation implementation, after the resource read method, call the function tpgresource.SetDataSourceAnnotations(d) to make annotations have all of the annotations on the resource. Register the datasource to handwrittenDatasources in magic-modules/mmv1/third_party/terraform/provider/provider_mmv1_resources.go.tmpl Implement a test which will create and resources and read the corresponding datasource Add documentation For creating a datasource based off an existing resource you can make use of the schema directly. Otherwise implementing the schema directly, similar to normal resource creation, is the desired path.\nResourceless Datasources# Datasources not backed by a resource are possible to add as well. They follow the same general steps as adding a resource-based datasource, except that a full Read method will need to be defined for them rather than calling a resource\u0026rsquo;s Read method.\nNote that while resource-based datasources can depend on the resource read method for API calls, resourceless datasources need to make them themselves. An HTTP-based client that\u0026rsquo;s properly configured with logging and retries must be used, such as a client from the https://github.com/googleapis/google-api-go-client library, or the raw HTTP client used in MMV1 through SendRequest.\nAdd documentation# Open the data source documentation in magic-modules/third_party/terraform/website/docs/d/ using an editor of your choice. The name of the file is the name of the data source without a google_ prefix. For example, for google_compute_instance, the file is called compute_instance.html.markdown Modify the documentation as needed according to Handwritten documentation style guide. Generate the providers Copy and paste the generated documentation into the Hashicorp Registry\u0026rsquo;s Doc Preview Tool to see how it is rendered. "},{"id":26,"href":"/magic-modules/develop/custom-code/","title":"Add custom resource code","section":"Develop","content":"Add custom resource code# This document covers how to add \u0026ldquo;custom code\u0026rdquo; to MMv1 resources. Custom code can be used to add arbitrary logic to a resource while still generating most of the code; it allows for a balance between maintainability and supporting real-worlds APIs that deviate from what MMv1 can support. Custom code should only be added if the desired behavior can\u0026rsquo;t be achieved otherwise.\nMost custom code attributes are strings that contain a path to a template file relative to the mmv1 directory. For example:\ncustom_code: # References mmv1/templates/terraform/custom_delete/resource_name_custom_delete.go.tmpl custom_delete: templates/terraform/custom_delete/resource_name_custom_delete.go.tmplBy convention, the template files are stored in a directory matching the type of custom code, and the name of the file includes the resource (and, if relevant, field) impacted by the custom code. Like handwritten resource and test code, custom code is written as go templates which render go code.\nWhen in doubt about the behavior of custom code, write the custom code, generate the providers, and inspect what changed in the providers using git diff.\nThe following sections describe types of custom code in more detail.\nAdd reusable variables and functions# custom_code: constants: templates/terraform/constants/PRODUCT_RESOURCE.go.tmplUse custom_code.constants to inject top-level code in a resource file. This is useful for anything that should be referenced from other parts of the resource, such as:\nConstants Regexes compiled at build time Functions, such as diff suppress functions, validation functions, CustomizeDiff functions, and so on. Methods Any custom functions added should have thorough unit tests.\nModify the API request or response# API requests and responses can be modified in the following order:\nModify the API request value for a specific field Modify the API request data for an entire resource Modify the API response data for an entire resource Modify the API response value for a specific field These are described in more detail in the following sections.\nModify the API request value for a specific field# - name: \u0026#39;FIELD\u0026#39; type: String custom_expand: \u0026#39;templates/terraform/custom_expand/PRODUCT_RESOURCE_FIELD.go.tmpl\u0026#39;Set custom_expand on a field to inject code that modifies the value to send to the API for that field. Custom expanders run before any encoder or update_encoder. The referenced file must include the function signature for the expander. For example:\nfunc expand{{$.GetPrefix}}{{$.TitlelizeProperty}}(v interface{}, d tpgresource.TerraformResourceData, config *transport_tpg.Config) (interface{}, error) { if v == nil { return nil, nil } return base64.StdEncoding.EncodeToString([]byte(v.(string))), nil }The parameters the function receives are:\nv: The value for the field d: Terraform resource data. Use d.Get(\u0026quot;field_name\u0026quot;) to get a field\u0026rsquo;s current value. config: Config object. Can be used to make API calls. The function returns a final value that will be sent to the API.\nModify the API request data for an entire resource# custom_code: encoder: templates/terraform/encoder/PRODUCT_RESOURCE.go.tmpl update_encoder: templates/terraform/update_encoder/PRODUCT_RESOURCE.go.tmplUse custom_code.encoder to inject code that modifies the data that will be sent in the API request. This is useful if the API expects the data to be in a significantly different structure than Terraform does - for example, if the API expects the entire object to be nested under a key, or a particular field must never be sent to the API. The encoder will run after any custom_expand code.\nThe encoder code will be wrapped in a function like:\nfunc resourceProductResourceEncoder(d *schema.ResourceData, meta interface{}, obj map[string]interface{}) (map[string]interface{}, error) { // Your code will be injected here. }The parameters the function receives are:\nd: Terraform resource data. Use d.Get(\u0026quot;field_name\u0026quot;) to get a field\u0026rsquo;s current value. meta: Can be cast to a Config object (which can make API calls) using meta.(*transport_tpg.Config) obj: The data that will be sent to the API. The function returns data that will be sent to the API and an optional error.\nIf the Create and Update methods for the resource need different logic, set custom_code.update_encoder to override the logic for update only. It is otherwise the same as custom_code.encoder.\nModify the API response data for an entire resource# custom_code: decoder: templates/terraform/decoder/PRODUCT_RESOURCE.go.tmplUse custom_code.decoder to inject code that modifies the data recieved from an API response. This is useful if the API returns data in a significantly different structure than what Terraform expects - for example, if the API returns the entire object nested under a key, or uses a different name for a field in the response than in the request. The decoder will run before any custom_flatten code.\nThe decoder code will be wrapped in a function like:\nfunc resourceProductResourceDecoder(d *schema.ResourceData, meta interface{}, res map[string]interface{}) (map[string]interface{}, error) { // Your code will be injected here. }The parameters the function receives are:\nd: Terraform resource data. Use d.Get(\u0026quot;field_name\u0026quot;) to get a field\u0026rsquo;s current value. meta: Can be cast to a Config object (which can make API calls) using meta.(*transport_tpg.Config) res: The data (\u0026ldquo;response\u0026rdquo;) returned by the API. The function returns data that will be set in Terraform state and an optional error.\nModify the API response value for a specific field# - name: \u0026#39;FIELD\u0026#39; type: String custom_flatten: \u0026#39;templates/terraform/custom_flatten/PRODUCT_RESOURCE_FIELD.go.tmpl\u0026#39;Set custom_flatten on a field to inject code that modifies the value returned by the API prior to storing it in Terraform state. Custom flatteners run after any decoder. The referenced file must include the function signature for the flattener. For example:\nfunc flatten{{$.GetPrefix}}{{$.TitlelizeProperty}}(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} { if v == nil { return \u0026#34;0\u0026#34; } return v }The parameters the function receives are:\nv: The value for the field d: Terraform resource data. Use d.Get(\u0026quot;field_name\u0026quot;) to get a field\u0026rsquo;s current value. config: Config object. Can be used to make API calls. The function returns a final value that will be stored in Terraform state for the field, which will be compared with the user\u0026rsquo;s configuration to determine if there is a diff.\nInject code before / after CRUD operations and Import# custom_code: pre_create: templates/terraform/pre_create/PRODUCT_RESOURCE.go.tmpl post_create: templates/terraform/post_create/PRODUCT_RESOURCE.go.tmpl pre_read: templates/terraform/pre_read/PRODUCT_RESOURCE.go.tmpl pre_update: templates/terraform/pre_update/PRODUCT_RESOURCE.go.tmpl post_update: templates/terraform/post_update/PRODUCT_RESOURCE.go.tmpl pre_delete: templates/terraform/pre_delete/PRODUCT_RESOURCE.go.tmpl post_delete: templates/terraform/post_delete/PRODUCT_RESOURCE.go.tmpl post_import: templates/terraform/post_import/PRODUCT_RESOURCE.go.tmplCRUD operations can be modified with pre/post hooks. This code will be injected directly into the relevant CRUD method as close as possible to the related API call and will have access to any variables that are present when it runs. pre_create and pre_update run after any encoder. Some example use cases:\nUse post_create to set an update-only field after create finishes. Use pre_delete to detach a disk before deleting it. Use post_import to parse attributes from the import ID and call d.Set(\u0026quot;field\u0026quot;) so that the resource can be read from the API. Custom create error handling# custom_code: post_create_failure: templates/terraform/post_create_failure/PRODUCT_RESOURCE.go.tmplUse custom_code.post_create_failure to inject code that runs if a Create request to the API returns an error.\nThe post_create_failure code will be wrapped in a function like:\nfunc resourceProductResourcePostCreateFailure(d *schema.ResourceData, meta interface{}) { // Your code will be injected here. }The parameters the function receives are:\nd: Terraform resource data. Use d.Get(\u0026quot;field_name\u0026quot;) to get a field\u0026rsquo;s current value. meta: Can be cast to a Config object (which can make API calls) using meta.(*transport_tpg.Config) Custom retry handling# error_retry_predicates: - \u0026#39;transport_tpg.IamMemberMissing\u0026#39; error_abort_predicates: - \u0026#39;transport_tpg.Is429QuotaError\u0026#39;Use error_retry_predicates or error_abort_predicates functions to retry or abort when encountering certain error responses. By default, errors are retried using this list of retry predicates. error_retry_predicates can be used to make more errors retryable, while error_abort_predicates can be used to prevent errors from being retried.\nBoth functions use the following signature:\nfunc (err error) (bool, string) {}The function takes an error and returns:\nbool: whether the error should be retried/aborted string: a reason that will be logged Replace entire CRUD methods# custom_code: custom_create: templates/terraform/custom_create/PRODUCT_RESOURCE.go.tmpl custom_update: templates/terraform/custom_update/PRODUCT_RESOURCE.go.tmpl custom_delete: templates/terraform/custom_delete/PRODUCT_RESOURCE.go.tmpl custom_import: templates/terraform/custom_import/PRODUCT_RESOURCE.go.tmplCustom methods replace the entire contents of the Create, Update, Delete, or Import methods. For example:\nfunc resourceProductResourceImport(d *schema.ResourceData, meta interface{}) ([]*schema.ResourceData, error) { // Your code will be injected here. }Custom methods are similar to handwritten code and should be avoided if possible. If you have to replace two or more methods, the resource should be handwritten instead.\nAdd extra fields to a resource# Use custom_code.extra_schema_entry to add additional fields to a resource. Do not use extra_schema_entry unless there is no other option. The extra fields are injected at the end of the resource\u0026rsquo;s Schema field. They should be formatted as entries in the map. For example:\n\u0026#34;foo\u0026#34;: \u0026amp;schema.Schema{ ... },Any fields added in this way will need to be have documentation manually added using the top-level docs field:\ndocs: optional_properties: | * `FIELD_NAME` - (Optional, [Beta](../guides/provider_versions.html.markdown)) FIELD_DESCRIPTIONSee Add documentation (Handwritten) for more information about what to include in the field documentation.\nWhat\u0026rsquo;s next?# Add tests Run tests "},{"id":27,"href":"/magic-modules/develop/promote-to-ga/","title":"Promote to GA","section":"Develop","content":"Promote from beta to GA# This document describes how to promote an existing resource or field that uses MMv1 and/or handwritten code from the google-beta provider to the google (also known as \u0026ldquo;GA\u0026rdquo;) provider.\nHandwritten code (including custom_code) commonly uses \u0026ldquo;version guards\u0026rdquo; in the form of {{- if ne $.TargetVersionName \u0026quot;ga\u0026quot; }}...{{- end }} to wrap code that is beta-specific, which need to be removed during promotion.\nFor more information about types of resources and the generation process overall, see How Magic Modules works.\nBefore you begin# Complete the steps in Set up your development environment to set up your environment and your Google Cloud project. Ensure that your magic-modules, terraform-provider-google, and terraform-provider-google-beta repositories are up to date. cd ~/magic-modules git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta git checkout main \u0026amp;\u0026amp; git clean -f . \u0026amp;\u0026amp; git checkout -- . \u0026amp;\u0026amp; git pull Promote fields and resources# MMv1 Remove min_version: 'beta' from the resource\u0026rsquo;s or field\u0026rsquo;s configuration in ResourceName.yaml. If necessary, remove version guards from resource-level custom_code. Add min_version: 'beta' on any fields or subfields that should not be promoted. If necessary, add {{- if ne $.TargetVersionName \u0026quot;ga\u0026quot; }}...{{- end }} version guards to resource-level custom_code that should not be promoted. Handwritten Remove version guards from the resource\u0026rsquo;s implementation for any functionality being promoted. Be sure to check: The overall resource (if the entire resource was beta-only) The resource schema For top-level fields, the resource\u0026rsquo;s Create, Update, and Read methods For other fields, expanders and flatteners Any other resource-specific code Add {{- if ne $.TargetVersionName \u0026quot;ga\u0026quot; }}...{{- end }} version guards to any parts of the resource or field implementation that should not be promoted. Be sure to check: The resource schema For top-level fields, the resource\u0026rsquo;s Create, Update, and Read methods For other fields, expanders and flatteners Any other resource-specific code Promote tests# Remove min_version: beta from any examples in a ResourceName.yaml which only test fields and resources that are present in the google provider. Remove version guards from any handwritten code related to fields and resources that are present in the google provider. Remove provider = google-beta from any test configurations (from MMv1 examples or handwritten) which have been promoted. Replace ProtoV5ProviderBetaFactories with ProtoV5ProviderFactories in all promoted handwritten tests. Ensure that there is at least one test that will run for the google provider that covers any promoted fields and resources. Promote documentation# For handwritten resources, modify the documentation as appropriate for your change:\nIf the entire resource has been promoted to google, remove the beta warning at the top of the documentation.\nRemove the Beta annotation for any fields that have been promoted.\nAdd Beta as an annotation on any fields or subfields that remained beta-only. For example:\n* `FIELD_NAME` - (Optional, [Beta](../guides/provider_versions.html.markdown)) FIELD_DESCRIPTIONReplace FIELD_NAME and FIELD_DESCRIPTION with the field\u0026rsquo;s name and description.\nWhat\u0026rsquo;s next?# Test your changes "},{"id":28,"href":"/magic-modules/develop/update-dependencies/","title":"Update dependencies","section":"Develop","content":"Update provider dependencies# The Magic Modules repository does not contain a complete Go module, preventing the use of automated tooling like go get from that repository. To add or update provider dependencies, use standard Go tooling to update the dependency in the terraform-provider-google provider and copy the results to the upstream files in Magic Modules.\nBelow are the steps you can follow to make the change:\nNavigate to the local google provider directory: cd $GOPATH/src/github.com/hashicorp/terraform-provider-google Open the go.mod file and add the new entries or modify the versions of existing entries as needed Update dependencies using either of the following methods run the following commands to update all dependencies: go get go mod tidy Alternatively, update a specific package to a desired version: go get google.golang.org/api@v0.105.0 go mod tidy Copy the contents of the updated go.mod and go.sum file into mmv1/third_party/terraform/go.mod and mmv1/third_party/terraform/go.sum in the magic-modules respectively. Create a pull request containing only the dependency changes. Resolve any errors caused by the dependency upgrade. After the dependency pull request is merged, continue with a separate pull request for any additional changes that were blocked by the upgrade. "},{"id":29,"href":"/magic-modules/develop/diffs/","title":"Fix diffs","section":"Develop","content":"Fix diffs# This page outlines best practices for fixing various kinds of diffs that can show up at plan time. These will often show up as test failures with the text: After applying this test step, the plan was not empty.. They can also show up for users at plan time, on fields that a user has not modified in their configuration. If the diff does not go away even after running terraform apply more than once with the same configuration, the diff is called a \u0026ldquo;permadiff\u0026rdquo;.\nIn a general sense, diffs appear when the API response is detected by Terraform to be different than what is in the user\u0026rsquo;s configuration. This can happen for a number of reasons, including:\nAPI returns a normalized version of the input API returns server-side defaults if the field is unset API does not return all the fields set on a resource (for example, secrets) The sections below describe in more detail how to address a number of different causes of diffs.\nAPI returns default value for unset field# For new fields, if possible, set a client-side default that matches the API default. This will prevent the diff and will allow users to accurately see what the end state will be if the field is not set in their configuration. A client-side default should only be used if the API sets the same default value in all cases and the default value will be stable over time. Changing a client-side default is a breaking change.\nMMv1 default_value: DEFAULT_VALUEIn the providers, this will be converted to:\n\u0026#34;field\u0026#34;: { // ... Default: \u0026#34;DEFAULT_VALUE\u0026#34;, }See SDKv2 Schema Behaviors - Default ↗ for more information.\nHandwritten \u0026#34;field\u0026#34;: { // ... Default: \u0026#34;DEFAULT_VALUE\u0026#34;, }See SDKv2 Schema Behaviors - Default ↗ for more information.\nFor existing fields (or new fields that are not eligible for a client-side default), mark the field as having an API-side default. If the field is not set (or is set to an \u0026ldquo;empty\u0026rdquo; value such as zero, false, or an empty string) the provider will treat the most recent value returned by the API as the value for the field, and will send that value for the field on subsequent requests. The field will show as (known after apply) in plans and it will not be possible for the user to explicitly set the field to an \u0026ldquo;empty\u0026rdquo; value.\nMMv1 default_from_api: trueIn the providers, this will be converted to:\n\u0026#34;field\u0026#34;: { // ... Optional: true, Computed: true, }See SDKv2 Schema Behaviors - Optional ↗ and SDKv2 Schema Behaviors - Computed ↗ for more information.\nHandwritten \u0026#34;field\u0026#34;: { // ... Optional: true, Computed: true, }See SDKv2 Schema Behaviors - Optional ↗ and SDKv2 Schema Behaviors - Computed ↗ for more information.\nAPI returns an empty value if default value is sent# Use a flattener to store the default value in state if the response has an empty (or unset) value.\nMMv1 Use the standard default_if_empty flattener.\ncustom_flatten: \u0026#39;templates/terraform/custom_flatten/default_if_empty.tmpl\u0026#39; Handwritten func flattenResourceNameFieldName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} { if v == nil || tpgresource.IsEmptyValue(reflect.ValueOf(v)) { return \u0026#34;DEFAULT_VALUE\u0026#34; } // Any other necessary logic goes here. return v } API normalizes a value# In cases where the API normalizes and returns a value in a simple, predictable way (such as capitalizing the value) add a diff suppress function for the field to suppress the diff.\nThe tpgresource package in each provider supplies diff suppress functions for the following common cases:\ntpgresource.CaseDiffSuppress: Suppress diffs from capitalization differences between the user\u0026rsquo;s configuration and the API. tpgresource.DurationDiffSuppress: Suppress diffs from duration format differences such as \u0026ldquo;60.0s\u0026rdquo; vs \u0026ldquo;60s\u0026rdquo;. This is necessary for Duration API fields. tpgresource.ProjectNumberDiffSuppress: Suppress diffs caused by the provider sending a project ID and the API returning a project number. MMv1 # Use a built-in function diff_suppress_func: \u0026#39;tpgresource.CaseDiffSuppress\u0026#39; # Reference a resource-specific function diff_suppress_func: \u0026#39;resourceNameFieldNameDiffSuppress\u0026#39;Define resource-specific functions in a custom_code.constants file.\nfunc resourceNameFieldNameDiffSuppress(_, old, new string, _ *schema.ResourceData) bool { // Separate function for easier unit testing return resourceNameFieldNameDiffSuppressLogic(old, new) } func resourceNameFieldNameDiffSuppressLogic(old, new) bool { // Diff suppression logic. Returns true if the diff should be suppressed - that is, if the // old and new values should be considered \u0026#34;the same\u0026#34;. }See SDKv2 Schema Behaviors - DiffSuppressFunc ↗ for more information.\nHandwritten Define resource-specific functions in your service package, for example at the top of the related resource file.\nfunc resourceNameFieldNameDiffSuppress(_, old, new string, _ *schema.ResourceData) bool { // Separate function for easier unit testing return resourceNameFieldNameDiffSuppressLogic(old, new) } func resourceNameFieldNameDiffSuppressLogic(old, new) bool { // Diff suppression logic. Returns true if the diff should be suppressed - that is, if the // old and new values should be considered \u0026#34;the same\u0026#34;. }Reference diff suppress functions from the field definition.\n\u0026#34;field\u0026#34;: { // ... DiffSuppressFunc: resourceNameFieldNameDiffSuppress, }See SDKv2 Schema Behaviors - DiffSuppressFunc ↗ for more information.\nAPI field that is never included in the response# This is common for fields that store credentials or similar information. Such fields should also be marked as sensitive.\nIn the flattener for the field, return the value of the field in the user\u0026rsquo;s configuration.\nMMv1 On top-level fields, this can be done with:\nignore_read: trueFor nested fields, ignore_read is not currently supported, so this must be implemented with a custom flattener. You will also need to add the field to ignore_read_extra on any examples that are used to generate tests; this will cause tests to ignore the field when checking that the values in the API match the user\u0026rsquo;s configuration.\nfunc flatten{{$.GetPrefix}}{{$.TitlelizeProperty}}(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} { // We want to ignore read on this field, but cannot because it is nested return d.Get(\u0026#34;path.0.to.0.nested.0.field\u0026#34;) }examples: # example configuration ignore_read_extra: - \u0026#34;path.0.to.0.nested.0.field\u0026#34; Handwritten Use d.Get to set the flattened value to be the same as the user-configured value (instead of a value from the API).\nfunc flattenParentField(d *schema.ResourceData, disk *compute.AttachedDisk, config *transport_tpg.Config) []map[string]interface{} { result := map[string]interface{}{ \u0026#34;nested_field\u0026#34;: d.Get(\u0026#34;path.0.to.0.parent_field.0.nested_field\u0026#34;) } return []map[string]interface{}{result} }In tests, add the field to ImportStateVerifyIgnore on any relevant import steps.\n{ ResourceName: \u0026#34;google_product_resource.default\u0026#34;, ImportState: true, ImportStateVerify: true, ImportStateVerifyIgnore: []string{\u0026#34;\u0026#34;path.0.to.0.parent_field.0.nested_field\u0026#34;}, }, API returns a list in a different order than was sent# For an Array of unique string values (or nested objects with unique string identifiers), use the SortStringsByConfigOrder or SortMapsByConfigOrder helper functions to sort the API response to match the order in the user\u0026rsquo;s configuration. This will also simplify diffs if new values are added or removed. Imported resources will not have access to a configuration, so the field will be sorted alphabetically. This means that tests for the resource need to ignore the field\u0026rsquo;s import behavior via ignore_read_extra (for MMv1 examples) or ImportStateVerifyIgnore (for handwritten tests).\nMMv1 Add a custom flattener for the field.\nfunc flatten{{$.GetPrefix}}{{$.TitlelizeProperty}}(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} { rawConfigValue := d.Get(\u0026#34;path.0.to.0.parent_field.0.nested_field\u0026#34;) // Convert config value to []string configValue, err := tpgresource.InterfaceSliceToStringSlice(rawConfigValue) if err != nil { log.Printf(\u0026#34;[ERROR] Failed to convert config value: %s\u0026#34;, err) return v } // Convert v to []string apiStringValue, err := tpgresource.InterfaceSliceToStringSlice(v) if err != nil { log.Printf(\u0026#34;[ERROR] Failed to convert API value: %s\u0026#34;, err) return v } sortedStrings, err := tpgresource.SortStringsByConfigOrder(configValue, apiStringValue) if err != nil { log.Printf(\u0026#34;[ERROR] Could not sort API response value: %s\u0026#34;, err) return v } return sortedStrings } Handwritten Define resource-specific functions in your service package, for example at the top of the related resource file.\nfunc flattenResourceNameFieldName(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} { rawConfigValue := d.Get(\u0026#34;path.0.to.0.parent_field.0.nested_field\u0026#34;) // Convert config value to []string configValue, err := tpgresource.InterfaceSliceToStringSlice(rawConfigValue) if err != nil { log.Printf(\u0026#34;[ERROR] Failed to convert config value: %s\u0026#34;, err) return v } // Convert v to []string apiStringValue, err := tpgresource.InterfaceSliceToStringSlice(v) if err != nil { log.Printf(\u0026#34;[ERROR] Failed to convert API value: %s\u0026#34;, err) return v } sortedStrings, err := tpgresource.SortStringsByConfigOrder(configValue, apiStringValue) if err != nil { log.Printf(\u0026#34;[ERROR] Could not sort API response value: %s\u0026#34;, err) return v } return sortedStrings } For other Array fields, convert the field to a Set – this is a breaking change and can only happen in a major release.\nAPI is eventually consistent or returns an Operation# If a resource\u0026rsquo;s creation or update takes a long time before the results will be returned from a Read call, it can lead to diffs.\nIf the method returns an Operation, the best thing to do is wait for the operation to complete. In MMv1 resources, this can be done by setting autogen_async: true and configuring the resource\u0026rsquo;s async settings.\nEventually consistent APIs that do not return an Operation are not compliant with AIP-121\u0026rsquo;s strong consistency requirement, but they do exist. The fix in this case is to add post-create custom code which adds a sleep after creation completes. There are three premade templates that can be used for this:\ntemplates/terraform/post_create/sleep.go.tmpl templates/terraform/post_create/sleep_2_min.go.tmpl templates/terraform/post_create/sleep_5_min.go.tmpl "},{"id":30,"href":"/magic-modules/develop/generate-providers/","title":"Generate the providers","section":"Develop","content":"Generate google and google-beta providers# After making a change to the Terraform providers for Google Cloud, you must integrate your changes with the providers. This page explains how to generate provider changes to the google and google-beta Terraform providers.\nBefore you begin# Set up your development environment. Update magic-modules as needed. These updates could be any of the following changes: Adding a resource. Adding a datasource. Adding custom resource code. Promoting a resource to GA. By default, running a full make provider command cleans the output directory (OUTPUT_PATH) before generating code to prevent sync issues. This will override and delete any changes to that directory. See the make commands reference for details on advanced usage.\nGenerate a provider change# Clone the google and google-beta provider repositories with the following commands:\ngit clone https://github.com/hashicorp/terraform-provider-google.git $GOPATH/src/github.com/hashicorp/terraform-provider-google git clone https://github.com/hashicorp/terraform-provider-google-beta.git $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta Generate changes for the google provider:\nmake provider VERSION=ga OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google\u0026#34; Generate changes for the google-beta provider:\nmake provider VERSION=beta OUTPUT_PATH=\u0026#34;$GOPATH/src/github.com/hashicorp/terraform-provider-google-beta\u0026#34; Confirm that the expected changes were generated:\ncd $GOPATH/src/github.com/hashicorp/terraform-provider-google git diff -U0 cd $GOPATH/src/github.com/hashicorp/terraform-provider-google-beta git diff -U0 Note: You might see additional changes in your git diff output beyond your own. This can happen if your magic-modules repository is out of sync with the provider repositories, causing the generator to also apply any pending updates from magic-modules.\nTroubleshoot# Too many open files# If you are getting “Too many open files” ulimit needs to be raised.\nMac OS ulimit -n 8192 What\u0026rsquo;s next# Learn how to add resource tests Learn how to run tests Learn about make commands "},{"id":31,"href":"/magic-modules/develop/client-side-fields/","title":"Client-side fields","section":"Develop","content":"Client-side fields# Client-side fields are most often used as flags to modify the behavior of a Terraform resource. Because they don\u0026rsquo;t correspond to an API field, there are some additional considerations in terms of how to implement them.\nCommon client-side fields include:\ndeletion_protection deletion_policy MMv1 Add to the schema# Instead of adding the field in parameters or properties, use a section called virtual_fields.\nExample:\nvirtual_fields: - name: \u0026#39;deletion_protection\u0026#39; type: Boolean default_value: true description: | Whether Terraform will be prevented from destroying the CertificateAuthority. When the field is set to true or unset in Terraform state, a `terraform apply` or `terraform destroy` that would delete the CertificateAuthority will fail. When the field is set to false, deleting the CertificateAuthority is allowed.This will automatically ensure that the field works as users expect.\nHandwritten Add to the schema# Add the field to the schema as usual.\nExample:\n\u0026#34;deletion_protection\u0026#34;: { Type: schema.TypeBool, Optional: true, Default: true, Description: `Whether Terraform will be prevented from destroying the instance. When the field is set to true or unset in Terraform state, a terraform apply or terraform destroy that would delete the table will fail. When the field is set to false, deleting the table is allowed.`, },Set on read# For fields with default values, you need to explicitly set client-side fields in the Read function to avoid a diff that \u0026ldquo;sets\u0026rdquo; the field to its default value when users upgrade to the version that contains the new field.\nExample:\n// Explicitly set client-side fields to default values if unset if _, ok := d.GetOkExists(\u0026#34;deletion_protection\u0026#34;); !ok { if err := d.Set(\u0026#34;deletion_protection\u0026#34;, true); err != nil { return fmt.Errorf(\u0026#34;Error setting deletion_protection: %s\u0026#34;, err) } }Short-circuit updates if only client-side fields were modified# Client-side fields can always be updated in-place. However, if the resource is otherwise immutable, you will need to ensure that an Update function is present for the resource. Terraform automatically updates the state based on the plan; this does not need to happen in the Update function unless the value for a field might have changed (for example, based on an API response, which doesn\u0026rsquo;t apply to client-side fields).\nIf only client-side fields were modified, you can short-circuit the Update function to avoid sending an API request. This is important because the update request will be empty (which causes errors for some APIs.) This can go at the top of the Update function:\nclientSideFields := map[string]bool{\u0026#34;deletion_protection\u0026#34;: true} clientSideOnly := true for field := range ResourceSpannerInstance().Schema { if d.HasChange(field) \u0026amp;\u0026amp; !clientSideFields[field] { clientSideOnly = false break } } if clientSideOnly { return nil }Replace ResourceSpannerInstance with the appropriate resource function.\nUpdate data source# If the resource has a corresponding data source that calls the resource\u0026rsquo;s Read function, you will need to make the following changes to the data source:\nAdd the client-side field to the data source\u0026rsquo;s Schema as an output-only field. (This will happen automatically for data sources that use tpgresource.DatasourceSchemaFromResourceSchema.)\n\u0026#34;deletion_protection\u0026#34;: { Type: schema.TypeBool, Computed: true, }, Unset the field in the data source\u0026rsquo;s Read function.\nif err := d.Set(\u0026#34;deletion_protection\u0026#34;, nil); err != nil { return fmt.Errorf(\u0026#34;Error setting deletion_protection: %s\u0026#34;, err) } Implement logic# At this point, you should be ready to implement your logic! For example, a deletion_protection field short-ciruits the deletion process if it is not explicitly set to false.\nMMv1 Add the following as pre_delete custom code.\nif d.Get(\u0026#34;deletion_protection\u0026#34;).(bool) { return fmt.Errorf(\u0026#34;cannot destroy folder without setting deletion_protection=false and running `terraform apply`\u0026#34;) } Handwritten Add the following at the beginning of the resource\u0026rsquo;s Delete function.\nif d.Get(\u0026#34;deletion_protection\u0026#34;).(bool) { return fmt.Errorf(\u0026#34;cannot destroy folder without setting deletion_protection=false and running `terraform apply`\u0026#34;) } "}]