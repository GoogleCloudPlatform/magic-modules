# Copyright 2023 Google Inc.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

--- !ruby/object:Api::Resource
name: Pipeline
base_url: projects/{{project}}/locations/{{region}}/pipelines
update_verb: :PATCH
update_mask: true
description: |
  The main pipeline entity and all the necessary metadata for launching and managing linked jobs.
references: !ruby/object:Api::Resource::ReferenceLinks
  guides:
    'Official Documentation': 'https://cloud.google.com/dataflow'
  api: 'https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines'
id_format: projects/{{project}}/locations/{{region}}/pipelines/{{name}}
import_format:
  ['projects/{{project}}/locations/{{region}}/pipelines/{{name}}']
examples:
  - !ruby/object:Provider::Terraform::Examples
    name: 'data_pipeline_pipeline'
    primary_resource_name:
      'fmt.Sprintf("tf-test-my-pipeline%s", context["random_suffix"])'
    primary_resource_id: 'primary'
    vars:
      pipeline_name: 'my-pipeline'
      account_id: 'my-account'
parameters:
  - !ruby/object:Api::Type::String
    name: 'region'
    description: 'A reference to the region'
    url_param_only: true
properties:
  - !ruby/object:Api::Type::String
    name: 'name'
    description: |
      "The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID."
      "- PROJECT_ID can contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see Identifying projects."
      "LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine regions."
      "PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
    required: true
    immutable: true
    pattern: projects/{{project}}/locations/{{region}}/functions/{{name}}
    custom_flatten: 'templates/terraform/custom_flatten/name_from_self_link.erb'
    custom_expand: 'templates/terraform/custom_expand/shortname_to_url.go.erb'
  - !ruby/object:Api::Type::String
    name: 'displayName'
    description: |
      The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores (_).
  - !ruby/object:Api::Type::Enum
    name: 'type'
    description: |
      The type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the pipeline.
      https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
    required: true
    values:
      - :PIPELINE_TYPE_UNSPECIFIED
      - :PIPELINE_TYPE_BATCH
      - :PIPELINE_TYPE_STREAMING
  - !ruby/object:Api::Type::Enum
    name: 'state'
    description: |
      The state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through pipelines.patch requests.
      https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state
    required: true
    immutable: true
    values:
      - :STATE_UNSPECIFIED
      - :STATE_RESUMING
      - :STATE_ACTIVE
      - :STATE_STOPPING
      - :STATE_ARCHIVED
      - :STATE_PAUSED
  - !ruby/object:Api::Type::String
    name: 'createTime'
    description: |
      The timestamp when the pipeline was initially created. Set by the Data Pipelines service.
      A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
    output: true
  - !ruby/object:Api::Type::String
    name: 'lastUpdateTime'
    description: |
      The timestamp when the pipeline was last modified. Set by the Data Pipelines service.
      A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
    output: true
  - !ruby/object:Api::Type::NestedObject
    name: 'workload'
    description: |
      Workload information for creating new jobs.
      https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
    properties:
      - !ruby/object:Api::Type::NestedObject
        name: 'dataflowLaunchTemplateRequest'
        description: |
          Template information and additional parameters needed to launch a Dataflow job using the standard launch API.
          https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#launchtemplaterequest
        properties:
          - !ruby/object:Api::Type::String
            name: 'projectId'
            description: |
              The ID of the Cloud Platform project that the job belongs to.
            required: true
          - !ruby/object:Api::Type::Boolean
            name: 'validateOnly'
            description: |
          - !ruby/object:Api::Type::NestedObject
            name: 'launchParameters'
            description: |
              The parameters of the template to launch. This should be part of the body of the POST request.
              https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#launchtemplateparameters
            properties:
              - !ruby/object:Api::Type::String
                name: 'jobName'
                description: |
                  The job name to use for the created job.
                required: true
              - !ruby/object:Api::Type::KeyValuePairs
                name: 'parameters'
                description: |
                  The runtime parameters to pass to the job.
                  'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'
              - !ruby/object:Api::Type::NestedObject
                name: 'environment'
                description: |
                  The runtime environment for the job.
                  https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#RuntimeEnvironment
                properties:
                  - !ruby/object:Api::Type::Integer
                    name: 'numWorkers'
                    description: |
                      The initial number of Compute Engine instances for the job.
                  - !ruby/object:Api::Type::Integer
                    name: 'maxWorkers'
                    description: |
                      The maximum number of Compute Engine instances to be made available to your pipeline during execution, from 1 to 1000.
                  - !ruby/object:Api::Type::String
                    name: 'zone'
                    description: |
                      The Compute Engine availability zone for launching worker instances to run your pipeline. In the future, workerZone will take precedence.
                  - !ruby/object:Api::Type::String
                    name: 'serviceAccountEmail'
                    description: |
                      The email address of the service account to run the job as.
                  - !ruby/object:Api::Type::String
                    name: 'tempLocation'
                    description: |
                      The Cloud Storage path to use for temporary files. Must be a valid Cloud Storage URL, beginning with gs://.
                  - !ruby/object:Api::Type::Boolean
                    name: 'bypassTempDirValidation'
                    description: |
                      Whether to bypass the safety checks for the job's temporary directory. Use with caution.
                  - !ruby/object:Api::Type::String
                    name: 'machineType'
                    description: |
                      The machine type to use for the job. Defaults to the value from the template if not specified.
                  - !ruby/object:Api::Type::Array
                    name: 'additionalExperiments'
                    item_type: Api::Type::String
                    description: |
                      Additional experiment flags for the job.
                  - !ruby/object:Api::Type::String
                    name: 'network'
                    description: |
                      Network to which VMs will be assigned. If empty or unspecified, the service will use the network "default".
                    default_from_api: true
                  - !ruby/object:Api::Type::String
                    name: 'subnetwork'
                    description: |
                      Subnetwork to which VMs will be assigned, if desired. You can specify a subnetwork using either a complete URL or an abbreviated path. Expected to be of the form "https://www.googleapis.com/compute/v1/projects/HOST_PROJECT_ID/regions/REGION/subnetworks/SUBNETWORK" or "regions/REGION/subnetworks/SUBNETWORK". If the subnetwork is located in a Shared VPC network, you must use the complete URL.
                  - !ruby/object:Api::Type::KeyValuePairs
                    name: 'additionalUserLabels'
                    description: |
                      Additional user labels to be specified for the job. Keys and values should follow the restrictions specified in the labeling restrictions page. An object containing a list of key/value pairs.
                      'Example: { "name": "wrench", "mass": "1kg", "count": "3" }.'
                      'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'
                  - !ruby/object:Api::Type::String
                    name: 'kmsKeyName'
                    description: |
                      'Name for the Cloud KMS key for the job. The key format is: projects//locations//keyRings//cryptoKeys/'
                  - !ruby/object:Api::Type::Enum
                    name: 'ipConfiguration'
                    description: |
                      Configuration for VM IPs.
                      https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#WorkerIPAddressConfiguration
                    values:
                      - :WORKER_IP_UNSPECIFIED
                      - :WORKER_IP_PUBLIC
                      - :WORKER_IP_PRIVATE
                  - !ruby/object:Api::Type::String
                    name: 'workerRegion'
                    description: |
                      The Compute Engine region (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. "us-west1". Mutually exclusive with workerZone. If neither workerRegion nor workerZone is specified, default to the control plane's region.
                  - !ruby/object:Api::Type::String
                    name: 'workerZone'
                    description: |
                      The Compute Engine zone (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. "us-west1-a". Mutually exclusive with workerRegion. If neither workerRegion nor workerZone is specified, a zone in the control plane's region is chosen based on available capacity. If both workerZone and zone are set, workerZone takes precedence.
                  - !ruby/object:Api::Type::Boolean
                    name: 'enableStreamingEngine'
                    description: |
                      Whether to enable Streaming Engine for the job.
              - !ruby/object:Api::Type::Boolean
                name: 'update'
                description: |
                  If set, replace the existing pipeline with the name specified by jobName with this pipeline, preserving state.
              - !ruby/object:Api::Type::KeyValuePairs
                name: 'transformNameMapping'
                description: |
                  Map of transform name prefixes of the job to be replaced to the corresponding name prefixes of the new job. Only applicable when updating a pipeline.
                  'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'
          - !ruby/object:Api::Type::String
            name: 'location'
            description: |
              The regional endpoint to which to direct the request.
          - !ruby/object:Api::Type::String
            name: 'gcsPath'
            description: |
              A Cloud Storage path to the template from which to create the job. Must be a valid Cloud Storage URL, beginning with 'gs://'.
      - !ruby/object:Api::Type::NestedObject
        name: 'dataflowFlexTemplateRequest'
        description: |
          Template information and additional parameters needed to launch a Dataflow job using the flex launch API.
          https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#launchflextemplaterequest
        properties:
          - !ruby/object:Api::Type::String
            name: 'projectId'
            description: |
              The ID of the Cloud Platform project that the job belongs to.
            required: true
          - !ruby/object:Api::Type::NestedObject
            name: 'launchParameter'
            description: |
              Parameter to launch a job from a Flex Template.
              https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#launchflextemplateparameter
            required: true
            properties:
              - !ruby/object:Api::Type::String
                name: 'jobName'
                description: |
                  The job name to use for the created job. For an update job request, the job name should be the same as the existing running job.
                required: true
              - !ruby/object:Api::Type::KeyValuePairs
                name: 'parameters'
                description: |
                  'The parameters for the Flex Template. Example: {"numWorkers":"5"}'
                  'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'
              - !ruby/object:Api::Type::KeyValuePairs
                name: 'launchOptions'
                description: |
                  Launch options for this Flex Template job. This is a common set of options across languages and templates. This should not be used to pass job parameters.
                  'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'
              - !ruby/object:Api::Type::NestedObject
                name: 'environment'
                description: |
                  The runtime environment for the Flex Template job.
                  https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#FlexTemplateRuntimeEnvironment
                properties:
                  - !ruby/object:Api::Type::Integer
                    name: 'numWorkers'
                    description: |
                      The initial number of Compute Engine instances for the job.
                  - !ruby/object:Api::Type::Integer
                    name: 'maxWorkers'
                    description: |
                      The maximum number of Compute Engine instances to be made available to your pipeline during execution, from 1 to 1000.
                  - !ruby/object:Api::Type::String
                    name: 'zone'
                    description: |
                      The Compute Engine availability zone for launching worker instances to run your pipeline. In the future, workerZone will take precedence.
                  - !ruby/object:Api::Type::String
                    name: 'serviceAccountEmail'
                    description: |
                      The email address of the service account to run the job as.
                  - !ruby/object:Api::Type::String
                    name: 'tempLocation'
                    description: |
                      The Cloud Storage path to use for temporary files. Must be a valid Cloud Storage URL, beginning with gs://.
                  - !ruby/object:Api::Type::String
                    name: 'machineType'
                    description: |
                      The machine type to use for the job. Defaults to the value from the template if not specified.
                  - !ruby/object:Api::Type::Array
                    name: 'additionalExperiments'
                    item_type: Api::Type::String
                    description: |
                      Additional experiment flags for the job.
                  - !ruby/object:Api::Type::String
                    name: 'network'
                    description: |
                      Network to which VMs will be assigned. If empty or unspecified, the service will use the network "default".
                  - !ruby/object:Api::Type::String
                    name: 'subnetwork'
                    description: |
                      Subnetwork to which VMs will be assigned, if desired. You can specify a subnetwork using either a complete URL or an abbreviated path. Expected to be of the form "https://www.googleapis.com/compute/v1/projects/HOST_PROJECT_ID/regions/REGION/subnetworks/SUBNETWORK" or "regions/REGION/subnetworks/SUBNETWORK". If the subnetwork is located in a Shared VPC network, you must use the complete URL.
                  - !ruby/object:Api::Type::KeyValuePairs
                    name: 'additionalUserLabels'
                    description: |
                      Additional user labels to be specified for the job. Keys and values should follow the restrictions specified in the labeling restrictions page. An object containing a list of key/value pairs.
                      'Example: { "name": "wrench", "mass": "1kg", "count": "3" }.'
                      'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'
                  - !ruby/object:Api::Type::String
                    name: 'kmsKeyName'
                    description: |
                      'Name for the Cloud KMS key for the job. The key format is: projects//locations//keyRings//cryptoKeys/'
                  - !ruby/object:Api::Type::Enum
                    name: 'ipConfiguration'
                    description: |
                      Configuration for VM IPs.
                      https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#WorkerIPAddressConfiguration
                    values:
                      - :WORKER_IP_UNSPECIFIED
                      - :WORKER_IP_PUBLIC
                      - :WORKER_IP_PRIVATE
                  - !ruby/object:Api::Type::String
                    name: 'workerRegion'
                    description: |
                      The Compute Engine region (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. "us-west1". Mutually exclusive with workerZone. If neither workerRegion nor workerZone is specified, default to the control plane's region.
                  - !ruby/object:Api::Type::String
                    name: 'workerZone'
                    description: |
                      The Compute Engine zone (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. "us-west1-a". Mutually exclusive with workerRegion. If neither workerRegion nor workerZone is specified, a zone in the control plane's region is chosen based on available capacity. If both workerZone and zone are set, workerZone takes precedence.
                  - !ruby/object:Api::Type::Boolean
                    name: 'enableStreamingEngine'
                    description: |
                      Whether to enable Streaming Engine for the job.
                  - !ruby/object:Api::Type::Enum
                    name: 'flexrsGoal'
                    description: |
                      Set FlexRS goal for the job. https://cloud.google.com/dataflow/docs/guides/flexrs
                      https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#FlexResourceSchedulingGoal
                    values:
                      - :FLEXRS_UNSPECIFIED
                      - :FLEXRS_SPEED_OPTIMIZED
                      - :FLEXRS_COST_OPTIMIZED
              - !ruby/object:Api::Type::Boolean
                name: 'update'
                description: |
                  Set this to true if you are sending a request to update a running streaming job. When set, the job name should be the same as the running job.
              - !ruby/object:Api::Type::KeyValuePairs
                name: 'transformNameMappings'
                description: |
                  'Use this to pass transform name mappings for streaming update jobs. Example: {"oldTransformName":"newTransformName",...}'
                  'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'
              - !ruby/object:Api::Type::String
                name: 'containerSpecGcsPath'
                description: |
                  Cloud Storage path to a file with a JSON-serialized ContainerSpec as content.
          - !ruby/object:Api::Type::String
            name: 'location'
            description: |
              The regional endpoint to which to direct the request. For example, us-central1, us-west1.
            required: true
          - !ruby/object:Api::Type::Boolean
            name: 'validateOnly'
            description: |
              If true, the request is validated but not actually executed. Defaults to false.
  - !ruby/object:Api::Type::NestedObject
    name: 'scheduleInfo'
    description: |
      Internal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the schedule. If not, users are responsible for creating jobs externally.
      https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
    properties:
      - !ruby/object:Api::Type::String
        name: 'schedule'
        description: |
          Unix-cron format of the schedule. This information is retrieved from the linked Cloud Scheduler.
      - !ruby/object:Api::Type::String
        name: 'timeZone'
        description: |
          Timezone ID. This matches the timezone IDs used by the Cloud Scheduler API. If empty, UTC time is assumed.
        default_value: UTC
      - !ruby/object:Api::Type::String
        name: 'nextJobTime'
        description: |
          When the next Scheduler job is going to run.
          A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
        output: true
  - !ruby/object:Api::Type::Integer
    name: 'jobCount'
    description: |
      Number of jobs.
    output: true
  - !ruby/object:Api::Type::String
    name: 'schedulerServiceAccountEmail'
    description: |
      Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine service account will be used.
    immutable: true
  - !ruby/object:Api::Type::KeyValuePairs
    name: 'pipelineSources'
    description: |
       The sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during pipeline creation.
       An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
    immutable: true
