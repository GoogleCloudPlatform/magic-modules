# Copyright 2023 Google Inc.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

--- !ruby/object:Api::Resource
name: 'Routine'
kind: 'bigquery#routine'
base_url: projects/{{project}}/datasets/{{dataset_id}}/routines
self_link: projects/{{project}}/datasets/{{dataset_id}}/routines/{{routine_id}}
description: |
  A user-defined function or a stored procedure that belongs to a Dataset
references: !ruby/object:Api::Resource::ReferenceLinks
  guides:
    'Routines Intro': 'https://cloud.google.com/bigquery/docs/reference/rest/v2/routines'
  api: 'https://cloud.google.com/bigquery/docs/reference/rest/v2/routines'
import_format:
  ['projects/{{project}}/datasets/{{dataset_id}}/routines/{{routine_id}}']
examples:
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_routine_basic'
    primary_resource_id: 'sproc'
    primary_resource_name: "fmt.Sprintf(\"tf_test_dataset_id%s\",
      context[\"random_suffix\"\
      ]), fmt.Sprintf(\"tf_test_table_id%s\", context[\"random_suffix\"])"
    vars:
      dataset_id: 'dataset_id'
      routine_id: 'routine_id'
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_routine_json'
    primary_resource_id: 'sproc'
    primary_resource_name: "fmt.Sprintf(\"tf_test_dataset_id%s\",
      context[\"random_suffix\"\
      ]), fmt.Sprintf(\"tf_test_table_id%s\", context[\"random_suffix\"])"
    vars:
      dataset_id: 'dataset_id'
      routine_id: 'routine_id'
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_routine_tvf'
    primary_resource_id: 'sproc'
    primary_resource_name: "fmt.Sprintf(\"tf_test_dataset_id%s\",
      context[\"random_suffix\"\
      ]), fmt.Sprintf(\"tf_test_table_id%s\", context[\"random_suffix\"])"
    vars:
      dataset_id: 'dataset_id'
      routine_id: 'routine_id'
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_routine_pyspark'
    primary_resource_id: 'pyspark'
    vars:
      dataset_id: 'dataset_id'
      connection_id: 'connection_id'
      routine_id: 'routine_id'
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_routine_pyspark_mainfile'
    primary_resource_id: 'pyspark_mainfile'
    vars:
      dataset_id: 'dataset_id'
      connection_id: 'connection_id'
      routine_id: 'routine_id'
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_routine_spark_jar'
    primary_resource_id: 'spark_jar'
    vars:
      dataset_id: 'dataset_id'
      connection_id: 'connection_id'
      routine_id: 'routine_id'
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_routine_data_governance_type'
    primary_resource_id: 'custom_masking_routine'
    vars:
      dataset_id: 'dataset_id'
      routine_id: 'routine_id'
  - !ruby/object:Provider::Terraform::Examples
    skip_test: true
    name: 'bigquery_routine_remote_function'
    primary_resource_id: 'remote_function'
    vars:
      dataset_id: 'dataset_id'
      connection_id: 'connection_id'
      routine_id: 'routine_id'
properties:
  - !ruby/object:Api::Type::NestedObject
    name: routineReference
    description: Reference describing the ID of this routine
    required: true
    custom_expand: 'templates/terraform/custom_expand/bigquery_routine_ref.go.erb'
    flatten_object: true
    properties:
      - !ruby/object:Api::Type::String
        name: 'datasetId'
        description: The ID of the dataset containing this routine
        required: true
        immutable: true
      - !ruby/object:Api::Type::String
        name: 'routineId'
        description:
          The ID of the the routine. The ID must contain only letters (a-z,
          A-Z), numbers (0-9), or underscores (_). The maximum length is 256
          characters.
        required: true
        immutable: true
  - !ruby/object:Api::Type::Enum
    name: 'routineType'
    immutable: true
    required: true
    description: The type of routine.
    values:
      - :SCALAR_FUNCTION
      - :PROCEDURE
      - :TABLE_VALUED_FUNCTION
  - !ruby/object:Api::Type::Integer
    name: 'creationTime'
    output: true
    description: |
      The time when this routine was created, in milliseconds since the
      epoch.
  - !ruby/object:Api::Type::Integer
    name: 'lastModifiedTime'
    output: true
    description: |
      The time when this routine was modified, in milliseconds since the
      epoch.
  - !ruby/object:Api::Type::Enum
    name: 'language'
    description: |
      The language of the routine.
    values:
      - :SQL
      - :JAVASCRIPT
      - :PYTHON
      - :JAVA
      - :SCALA
  - !ruby/object:Api::Type::Array
    name: 'arguments'
    description: Input/output argument of a function or a stored procedure.
    item_type: !ruby/object:Api::Type::NestedObject
      properties:
        - !ruby/object:Api::Type::String
          name: 'name'
          description: |
            The name of this argument. Can be absent for function return argument.
        - !ruby/object:Api::Type::Enum
          name: 'argumentKind'
          description: Defaults to FIXED_TYPE.
          values:
            - :FIXED_TYPE
            - :ANY_TYPE
          default_value: :FIXED_TYPE
        - !ruby/object:Api::Type::Enum
          name: 'mode'
          description: |
            Specifies whether the argument is input or output. Can be set for procedures only.
          values:
            - :IN
            - :OUT
            - :INOUT
        # This is a string instead of a NestedObject because schemas contain ColumnSchemas,
        # which can contain nested StandardSqlDataType.
        # We'll have people provide the json blob for the schema instead.
        - !ruby/object:Api::Type::String
          name: 'dataType'
          description: |
            A JSON schema for the data type. Required unless argumentKind = ANY_TYPE.
            ~>**NOTE**: Because this field expects a JSON string, any changes to the string
            will create a diff, even if the JSON itself hasn't changed. If the API returns
            a different value for the same schema, e.g. it switched the order of values
            or replaced STRUCT field type with RECORD field type, we currently cannot
            suppress the recurring diff this causes. As a workaround, we recommend using
            the schema as returned by the API.
          custom_expand: 'templates/terraform/custom_expand/json_schema.erb'
          custom_flatten: 'templates/terraform/custom_flatten/json_schema.erb'
          state_func:
            'func(v interface{}) string { s, _ :=
            structure.NormalizeJsonString(v); return s }'
          validation: !ruby/object:Provider::Terraform::Validation
            function: 'validation.StringIsJSON'
  - !ruby/object:Api::Type::String
    name: 'returnType'
    description: |
      A JSON schema for the return type. Optional if language = "SQL"; required otherwise.
      If absent, the return type is inferred from definitionBody at query time in each query
      that references this routine. If present, then the evaluated result will be cast to
      the specified returned type at query time. ~>**NOTE**: Because this field expects a JSON
      string, any changes to the string will create a diff, even if the JSON itself hasn't
      changed. If the API returns a different value for the same schema, e.g. it switche
      d the order of values or replaced STRUCT field type with RECORD field type, we currently
      cannot suppress the recurring diff this causes. As a workaround, we recommend using
      the schema as returned by the API.
    custom_expand: 'templates/terraform/custom_expand/json_schema.erb'
    custom_flatten: 'templates/terraform/custom_flatten/json_schema.erb'
    state_func:
      'func(v interface{}) string { s, _ := structure.NormalizeJsonString(v);
      return s }'
    validation: !ruby/object:Provider::Terraform::Validation
      function: 'validation.StringIsJSON'
  - !ruby/object:Api::Type::String
    name: 'returnTableType'
    description: |
      Optional. Can be set only if routineType = "TABLE_VALUED_FUNCTION".

      If absent, the return table type is inferred from definitionBody at query time in each query
      that references this routine. If present, then the columns in the evaluated table result will
      be cast to match the column types specificed in return table type, at query time.
    custom_expand: 'templates/terraform/custom_expand/json_schema.erb'
    custom_flatten: 'templates/terraform/custom_flatten/json_schema.erb'
    state_func:
      'func(v interface{}) string { s, _ := structure.NormalizeJsonString(v);
      return s }'
    validation: !ruby/object:Provider::Terraform::Validation
      function: 'validation.StringIsJSON'
  - !ruby/object:Api::Type::Array
    name: 'importedLibraries'
    description: |
      Optional. If language = "JAVASCRIPT", this field stores the path of the
      imported JAVASCRIPT libraries.
    item_type: Api::Type::String
  - !ruby/object:Api::Type::String
    name: 'definitionBody'
    required: true
    description: |
      The body of the routine. For functions, this is the expression in the AS clause.
      If language=SQL, it is the substring inside (but excluding) the parentheses.
  - !ruby/object:Api::Type::String
    name: 'description'
    description: The description of the routine if defined.
  - !ruby/object:Api::Type::Enum
    name: 'determinismLevel'
    description: The determinism level of the JavaScript UDF if defined.
    values:
      - :DETERMINISM_LEVEL_UNSPECIFIED
      - :DETERMINISTIC
      - :NOT_DETERMINISTIC
  - !ruby/object:Api::Type::Enum
    name: 'dataGovernanceType'
    description: If set to DATA_MASKING, the function is validated and made available as a masking function. For more information, see https://cloud.google.com/bigquery/docs/user-defined-functions#custom-mask
    values:
      - :DATA_MASKING
  - !ruby/object:Api::Type::NestedObject
    name: 'sparkOptions'
    description: |
      Optional. If language is one of "PYTHON", "JAVA", "SCALA", this field stores the options for spark stored procedure.
    properties:
      - !ruby/object:Api::Type::String
        name: 'connection'
        description: |
          Fully qualified name of the user-provided Spark connection object.
          Format: "projects/{projectId}/locations/{locationId}/connections/{connectionId}"
      - !ruby/object:Api::Type::String
        name: 'runtimeVersion'
        description: Runtime version. If not specified, the default runtime version is used.
      - !ruby/object:Api::Type::String
        name: 'containerImage'
        description: Custom container image for the runtime environment.
      - !ruby/object:Api::Type::KeyValuePairs
        name: "properties"
        description: |
          Configuration properties as a set of key/value pairs, which will be passed on to the Spark application.
          For more information, see Apache Spark and the procedure option list.
          An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
        default_from_api: true
      - !ruby/object:Api::Type::String
        name: 'mainFileUri'
        description: |
          The main file/jar URI of the Spark application.
          Exactly one of the definitionBody field and the mainFileUri field must be set for Python.
          Exactly one of mainClass and mainFileUri field should be set for Java/Scala language type.
      - !ruby/object:Api::Type::Array
        name: 'pyFileUris'
        description: |
          Python files to be placed on the PYTHONPATH for PySpark application. Supported file types: .py, .egg, and .zip. For more information about Apache Spark, see Apache Spark.
        item_type: Api::Type::String
        default_from_api: true
      - !ruby/object:Api::Type::Array
        name: 'jarUris'
        description: |
          JARs to include on the driver and executor CLASSPATH. For more information about Apache Spark, see Apache Spark.
        item_type: Api::Type::String
        default_from_api: true
      - !ruby/object:Api::Type::Array
        name: 'fileUris'
        description: |
          Files to be placed in the working directory of each executor. For more information about Apache Spark, see Apache Spark.
        item_type: Api::Type::String
        default_from_api: true
      - !ruby/object:Api::Type::Array
        name: 'archiveUris'
        description: |
          Archive files to be extracted into the working directory of each executor. For more information about Apache Spark, see Apache Spark.
        item_type: Api::Type::String
        default_from_api: true
      - !ruby/object:Api::Type::String
        name: 'mainClass'
        description: |
          The fully qualified name of a class in jarUris, for example, com.example.wordcount.
          Exactly one of mainClass and main_jar_uri field should be set for Java/Scala language type.
  - !ruby/object:Api::Type::NestedObject
    name: 'remoteFunctionOptions'
    description: Remote function specific options.
    properties:
      - !ruby/object:Api::Type::String
        name: 'endpoint'
        description: |
          Endpoint of the user-provided remote service, e.g.
          `https://us-east1-my_gcf_project.cloudfunctions.net/remote_add`
      - !ruby/object:Api::Type::String
        name: 'connection'
        description: |
          Fully qualified name of the user-provided connection object which holds
          the authentication information to send requests to the remote service.
          Format: "projects/{projectId}/locations/{locationId}/connections/{connectionId}"
      - !ruby/object:Api::Type::KeyValuePairs
        name: 'userDefinedContext'
        description: |
          User-defined context as a set of key/value pairs, which will be sent as function
          invocation context together with batched arguments in the requests to the remote
          service. The total number of bytes of keys and values must be less than 8KB.

          An object containing a list of "key": value pairs. Example:
          `{ "name": "wrench", "mass": "1.3kg", "count": "3" }`.
        default_from_api: true
      - !ruby/object:Api::Type::String
        name: 'maxBatchingRows'
        description: |
          Max number of rows in each batch sent to the remote service. If absent or if 0,
          BigQuery dynamically decides the number of rows in a batch.
