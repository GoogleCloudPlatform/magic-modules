# Copyright 2017 Google Inc.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

--- !ruby/object:Api::Product
name: BigQuery
display_name: BigQuery
versions:
  - !ruby/object:Api::Product::Version
    name: ga
    base_url: https://bigquery.googleapis.com/bigquery/v2/
scopes:
  - https://www.googleapis.com/auth/bigquery
apis_required:
  - !ruby/object:Api::Product::ApiReference
    name: BigQuery API
    url: https://console.cloud.google.com/apis/library/bigquery-json.googleapis.com/
objects:
  - !ruby/object:Api::Resource
    name: 'Dataset'
    kind: 'bigquery#dataset'
    base_url: projects/{{project}}/datasets
    self_link: projects/{{project}}/datasets/{{dataset_id}}
    has_self_link: true
    description: |
      Datasets allow you to organize and control access to your tables.
    references: !ruby/object:Api::Resource::ReferenceLinks
      guides:
        'Datasets Intro': 'https://cloud.google.com/bigquery/docs/datasets-intro'
      api: 'https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets'
    properties:
      - !ruby/object:Api::Type::String
        name: 'name'
        description: 'Dataset name'
      - !ruby/object:Api::Type::Array
        name: 'access'
        description: 'An array of objects that define dataset access for one or more entities.'
        item_type: !ruby/object:Api::Type::NestedObject
          properties:
            - !ruby/object:Api::Type::String
              name: 'domain'
              description: |
                A domain to grant access to. Any users signed in with the
                domain specified will be granted the specified access
            - !ruby/object:Api::Type::String
              name: 'groupByEmail'
              description: An email address of a Google Group to grant access to.
            - !ruby/object:Api::Type::String
              name: 'role'
              description: |
                Describes the rights granted to the user specified by the other
                member of the access object. Basic, predefined, and custom roles
                are supported. Predefined roles that have equivalent basic roles
                are swapped by the API to their basic counterparts. See
                [official docs](https://cloud.google.com/bigquery/docs/access-control).
            - !ruby/object:Api::Type::String
              name: 'specialGroup'
              description: |
                A special group to grant access to. Possible values include:


                * `projectOwners`: Owners of the enclosing project.


                * `projectReaders`: Readers of the enclosing project.


                * `projectWriters`: Writers of the enclosing project.


                * `allAuthenticatedUsers`: All authenticated BigQuery users.
            - !ruby/object:Api::Type::String
              name: 'userByEmail'
              description: |
                An email address of a user to grant access to. For example:
                fred@example.com
            - !ruby/object:Api::Type::String
              name: 'iamMember'
              description: |
                Some other type of member that appears in the IAM Policy but isn't a user,
                group, domain, or special group. For example: `allUsers`
            - !ruby/object:Api::Type::NestedObject
              name: 'view'
              description: |
                A view from a different dataset to grant access to. Queries
                executed against that view will have read access to tables in
                this dataset. The role field is not required when this field is
                set. If that view is updated by any user, access to the view
                needs to be granted again via an update operation.
              properties:
                - !ruby/object:Api::Type::String
                  name: 'datasetId'
                  description: The ID of the dataset containing this table.
                  required: true
                - !ruby/object:Api::Type::String
                  name: 'projectId'
                  description: The ID of the project containing this table.
                  required: true
                - !ruby/object:Api::Type::String
                  name: 'tableId'
                  description: |
                    The ID of the table. The ID must contain only letters (a-z,
                    A-Z), numbers (0-9), or underscores (_). The maximum length
                    is 1,024 characters.
                  required: true
      - !ruby/object:Api::Type::Integer
        name: 'creationTime'
        output: true
        description: |
          The time when this dataset was created, in milliseconds since the
          epoch.
      - !ruby/object:Api::Type::NestedObject
        name: 'datasetReference'
        description: 'A reference that identifies the dataset.'
        required: true
        input: true
        properties:
          - !ruby/object:Api::Type::String
            name: 'datasetId'
            description: |
              A unique ID for this dataset, without the project name. The ID
              must contain only letters (a-z, A-Z), numbers (0-9), or
              underscores (_). The maximum length is 1,024 characters.
            required: true
            input: true
          - !ruby/object:Api::Type::String
            name: 'projectId'
            description: The ID of the project containing this dataset.
            input: true
      - !ruby/object:Api::Type::Integer
        name: 'defaultTableExpirationMs'
        description: |
          The default lifetime of all tables in the dataset, in milliseconds.
          The minimum value is 3600000 milliseconds (one hour).


          Once this property is set, all newly-created tables in the dataset
          will have an `expirationTime` property set to the creation time plus
          the value in this property, and changing the value will only affect
          new tables, not existing ones. When the `expirationTime` for a given
          table is reached, that table will be deleted automatically.
          If a table's `expirationTime` is modified or removed before the
          table expires, or if you provide an explicit `expirationTime` when
          creating a table, that value takes precedence over the default
          expiration time indicated by this property.
      - !ruby/object:Api::Type::Integer
        name: 'defaultPartitionExpirationMs'
        description: |
          The default partition expiration for all partitioned tables in
          the dataset, in milliseconds.


          Once this property is set, all newly-created partitioned tables in
          the dataset will have an `expirationMs` property in the `timePartitioning`
          settings set to this value, and changing the value will only
          affect new tables, not existing ones. The storage in a partition will
          have an expiration time of its partition time plus this value.
          Setting this property overrides the use of `defaultTableExpirationMs`
          for partitioned tables: only one of `defaultTableExpirationMs` and
          `defaultPartitionExpirationMs` will be used for any new partitioned
          table. If you provide an explicit `timePartitioning.expirationMs` when
          creating or updating a partitioned table, that value takes precedence
          over the default partition expiration time indicated by this property.
      - !ruby/object:Api::Type::String
        name: 'description'
        description: A user-friendly description of the dataset
      - !ruby/object:Api::Type::String
        name: 'etag'
        description: |
          A hash of the resource.
        output: true
      - !ruby/object:Api::Type::String
        name: 'friendlyName'
        description: A descriptive name for the dataset
      - !ruby/object:Api::Type::String
        name: 'id'
        output: true
        description: |
          The fully-qualified unique name of the dataset in the format
          projectId:datasetId. The dataset name without the project name is
          given in the datasetId field
      - !ruby/object:Api::Type::KeyValuePairs
        name: 'labels'
        description: |
          The labels associated with this dataset. You can use these to
          organize and group your datasets
      - !ruby/object:Api::Type::Integer
        name: 'lastModifiedTime'
        description: |
          The date when this dataset or any of its tables was last modified, in
          milliseconds since the epoch.
        output: true
      - !ruby/object:Api::Type::String
        name: 'location'
        description: |
          The geographic location where the dataset should reside.
          See [official docs](https://cloud.google.com/bigquery/docs/dataset-locations).


          There are two types of locations, regional or multi-regional. A regional
          location is a specific geographic place, such as Tokyo, and a multi-regional
          location is a large geographic area, such as the United States, that
          contains at least two geographic places.


          The default value is multi-regional location `US`.
          Changing this forces a new resource to be created.
        default_value: US
      - !ruby/object:Api::Type::NestedObject
        name: 'defaultEncryptionConfiguration'
        description: |
          The default encryption key for all tables in the dataset. Once this property is set,
          all newly-created partitioned tables in the dataset will have encryption key set to
          this value, unless table creation request (or query) overrides the key.
        properties:
          - !ruby/object:Api::Type::String
            name: 'kmsKeyName'
            required: true
            description: |
              Describes the Cloud KMS encryption key that will be used to protect destination
              BigQuery table. The BigQuery Service Account associated with your project requires
              access to this encryption key.
  - !ruby/object:Api::Resource
    name: 'DatasetAccess'
    input: true
    base_url: projects/{{project}}/datasets/{{dataset_id}}
    self_link: projects/{{project}}/datasets/{{dataset_id}}
    create_verb: :PATCH
    delete_verb: :PATCH
    nested_query: !ruby/object:Api::Resource::NestedQuery
      keys:
        - access
      modify_by_patch: true
    identity:
      - role
      - userByEmail
      - groupByEmail
      - domain
      - specialGroup
      - iamMember
      - view
    description: |
      Gives dataset access for a single entity. This resource is intended to be used in cases where
      it is not possible to compile a full list of access blocks to include in a
      `google_bigquery_dataset` resource, to enable them to be added separately.

      ~> **Note:** If this resource is used alongside a `google_bigquery_dataset` resource, the
      dataset resource must either have no defined `access` blocks or a `lifecycle` block with
      `ignore_changes = [access]` so they don't fight over which accesses should be on the dataset.
    references: !ruby/object:Api::Resource::ReferenceLinks
      guides:
        'Controlling access to datasets': 'https://cloud.google.com/bigquery/docs/dataset-access-controls'
      api: 'https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets'
    properties:
      - !ruby/object:Api::Type::String
        name: 'datasetId'
        description: |
          A unique ID for this dataset, without the project name. The ID
          must contain only letters (a-z, A-Z), numbers (0-9), or
          underscores (_). The maximum length is 1,024 characters.
        required: true
      - !ruby/object:Api::Type::String
        name: 'role'
        description: |
          Describes the rights granted to the user specified by the other
          member of the access object. Basic, predefined, and custom roles are
          supported. Predefined roles that have equivalent basic roles are
          swapped by the API to their basic counterparts, and will show a diff
          post-create. See
          [official docs](https://cloud.google.com/bigquery/docs/access-control).
      - !ruby/object:Api::Type::String
        name: 'userByEmail'
        description: |
          An email address of a user to grant access to. For example:
          fred@example.com
        exactly_one_of:
          - user_by_email
          - group_by_email
          - domain
          - special_group
          - iam_member
          - view
      - !ruby/object:Api::Type::String
        name: 'groupByEmail'
        description: An email address of a Google Group to grant access to.
        exactly_one_of:
          - user_by_email
          - group_by_email
          - domain
          - special_group
          - iam_member
          - view
      - !ruby/object:Api::Type::String
        name: 'domain'
        description: |
          A domain to grant access to. Any users signed in with the
          domain specified will be granted the specified access
        exactly_one_of:
          - user_by_email
          - group_by_email
          - domain
          - special_group
          - iam_member
          - view
      - !ruby/object:Api::Type::String
        name: 'specialGroup'
        description: |
          A special group to grant access to. Possible values include:


          * `projectOwners`: Owners of the enclosing project.


          * `projectReaders`: Readers of the enclosing project.


          * `projectWriters`: Writers of the enclosing project.


          * `allAuthenticatedUsers`: All authenticated BigQuery users.
        exactly_one_of:
          - user_by_email
          - group_by_email
          - domain
          - special_group
          - iam_member
          - view
      - !ruby/object:Api::Type::String
        name: 'iamMember'
        description: |
          Some other type of member that appears in the IAM Policy but isn't a user,
          group, domain, or special group. For example: `allUsers`
        exactly_one_of:
          - user_by_email
          - group_by_email
          - domain
          - special_group
          - iam_member
          - view
      - !ruby/object:Api::Type::NestedObject
        name: 'view'
        description: |
          A view from a different dataset to grant access to. Queries
          executed against that view will have read access to tables in
          this dataset. The role field is not required when this field is
          set. If that view is updated by any user, access to the view
          needs to be granted again via an update operation.
        exactly_one_of:
          - user_by_email
          - group_by_email
          - domain
          - special_group
          - iam_member
          - view
        properties:
          - !ruby/object:Api::Type::String
            name: 'datasetId'
            description: The ID of the dataset containing this table.
            required: true
          - !ruby/object:Api::Type::String
            name: 'projectId'
            description: The ID of the project containing this table.
            required: true
          - !ruby/object:Api::Type::String
            name: 'tableId'
            description: |
              The ID of the table. The ID must contain only letters (a-z,
              A-Z), numbers (0-9), or underscores (_). The maximum length
              is 1,024 characters.
            required: true
  - !ruby/object:Api::Resource
    name: 'Job'
    kind: 'bigquery#job'
    base_url: projects/{{project}}/jobs
    self_link: projects/{{project}}/jobs/{{job_id}}?location={{location}}
    input: true
    description: |
      Jobs are actions that BigQuery runs on your behalf to load data, export data, query data, or copy data.
      Once a BigQuery job is created, it cannot be changed or deleted.
    references: !ruby/object:Api::Resource::ReferenceLinks
      guides:
        'BigQuery Jobs Intro': 'https://cloud.google.com/bigquery/docs/jobs-overview'
      api: 'https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs'
    properties:
      - !ruby/object:Api::Type::String
        name: 'id'
        output: true
        description: |
          Opaque ID field of the job.
      - !ruby/object:Api::Type::String
        name: 'user_email'
        output: true
        description: |
          Email address of the user who ran the job.
      - !ruby/object:Api::Type::NestedObject
        name: 'configuration'
        description: 'Describes the job configuration.'
        required: true
        properties:
          - !ruby/object:Api::Type::String
            name: 'jobType'
            description: |
              The type of the job.
            output: true
          - !ruby/object:Api::Type::String
            name: 'jobTimeoutMs'
            description: |
              Job timeout in milliseconds. If this time limit is exceeded, BigQuery may attempt to terminate the job.
          - !ruby/object:Api::Type::KeyValuePairs
            name: 'labels'
            description: |
              The labels associated with this job. You can use these to organize and group your jobs.
          - !ruby/object:Api::Type::NestedObject
            name: 'query'
            description: 'Configures a query job.'
            exactly_one_of:
              - query
              - load
              - copy
              - extract
            properties:
              - !ruby/object:Api::Type::String
                name: 'query'
                description: |
                  SQL query text to execute. The useLegacySql field can be used to indicate whether the query uses legacy SQL or standard SQL.
                  *NOTE*: queries containing [DML language](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language)
                  (`DELETE`, `UPDATE`, `MERGE`, `INSERT`) must specify `create_disposition = ""` and `write_disposition = ""`.
                required: true
              - !ruby/object:Api::Type::NestedObject
                name: 'destinationTable'
                description: |
                  Describes the table where the query results should be stored.
                  This property must be set for large results that exceed the maximum response size.
                  For queries that produce anonymous (cached) results, this field will be populated by BigQuery.
                properties:
                  - !ruby/object:Api::Type::String
                    name: 'projectId'
                    description: 'The ID of the project containing this table.'
                    required: true
                  - !ruby/object:Api::Type::String
                    name: 'datasetId'
                    description: 'The ID of the dataset containing this table.'
                    required: true
                  - !ruby/object:Api::Type::String
                    name: 'tableId'
                    description: 'The ID of the table.'
                    required: true
              - !ruby/object:Api::Type::Array
                name: 'userDefinedFunctionResources'
                description: |
                  Describes user-defined function resources used in the query.
                item_type: !ruby/object:Api::Type::NestedObject
                  properties:
                    - !ruby/object:Api::Type::String
                      name: 'resourceUri'
                      description: 'A code resource to load from a Google Cloud Storage URI (gs://bucket/path).'
                      # TODO (mbang): exactly_one_of: resourceUri, inlineCode
                    - !ruby/object:Api::Type::String
                      name: 'inlineCode'
                      description: |
                        An inline resource that contains code for a user-defined function (UDF).
                        Providing a inline code resource is equivalent to providing a URI for a file containing the same code.
                      # TODO (mbang): exactly_one_of: resourceUri, inlineCode
              - !ruby/object:Api::Type::Enum
                name: 'createDisposition'
                description: |
                  Specifies whether the job is allowed to create new tables. The following values are supported:
                  CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
                  CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
                  Creation, truncation and append actions occur as one atomic update upon job completion
                default_value: :CREATE_IF_NEEDED
                values:
                  - :CREATE_IF_NEEDED
                  - :CREATE_NEVER
              - !ruby/object:Api::Type::Enum
                name: 'writeDisposition'
                description: |
                  Specifies the action that occurs if the destination table already exists. The following values are supported:
                  WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
                  WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
                  WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
                  Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
                  Creation, truncation and append actions occur as one atomic update upon job completion.
                default_value: :WRITE_EMPTY
                values:
                  - :WRITE_TRUNCATE
                  - :WRITE_APPEND
                  - :WRITE_EMPTY
              - !ruby/object:Api::Type::NestedObject
                name: 'defaultDataset'
                description: |
                  Specifies the default dataset to use for unqualified table names in the query. Note that this does not alter behavior of unqualified dataset names.
                properties:
                  - !ruby/object:Api::Type::String
                    name: 'datasetId'
                    description: 'A unique ID for this dataset, without the project name.'
                    required: true
                  - !ruby/object:Api::Type::String
                    name: 'projectId'
                    description: 'The ID of the project containing this table.'
              - !ruby/object:Api::Type::Enum
                name: 'priority'
                description: |
                  Specifies a priority for the query.
                default_value: :INTERACTIVE
                values:
                  - :INTERACTIVE
                  - :BATCH
              - !ruby/object:Api::Type::Boolean
                name: 'allowLargeResults'
                description: |
                  If true and query uses legacy SQL dialect, allows the query to produce arbitrarily large result tables at a slight cost in performance.
                  Requires destinationTable to be set. For standard SQL queries, this flag is ignored and large results are always allowed.
                  However, you must still set destinationTable when result size exceeds the allowed maximum response size.
              - !ruby/object:Api::Type::Boolean
                name: 'useQueryCache'
                description: |
                  Whether to look for the result in the query cache. The query cache is a best-effort cache that will be flushed whenever
                  tables in the query are modified. Moreover, the query cache is only available when a query does not have a destination table specified.
                  The default value is true.
                default_value: true
              - !ruby/object:Api::Type::Boolean
                name: 'flattenResults'
                description: |
                  If true and query uses legacy SQL dialect, flattens all nested and repeated fields in the query results.
                  allowLargeResults must be true if this is set to false. For standard SQL queries, this flag is ignored and results are never flattened.
              - !ruby/object:Api::Type::Integer
                name: 'maximumBillingTier'
                description: |
                  Limits the billing tier for this job. Queries that have resource usage beyond this tier will fail (without incurring a charge).
                  If unspecified, this will be set to your project default.
              - !ruby/object:Api::Type::String
                name: 'maximumBytesBilled'
                description: |
                  Limits the bytes billed for this job. Queries that will have bytes billed beyond this limit will fail (without incurring a charge).
                  If unspecified, this will be set to your project default.
              - !ruby/object:Api::Type::Boolean
                name: 'useLegacySql'
                description: |
                  Specifies whether to use BigQuery's legacy SQL dialect for this query. The default value is true.
                  If set to false, the query will use BigQuery's standard SQL.
                send_empty_value: true
              - !ruby/object:Api::Type::String
                name: 'parameterMode'
                description: |
                  Standard SQL only. Set to POSITIONAL to use positional (?) query parameters or to NAMED to use named (@myparam) query parameters in this query.
              - !ruby/object:Api::Type::Array
                name: 'schemaUpdateOptions'
                description: |
                  Allows the schema of the destination table to be updated as a side effect of the query job.
                  Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
                  when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table,
                  specified by partition decorators. For normal tables, WRITE_TRUNCATE will always overwrite the schema.
                  One or more of the following values are specified:
                  ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
                  ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
                item_type: Api::Type::String
              - !ruby/object:Api::Type::NestedObject
                name: 'destinationEncryptionConfiguration'
                description: |
                  Custom encryption configuration (e.g., Cloud KMS keys)
                properties:
                  - !ruby/object:Api::Type::String
                    name: 'kmsKeyName'
                    description: |
                      Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
                      The BigQuery Service Account associated with your project requires access to this encryption key.
                    required: true
              - !ruby/object:Api::Type::NestedObject
                name: 'scriptOptions'
                description: |
                  Options controlling the execution of scripts.
                properties:
                  - !ruby/object:Api::Type::String
                    name: 'statementTimeoutMs'
                    description: 'Timeout period for each statement in a script.'
                    at_least_one_of:
                      - query.0.scriptOptions.0.statementTimeoutMs
                      - query.0.scriptOptions.0.statementByteBudget
                      - query.0.scriptOptions.0.keyResultStatement
                  - !ruby/object:Api::Type::String
                    name: 'statementByteBudget'
                    description: 'Limit on the number of bytes billed per statement. Exceeding this budget results in an error.'
                    at_least_one_of:
                      - query.0.scriptOptions.0.statementTimeoutMs
                      - query.0.scriptOptions.0.statementByteBudget
                      - query.0.scriptOptions.0.keyResultStatement
                  - !ruby/object:Api::Type::Enum
                    name: 'keyResultStatement'
                    description: |
                      Determines which statement in the script represents the "key result",
                      used to populate the schema and query results of the script job.
                    at_least_one_of:
                      - query.0.scriptOptions.0.statementTimeoutMs
                      - query.0.scriptOptions.0.statementByteBudget
                      - query.0.scriptOptions.0.keyResultStatement
                    values:
                      - :LAST
                      - :FIRST_SELECT
          - !ruby/object:Api::Type::NestedObject
            name: 'load'
            description: 'Configures a load job.'
            exactly_one_of:
              - query
              - load
              - copy
              - extract
            properties:
              - !ruby/object:Api::Type::Array
                name: 'sourceUris'
                description: |
                  The fully-qualified URIs that point to your data in Google Cloud.
                  For Google Cloud Storage URIs: Each URI can contain one '*' wildcard character
                  and it must come after the 'bucket' name. Size limits related to load jobs apply
                  to external data sources. For Google Cloud Bigtable URIs: Exactly one URI can be
                  specified and it has be a fully specified and valid HTTPS URL for a Google Cloud Bigtable table.
                  For Google Cloud Datastore backups: Exactly one URI can be specified. Also, the '*' wildcard character is not allowed.
                item_type: Api::Type::String
                required: true
              - !ruby/object:Api::Type::NestedObject
                name: 'destinationTable'
                description: |
                  The destination table to load the data into.
                required: true
                properties:
                  - !ruby/object:Api::Type::String
                    name: 'projectId'
                    description: 'The ID of the project containing this table.'
                    required: true
                  - !ruby/object:Api::Type::String
                    name: 'datasetId'
                    description: 'The ID of the dataset containing this table.'
                    required: true
                  - !ruby/object:Api::Type::String
                    name: 'tableId'
                    description: 'The ID of the table.'
                    required: true
              - !ruby/object:Api::Type::Enum
                name: 'createDisposition'
                description: |
                  Specifies whether the job is allowed to create new tables. The following values are supported:
                  CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
                  CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
                  Creation, truncation and append actions occur as one atomic update upon job completion
                default_value: :CREATE_IF_NEEDED
                values:
                  - :CREATE_IF_NEEDED
                  - :CREATE_NEVER
              - !ruby/object:Api::Type::Enum
                name: 'writeDisposition'
                description: |
                  Specifies the action that occurs if the destination table already exists. The following values are supported:
                  WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
                  WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
                  WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
                  Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
                  Creation, truncation and append actions occur as one atomic update upon job completion.
                default_value: :WRITE_EMPTY
                values:
                  - :WRITE_TRUNCATE
                  - :WRITE_APPEND
                  - :WRITE_EMPTY
              - !ruby/object:Api::Type::String
                name: 'nullMarker'
                description: |
                  Specifies a string that represents a null value in a CSV file. For example, if you specify "\N", BigQuery interprets "\N" as a null value
                  when loading a CSV file. The default value is the empty string. If you set this property to a custom value, BigQuery throws an error if an
                  empty string is present for all data types except for STRING and BYTE. For STRING and BYTE columns, BigQuery interprets the empty string as
                  an empty value.
                default_value: ''
              - !ruby/object:Api::Type::String
                name: 'fieldDelimiter'
                description: |
                  The separator for fields in a CSV file. The separator can be any ISO-8859-1 single-byte character.
                  To use a character in the range 128-255, you must encode the character as UTF8. BigQuery converts
                  the string to ISO-8859-1 encoding, and then uses the first byte of the encoded string to split the
                  data in its raw, binary state. BigQuery also supports the escape sequence "\t" to specify a tab separator.
                  The default value is a comma (',').
              - !ruby/object:Api::Type::Integer
                name: 'skipLeadingRows'
                description: |
                  The number of rows at the top of a CSV file that BigQuery will skip when loading the data.
                  The default value is 0. This property is useful if you have header rows in the file that should be skipped.
                  When autodetect is on, the behavior is the following:
                  skipLeadingRows unspecified - Autodetect tries to detect headers in the first row. If they are not detected,
                  the row is read as data. Otherwise data is read starting from the second row.
                  skipLeadingRows is 0 - Instructs autodetect that there are no headers and data should be read starting from the first row.
                  skipLeadingRows = N > 0 - Autodetect skips N-1 rows and tries to detect headers in row N. If headers are not detected,
                  row N is just skipped. Otherwise row N is used to extract column names for the detected schema.
                default_value: 0
              - !ruby/object:Api::Type::String
                name: 'encoding'
                description: |
                  The character encoding of the data. The supported values are UTF-8 or ISO-8859-1.
                  The default value is UTF-8. BigQuery decodes the data after the raw, binary data
                  has been split using the values of the quote and fieldDelimiter properties.
                default_value: 'UTF-8'
              - !ruby/object:Api::Type::String
                name: 'quote'
                description: |
                  The value that is used to quote data sections in a CSV file. BigQuery converts the string to ISO-8859-1 encoding,
                  and then uses the first byte of the encoded string to split the data in its raw, binary state.
                  The default value is a double-quote ('"'). If your data does not contain quoted sections, set the property value to an empty string.
                  If your data contains quoted newline characters, you must also set the allowQuotedNewlines property to true.
              - !ruby/object:Api::Type::Integer
                name: 'maxBadRecords'
                description: |
                  The maximum number of bad records that BigQuery can ignore when running the job. If the number of bad records exceeds this value,
                  an invalid error is returned in the job result. The default value is 0, which requires that all records are valid.
                default_value: 0
              - !ruby/object:Api::Type::Boolean
                name: 'allowQuotedNewlines'
                description: |
                  Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file.
                  The default value is false.
                default_value: false
              - !ruby/object:Api::Type::String
                name: 'sourceFormat'
                description: |
                  The format of the data files. For CSV files, specify "CSV". For datastore backups, specify "DATASTORE_BACKUP".
                  For newline-delimited JSON, specify "NEWLINE_DELIMITED_JSON". For Avro, specify "AVRO". For parquet, specify "PARQUET".
                  For orc, specify "ORC". [Beta] For Bigtable, specify "BIGTABLE".
                  The default value is CSV.
                default_value: 'CSV'
              - !ruby/object:Api::Type::Boolean
                name: 'allowJaggedRows'
                description: |
                  Accept rows that are missing trailing optional columns. The missing values are treated as nulls.
                  If false, records with missing trailing columns are treated as bad records, and if there are too many bad records,
                  an invalid error is returned in the job result. The default value is false. Only applicable to CSV, ignored for other formats.
                default_value: false
              - !ruby/object:Api::Type::Boolean
                name: 'ignoreUnknownValues'
                description: |
                  Indicates if BigQuery should allow extra values that are not represented in the table schema.
                  If true, the extra values are ignored. If false, records with extra columns are treated as bad records,
                  and if there are too many bad records, an invalid error is returned in the job result.
                  The default value is false. The sourceFormat property determines what BigQuery treats as an extra value:
                  CSV: Trailing columns
                  JSON: Named values that don't match any column names
                default_value: false
              - !ruby/object:Api::Type::Array
                name: 'projectionFields'
                description: |
                  If sourceFormat is set to "DATASTORE_BACKUP", indicates which entity properties to load into BigQuery from a Cloud Datastore backup.
                  Property names are case sensitive and must be top-level properties. If no properties are specified, BigQuery loads all properties.
                  If any named property isn't found in the Cloud Datastore backup, an invalid error is returned in the job result.
                item_type: Api::Type::String
              - !ruby/object:Api::Type::Boolean
                name: 'autodetect'
                description: |
                  Indicates if we should automatically infer the options and schema for CSV and JSON sources.
              - !ruby/object:Api::Type::Array
                name: 'schemaUpdateOptions'
                description: |
                  Allows the schema of the destination table to be updated as a side effect of the load job if a schema is autodetected or
                  supplied in the job configuration. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND;
                  when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators.
                  For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified:
                  ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema.
                  ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable.
                item_type: Api::Type::String
              - !ruby/object:Api::Type::NestedObject
                name: 'timePartitioning'
                description: |
                  Time-based partitioning specification for the destination table.
                properties:
                  - !ruby/object:Api::Type::String
                    name: 'type'
                    description: |
                      The only type supported is DAY, which will generate one partition per day. Providing an empty string used to cause an error,
                      but in OnePlatform the field will be treated as unset.
                    required: true
                  - !ruby/object:Api::Type::String
                    name: 'expirationMs'
                    description: |
                      Number of milliseconds for which to keep the storage for a partition. A wrapper is used here because 0 is an invalid value.
                  - !ruby/object:Api::Type::String
                    name: 'field'
                    description: |
                      If not set, the table is partitioned by pseudo column '_PARTITIONTIME'; if set, the table is partitioned by this field.
                      The field must be a top-level TIMESTAMP or DATE field. Its mode must be NULLABLE or REQUIRED.
                      A wrapper is used here because an empty string is an invalid value.
              - !ruby/object:Api::Type::NestedObject
                name: 'destinationEncryptionConfiguration'
                description: |
                  Custom encryption configuration (e.g., Cloud KMS keys)
                properties:
                  - !ruby/object:Api::Type::String
                    name: 'kmsKeyName'
                    description: |
                      Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
                      The BigQuery Service Account associated with your project requires access to this encryption key.
                    required: true
          - !ruby/object:Api::Type::NestedObject
            name: 'copy'
            description: 'Copies a table.'
            exactly_one_of:
              - query
              - load
              - copy
              - extract
            properties:
              - !ruby/object:Api::Type::Array
                name: 'sourceTables'
                description: |
                  Source tables to copy.
                required: true
                item_type: !ruby/object:Api::Type::NestedObject
                  properties:
                    - !ruby/object:Api::Type::String
                      name: 'projectId'
                      description: 'The ID of the project containing this table.'
                      required: true
                    - !ruby/object:Api::Type::String
                      name: 'datasetId'
                      description: 'The ID of the dataset containing this table.'
                      required: true
                    - !ruby/object:Api::Type::String
                      name: 'tableId'
                      description: 'The ID of the table.'
                      required: true
              - !ruby/object:Api::Type::NestedObject
                name: 'destinationTable'
                description: 'The destination table.'
                properties:
                  - !ruby/object:Api::Type::String
                    name: 'projectId'
                    description: 'The ID of the project containing this table.'
                    required: true
                  - !ruby/object:Api::Type::String
                    name: 'datasetId'
                    description: 'The ID of the dataset containing this table.'
                    required: true
                  - !ruby/object:Api::Type::String
                    name: 'tableId'
                    description: 'The ID of the table.'
                    required: true
              - !ruby/object:Api::Type::Enum
                name: 'createDisposition'
                description: |
                  Specifies whether the job is allowed to create new tables. The following values are supported:
                  CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table.
                  CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result.
                  Creation, truncation and append actions occur as one atomic update upon job completion
                default_value: :CREATE_IF_NEEDED
                values:
                  - :CREATE_IF_NEEDED
                  - :CREATE_NEVER
              - !ruby/object:Api::Type::Enum
                name: 'writeDisposition'
                description: |
                  Specifies the action that occurs if the destination table already exists. The following values are supported:
                  WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result.
                  WRITE_APPEND: If the table already exists, BigQuery appends the data to the table.
                  WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result.
                  Each action is atomic and only occurs if BigQuery is able to complete the job successfully.
                  Creation, truncation and append actions occur as one atomic update upon job completion.
                default_value: :WRITE_EMPTY
                values:
                  - :WRITE_TRUNCATE
                  - :WRITE_APPEND
                  - :WRITE_EMPTY
              - !ruby/object:Api::Type::NestedObject
                name: 'destinationEncryptionConfiguration'
                description: |
                  Custom encryption configuration (e.g., Cloud KMS keys)
                properties:
                  - !ruby/object:Api::Type::String
                    name: 'kmsKeyName'
                    description: |
                      Describes the Cloud KMS encryption key that will be used to protect destination BigQuery table.
                      The BigQuery Service Account associated with your project requires access to this encryption key.
                    required: true
          - !ruby/object:Api::Type::NestedObject
            name: 'extract'
            description: 'Configures an extract job.'
            exactly_one_of:
              - query
              - load
              - copy
              - extract
            properties:
              - !ruby/object:Api::Type::Array
                name: 'destinationUris'
                description: |
                  A list of fully-qualified Google Cloud Storage URIs where the extracted table should be written.
                required: true
                item_type: Api::Type::String
              - !ruby/object:Api::Type::Boolean
                name: 'printHeader'
                description: |
                  Whether to print out a header row in the results. Default is true.
                default_value: true
              - !ruby/object:Api::Type::String
                name: 'fieldDelimiter'
                description: |
                  When extracting data in CSV format, this defines the delimiter to use between fields in the exported data.
                  Default is ','
              - !ruby/object:Api::Type::String
                name: 'destinationFormat'
                description: |
                  The exported file format. Possible values include CSV, NEWLINE_DELIMITED_JSON and AVRO for tables and SAVED_MODEL for models.
                  The default value for tables is CSV. Tables with nested or repeated fields cannot be exported as CSV.
                  The default value for models is SAVED_MODEL.
              - !ruby/object:Api::Type::String
                name: 'compression'
                description: |
                  The compression type to use for exported files. Possible values include GZIP, DEFLATE, SNAPPY, and NONE.
                  The default value is NONE. DEFLATE and SNAPPY are only supported for Avro.
                default_value: 'NONE'
              - !ruby/object:Api::Type::Boolean
                name: 'useAvroLogicalTypes'
                description: |
                  Whether to use logical types when extracting to AVRO format.
              - !ruby/object:Api::Type::NestedObject
                name: 'sourceTable'
                description: |
                  A reference to the table being exported.
                exactly_one_of:
                  - extract.0.source_table
                  - extract.0.source_model
                properties:
                  - !ruby/object:Api::Type::String
                    name: 'projectId'
                    description: 'The ID of the project containing this table.'
                    required: true
                  - !ruby/object:Api::Type::String
                    name: 'datasetId'
                    description: 'The ID of the dataset containing this table.'
                    required: true
                  - !ruby/object:Api::Type::String
                    name: 'tableId'
                    description: 'The ID of the table.'
                    required: true
              - !ruby/object:Api::Type::NestedObject
                name: 'sourceModel'
                description: |
                  A reference to the model being exported.
                exactly_one_of:
                  - extract.0.source_table
                  - extract.0.source_model
                properties:
                  - !ruby/object:Api::Type::String
                    name: 'projectId'
                    description: 'The ID of the project containing this model.'
                    required: true
                  - !ruby/object:Api::Type::String
                    name: 'datasetId'
                    description: 'The ID of the dataset containing this model.'
                    required: true
                  - !ruby/object:Api::Type::String
                    name: 'modelId'
                    description: 'The ID of the model.'
                    required: true
      - !ruby/object:Api::Type::NestedObject
        name: 'jobReference'
        description: |
          Reference describing the unique-per-user name of the job.
        properties:
          - !ruby/object:Api::Type::String
            name: 'projectId'
            description: |
              The project ID of the project containing this job.
            required: true
          - !ruby/object:Api::Type::String
            name: 'jobId'
            description: |
              The ID of the job. The ID must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), or dashes (-). The maximum length is 1,024 characters.
            required: true
          - !ruby/object:Api::Type::String
            name: 'location'
            description: |
              The geographic location of the job. The default value is US.
            default_value: 'US'
      - !ruby/object:Api::Type::NestedObject
        name: 'status'
        output: true
        description: |
          The status of this job. Examine this value when polling an asynchronous job to see if the job is complete.
        properties:
          - !ruby/object:Api::Type::NestedObject
            name: 'errorResult'
            output: true
            description: |
              Final error result of the job. If present, indicates that the job has completed and was unsuccessful.
            properties:
              - !ruby/object:Api::Type::String
                name: 'reason'
                description: A short error code that summarizes the error.
              - !ruby/object:Api::Type::String
                name: 'location'
                description: Specifies where the error occurred, if present.
              - !ruby/object:Api::Type::String
                name: 'message'
                description: A human-readable description of the error.
          - !ruby/object:Api::Type::Array
            name: 'errors'
            output: true
            description: |
              The first errors encountered during the running of the job. The final message
              includes the number of errors that caused the process to stop. Errors here do
              not necessarily mean that the job has not completed or was unsuccessful.
            item_type: !ruby/object:Api::Type::NestedObject
              properties:
                - !ruby/object:Api::Type::String
                  name: 'reason'
                  description: A short error code that summarizes the error.
                - !ruby/object:Api::Type::String
                  name: 'location'
                  description: Specifies where the error occurred, if present.
                - !ruby/object:Api::Type::String
                  name: 'message'
                  description: A human-readable description of the error.
          - !ruby/object:Api::Type::String
            name: 'state'
            output: true
            description: |
              Running state of the job. Valid states include 'PENDING', 'RUNNING', and 'DONE'.
  - !ruby/object:Api::Resource
    name: 'Table'
    kind: 'bigquery#table'
    base_url: projects/{{project}}/datasets/{{dataset}}/tables
    description: |
      A Table that belongs to a Dataset
    parameters:
      # TODO(alexstephen): Remove once we have support for placing
      # nested object fields in URL
      - !ruby/object:Api::Type::String
        name: 'dataset'
        description: Name of the dataset
    properties:
      - !ruby/object:Api::Type::NestedObject
        name: tableReference
        description: Reference describing the ID of this table
        properties:
          - !ruby/object:Api::Type::String
            name: 'datasetId'
            description: The ID of the dataset containing this table
          - !ruby/object:Api::Type::String
            name: 'projectId'
            description: The ID of the project containing this table
          - !ruby/object:Api::Type::String
            name: 'tableId'
            description: The ID of the the table
      - !ruby/object:Api::Type::Array
            name: 'clustering'
            description: |
              One or more fields on which data should be clustered. Only
              top-level, non-repeated, simple-type fields are supported. When
              you cluster a table using multiple columns, the order of columns
              you specify is important. The order of the specified columns
              determines the sort order of the data.
            item_type: Api::Type::String
      - !ruby/object:Api::Type::Integer
        name: 'creationTime'
        output: true
        description: |
          The time when this dataset was created, in milliseconds since the
          epoch.
      - !ruby/object:Api::Type::String
        name: 'description'
        description: A user-friendly description of the dataset
      - !ruby/object:Api::Type::String
        name: 'friendlyName'
        description: A descriptive name for this table
      - !ruby/object:Api::Type::String
        name: 'id'
        description: 'An opaque ID uniquely identifying the table.'
        output: true
      - !ruby/object:Api::Type::KeyValuePairs
        name: 'labels'
        description: |
          The labels associated with this dataset. You can use these to
          organize and group your datasets
      - !ruby/object:Api::Type::Integer
        name: 'lastModifiedTime'
        description: |
          The time when this table was last modified, in milliseconds since the
          epoch.
        output: true
      - !ruby/object:Api::Type::String
        name: 'location'
        description: |
          The geographic location where the table resides. This value is
          inherited from the dataset.
        output: true
      - !ruby/object:Api::Type::String
        name: 'name'
        description: 'Name of the table'
      - !ruby/object:Api::Type::Integer
        name: 'numBytes'
        description: |
          The size of this table in bytes, excluding any data in the streaming
          buffer.
        output: true
      - !ruby/object:Api::Type::Integer
        name: 'numLongTermBytes'
        description: |
          The number of bytes in the table that are considered "long-term
          storage".
        output: true
      - !ruby/object:Api::Type::Integer
        name: 'numRows'
        description: |
          The number of rows of data in this table, excluding any data in the
          streaming buffer.
      - !ruby/object:Api::Type::Boolean
        name: 'requirePartitionFilter'
        description: |
          If set to true, queries over this table require a partition filter
          that can be used for partition elimination to be specified.
        output: true
      - !ruby/object:Api::Type::Enum
        name: 'type'
        description: 'Describes the table type'
        values:
          - :TABLE
          - :VIEW
          - :EXTERNAL
        output: true
      - !ruby/object:Api::Type::NestedObject
        name: 'view'
        description: The view definition.
        properties:
          - !ruby/object:Api::Type::Boolean
            name: 'useLegacySql'
            description: |
              Specifies whether to use BigQuery's legacy SQL for this view
          - !ruby/object:Api::Type::Array
            name: 'userDefinedFunctionResources'
            description: |
              Describes user-defined function resources used in the query.
            item_type: !ruby/object:Api::Type::NestedObject
              properties:
                - !ruby/object:Api::Type::String
                  name: 'inlineCode'
                  description: |
                    An inline resource that contains code for a user-defined
                    function (UDF). Providing a inline code resource is
                    equivalent to providing a URI for a file containing the
                    same code.
                # TODO: Convert into cross-product ResourceRef
                - !ruby/object:Api::Type::String
                  name: 'resourceUri'
                  description: |
                    A code resource to load from a Google Cloud Storage URI
                    (gs://bucket/path).
      - !ruby/object:Api::Type::NestedObject
        name: 'timePartitioning'
        description: |
          If specified, configures time-based partitioning for this table.
        properties:
          - !ruby/object:Api::Type::Integer
            name: 'expirationMs'
            description: |
              Number of milliseconds for which to keep the storage for a
              partition.
          - !ruby/object:Api::Type::String
            name: 'field'
            description: |
              If not set, the table is partitioned by pseudo column,
              referenced via either '_PARTITIONTIME' as TIMESTAMP type, or
              '_PARTITIONDATE' as DATE type. If field is specified, the table
              is instead partitioned by this field. The field must be a
              top-level TIMESTAMP or DATE field. Its mode must be NULLABLE or
              REQUIRED.
          - !ruby/object:Api::Type::Enum
            name: 'type'
            description: |
              The only type supported is DAY, which will generate one partition
              per day.
            values:
              - :DAY
      - !ruby/object:Api::Type::NestedObject
        name: 'streamingBuffer'
        description: |
          Contains information regarding this table's streaming buffer, if one
          is present. This field will be absent if the table is not being
          streamed to or if there is no data in the streaming buffer.
        output: true
        properties:
          - !ruby/object:Api::Type::Integer
            name: 'estimatedBytes'
            description: |
              A lower-bound estimate of the number of bytes currently in the
              streaming buffer.
            output: true
          - !ruby/object:Api::Type::Integer
            name: 'estimatedRows'
            description: |
              A lower-bound estimate of the number of rows currently in the
              streaming buffer.
            output: true
          - !ruby/object:Api::Type::Integer
            name: 'oldestEntryTime'
            description: |
              Contains the timestamp of the oldest entry in the streaming
              buffer, in milliseconds since the epoch, if the streaming buffer
              is available.
            output: true
      - !ruby/object:Api::Type::NestedObject
        name: 'schema'
        description: Describes the schema of this table
        properties:
          - !ruby/object:Api::Type::Array
            name: 'fields'
            description: Describes the fields in a table.
            item_type: !ruby/object:Api::Type::NestedObject
              properties:
                - !ruby/object:Api::Type::String
                  name: 'description'
                  description: |
                    The field description. The maximum length is 1,024
                    characters.
                - !ruby/object:Api::Type::Array
                  name: 'fields'
                  description: |
                    Describes the nested schema fields if the type property is
                    set to RECORD.
                  item_type: Api::Type::String
                - !ruby/object:Api::Type::Enum
                  name: 'mode'
                  description: The field mode
                  values:
                    - :NULLABLE
                    - :REQUIRED
                    - :REPEATED
                - !ruby/object:Api::Type::String
                  name: 'name'
                  description: The field name
                - !ruby/object:Api::Type::Enum
                  name: 'type'
                  description: 'The field data type'
                  values:
                    - :STRING
                    - :BYTES
                    - :INTEGER
                    - :FLOAT
                    - :TIMESTAMP
                    - :DATE
                    - :TIME
                    - :DATETIME
                    - :RECORD
      - !ruby/object:Api::Type::NestedObject
        name: 'encryptionConfiguration'
        description: Custom encryption configuration
        properties:
          - !ruby/object:Api::Type::String
            name: 'kmsKeyName'
            description: |
              Describes the Cloud KMS encryption key that will be used to
              protect destination BigQuery table. The BigQuery Service Account
              associated with your project requires access to this encryption
              key.
      - !ruby/object:Api::Type::Integer
        name: 'expirationTime'
        description: |
          The time when this table expires, in milliseconds since the epoch. If
          not present, the table will persist indefinitely.
      - !ruby/object:Api::Type::NestedObject
        name: 'externalDataConfiguration'
        description: |
          Describes the data format, location, and other properties of a table
          stored outside of BigQuery. By defining these properties, the data
          source can then be queried as if it were a standard BigQuery table.
        properties:
          - !ruby/object:Api::Type::Boolean
            name: 'autodetect'
            description: |
              Try to detect schema and format options automatically. Any option
              specified explicitly will be honored.
          - !ruby/object:Api::Type::Enum
            name: 'compression'
            description: The compression type of the data source
            values:
              - :GZIP
              - :NONE
          - !ruby/object:Api::Type::Boolean
            name: 'ignoreUnknownValues'
            description: |
              Indicates if BigQuery should allow extra values that are not
              represented in the table schema
          - !ruby/object:Api::Type::Integer
            name: 'maxBadRecords'
            description: |
              The maximum number of bad records that BigQuery can ignore when reading data
            default_value: 0
          - !ruby/object:Api::Type::Enum
            name: 'sourceFormat'
            description: The data format
            values:
              - :CSV
              - :GOOGLE_SHEETS
              - :NEWLINE_DELIMITED_JSON
              - :AVRO
              - :DATASTORE_BACKUP
              - :BIGTABLE
              - :ORC
          # TODO: Investigate if this is feasible as a ResourceRef
          # This is a very complicated ResourceRef (one-to-many, where the many are cross-product).
          - !ruby/object:Api::Type::Array
            name: 'sourceUris'
            description: |
              The fully-qualified URIs that point to your data in Google Cloud.
              For Google Cloud Storage URIs: Each URI can contain one '*'
              wildcard character and it must come after the 'bucket' name. Size
              limits related to load jobs apply to external data sources. For
              Google Cloud Bigtable URIs: Exactly one URI can be specified and it
              has be a fully specified and valid HTTPS URL for a Google Cloud
              Bigtable table. For Google Cloud Datastore backups, exactly one
              URI can be specified. Also, the '*' wildcard character is not
              allowed.
            item_type: Api::Type::String
          - !ruby/object:Api::Type::NestedObject
            name: 'schema'
            description: 'The schema for the data. Schema is required for CSV and JSON formats'
            properties:
              - !ruby/object:Api::Type::Array
                name: 'fields'
                description: 'Describes the fields in a table.'
                item_type: !ruby/object:Api::Type::NestedObject
                  properties:
                    - !ruby/object:Api::Type::String
                      name: 'description'
                      description: The field description
                    - !ruby/object:Api::Type::Array
                      name: 'fields'
                      description: |
                        Describes the nested schema fields if the type property
                        is set to RECORD
                      item_type: Api::Type::String
                    - !ruby/object:Api::Type::Enum
                      name: 'mode'
                      description: Field mode.
                      values:
                        - :NULLABLE
                        - :REQUIRED
                        - :REPEATED
                    - !ruby/object:Api::Type::String
                      name: 'name'
                      description: Field name
                    - !ruby/object:Api::Type::Enum
                      name: 'type'
                      description: Field data type
                      values:
                        - :STRING
                        - :BYTES
                        - :INTEGER
                        - :FLOAT
                        - :TIMESTAMP
                        - :DATE
                        - :TIME
                        - :DATETIME
                        - :RECORD
          - !ruby/object:Api::Type::NestedObject
            name: 'googleSheetsOptions'
            description: 'Additional options if sourceFormat is set to GOOGLE_SHEETS.'
            properties:
              - !ruby/object:Api::Type::Integer
                name: 'skipLeadingRows'
                description: |
                  The number of rows at the top of a Google Sheet that BigQuery
                  will skip when reading the data.
                default_value: 0
          - !ruby/object:Api::Type::NestedObject
            name: 'csvOptions'
            description: Additional properties to set if sourceFormat is set to CSV.
            properties:
              - !ruby/object:Api::Type::Boolean
                name: 'allowJaggedRows'
                description: |
                  Indicates if BigQuery should accept rows that are missing
                  trailing optional columns
              - !ruby/object:Api::Type::Boolean
                name: 'allowQuotedNewlines'
                description: |
                  Indicates if BigQuery should allow quoted data sections that
                  contain newline characters in a CSV file
              - !ruby/object:Api::Type::Enum
                name: 'encoding'
                description: 'The character encoding of the data'
                values:
                  - :UTF-8
                  - :ISO-8859-1
              - !ruby/object:Api::Type::String
                name: 'fieldDelimiter'
                description: 'The separator for fields in a CSV file'
              - !ruby/object:Api::Type::String
                name: 'quote'
                description: 'The value that is used to quote data sections in a CSV file'
              - !ruby/object:Api::Type::Integer
                name: 'skipLeadingRows'
                description: |
                  The number of rows at the top of a CSV file that BigQuery
                  will skip when reading the data.
                default_value: 0
          - !ruby/object:Api::Type::NestedObject
            name: 'bigtableOptions'
            description: 'Additional options if sourceFormat is set to BIGTABLE.'
            properties:
              - !ruby/object:Api::Type::Boolean
                name: 'ignoreUnspecifiedColumnFamilies'
                description: |
                  If field is true, then the column families that are not specified in
                  columnFamilies list are not exposed in the table schema
              - !ruby/object:Api::Type::Boolean
                name: 'readRowkeyAsString'
                description: |
                  If field is true, then the rowkey column families will be
                  read and converted to string.
              - !ruby/object:Api::Type::Array
                name: 'columnFamilies'
                description: |
                  List of column families to expose in the table schema along
                  with their types.
                item_type: !ruby/object:Api::Type::NestedObject
                  properties:
                    - !ruby/object:Api::Type::Array
                      name: 'columns'
                      description: |
                         Lists of columns that should be exposed as individual
                         fields as opposed to a list of (column name, value) pairs.
                      item_type: !ruby/object:Api::Type::NestedObject
                        properties:
                          - !ruby/object:Api::Type::Enum
                            name: 'encoding'
                            description: The encoding of the values when the type is not STRING
                            values:
                              - :TEXT
                              - :BINARY
                          - !ruby/object:Api::Type::String
                             name: 'fieldName'
                             description: |
                               If the qualifier is not a valid BigQuery field
                               identifier, a valid identifier must be provided as
                               the column field name and is used as field name in
                               queries.
                          - !ruby/object:Api::Type::Boolean
                             name: 'onlyReadLatest'
                             description: |
                               If this is set, only the latest version of value in this column are exposed
                          - !ruby/object:Api::Type::String
                             name: 'qualifierString'
                             description: Qualifier of the column
                             required: true
                          - !ruby/object:Api::Type::Enum
                             name: 'type'
                             description: The type to convert the value in cells of this column
                             values:
                               - :BYTES
                               - :STRING
                               - :INTEGER
                               - :FLOAT
                               - :BOOLEAN
                    - !ruby/object:Api::Type::Enum
                      name: 'encoding'
                      description: The encoding of the values when the type is not STRING
                      values:
                        - :TEXT
                        - :BINARY
                    - !ruby/object:Api::Type::String
                      name: 'familyId'
                      description: Identifier of the column family.
                    - !ruby/object:Api::Type::Boolean
                      name: 'onlyReadLatest'
                      description: |
                        If this is set only the latest version of value are
                        exposed for all columns in this column family
                    - !ruby/object:Api::Type::Enum
                      name: 'type'
                      description: The type to convert the value in cells of this column family
                      values:
                        - :BYTES
                        - :STRING
                        - :INTEGER
                        - :FLOAT
                        - :BOOLEAN
  - !ruby/object:Api::Resource
    name: 'Routine'
    kind: 'bigquery#routine'
    base_url: projects/{{project}}/datasets/{{dataset_id}}/routines
    self_link: projects/{{project}}/datasets/{{dataset_id}}/routines/{{routine_id}}
    description: |
      A user-defined function or a stored procedure that belongs to a Dataset
    references: !ruby/object:Api::Resource::ReferenceLinks
      guides:
        'Routines Intro': 'https://cloud.google.com/bigquery/docs/reference/rest/v2/routines'
      api: 'https://cloud.google.com/bigquery/docs/reference/rest/v2/routines'
    properties:
      - !ruby/object:Api::Type::NestedObject
        name: routineReference
        description: Reference describing the ID of this routine
        required: true
        properties:
          - !ruby/object:Api::Type::String
            name: 'datasetId'
            description: The ID of the dataset containing this routine
            required: true
          - !ruby/object:Api::Type::String
            name: 'projectId'
            description: The ID of the project containing this routine
            required: true
          - !ruby/object:Api::Type::String
            name: 'routineId'
            description: The ID of the the routine. The ID must contain only
              letters (a-z, A-Z), numbers (0-9), or underscores (_).
              The maximum length is 256 characters.
            required: true
      - !ruby/object:Api::Type::Enum
        name: 'routineType'
        input: true
        description: The type of routine.
        values:
          - :SCALAR_FUNCTION
          - :PROCEDURE
      - !ruby/object:Api::Type::Integer
        name: 'creationTime'
        output: true
        description: |
          The time when this routine was created, in milliseconds since the
          epoch.
      - !ruby/object:Api::Type::Integer
        name: 'lastModifiedTime'
        output: true
        description: |
          The time when this routine was modified, in milliseconds since the
          epoch.
      - !ruby/object:Api::Type::Enum
        name: 'language'
        description: |
          The language of the routine.
        values:
          - :SQL
          - :JAVASCRIPT
      - !ruby/object:Api::Type::Array
        name: 'arguments'
        description: Input/output argument of a function or a stored procedure.
        item_type: !ruby/object:Api::Type::NestedObject
          properties:
            - !ruby/object:Api::Type::String
              name: 'name'
              description: |
                The name of this argument. Can be absent for function return argument.
            - !ruby/object:Api::Type::Enum
              name: 'argumentKind'
              description: Defaults to FIXED_TYPE.
              values:
                - :FIXED_TYPE
                - :ANY_TYPE
              default_value: :FIXED_TYPE
            - !ruby/object:Api::Type::Enum
              name: 'mode'
              description: |
                Specifies whether the argument is input or output. Can be set for procedures only.
              values:
                - :IN
                - :OUT
                - :INOUT
            - !ruby/object:Api::Type::String
              # This is a string instead of a NestedObject because schemas contain ColumnSchemas,
              # which can contain nested StandardSqlDataType.
              # We'll have people provide the json blob for the schema instead.
              name: 'dataType'
              description: |
                A JSON schema for the data type. Required unless argumentKind = ANY_TYPE.
                ~>**NOTE**: Because this field expects a JSON string, any changes to the string
                will create a diff, even if the JSON itself hasn't changed. If the API returns
                a different value for the same schema, e.g. it switched the order of values
                or replaced STRUCT field type with RECORD field type, we currently cannot
                suppress the recurring diff this causes. As a workaround, we recommend using
                the schema as returned by the API.
      - !ruby/object:Api::Type::String
        name: 'returnType'
        description: |
          A JSON schema for the return type. Optional if language = "SQL"; required otherwise.
          If absent, the return type is inferred from definitionBody at query time in each query
          that references this routine. If present, then the evaluated result will be cast to
          the specified returned type at query time. ~>**NOTE**: Because this field expects a JSON
          string, any changes to the string will create a diff, even if the JSON itself hasn't
          changed. If the API returns a different value for the same schema, e.g. it switche
          d the order of values or replaced STRUCT field type with RECORD field type, we currently
          cannot suppress the recurring diff this causes. As a workaround, we recommend using
          the schema as returned by the API.
      - !ruby/object:Api::Type::Array
        name: 'importedLibraries'
        description: |
          Optional. If language = "JAVASCRIPT", this field stores the path of the
          imported JAVASCRIPT libraries.
        item_type: Api::Type::String
      - !ruby/object:Api::Type::String
        name: 'definitionBody'
        required: true
        description: |
          The body of the routine. For functions, this is the expression in the AS clause.
          If language=SQL, it is the substring inside (but excluding) the parentheses.
      - !ruby/object:Api::Type::String
        name: 'description'
        description: The description of the routine if defined.
      - !ruby/object:Api::Type::Enum
        name: 'determinismLevel'
        description: The determinism level of the JavaScript UDF if defined.
        values:
          - :DETERMINISM_LEVEL_UNSPECIFIED
          - :DETERMINISTIC
          - :NOT_DETERMINISTIC
      - !ruby/object:Api::Type::String
        name: 'id'
        output: true
        description: |
          The fully-qualified unique name of the routine in the format
          projectId:datasetId:routineId. The routine name without the project name is
          given in the routineId field
