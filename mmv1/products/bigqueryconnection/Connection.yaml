# Copyright 2023 Google Inc.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

--- !ruby/object:Api::Resource
name: 'Connection'
base_url: projects/{{project}}/locations/{{location}}/connections
self_link: projects/{{project}}/locations/{{location}}/connections/{{connection_id}}
create_url: projects/{{project}}/locations/{{location}}/connections?connectionId={{connection_id}}
update_verb: :PATCH
update_mask: true
description: |
  A connection allows BigQuery connections to external data sources..
references: !ruby/object:Api::Resource::ReferenceLinks
  guides:
    'Cloud SQL federated queries': 'https://cloud.google.com/bigquery/docs/cloud-sql-federated-queries'
  api: 'https://cloud.google.com/bigquery/docs/reference/bigqueryconnection/rest/v1/projects.locations.connections/create'
iam_policy: !ruby/object:Api::Resource::IamPolicy
  method_name_separator: ':'
  fetch_iam_policy_verb: :POST
  parent_resource_attribute: 'connection_id'
  import_format:
    [
      'projects/{{project}}/locations/{{location}}/connections/{{connection_id}}',
      '{{connection_id}}',
    ]
id_format: 'projects/{{project}}/locations/{{location}}/connections/{{connection_id}}'
import_format:
  [
    'projects/{{project}}/locations/{{location}}/connections/{{connection_id}}',
    '{{project}}/{{location}}/{{connection_id}}',
    '{{location}}/{{connection_id}}',
  ]
custom_code: !ruby/object:Provider::Terraform::CustomCode
  post_create: templates/terraform/post_create/bigquery_connection_id.go.erb
  encoder: templates/terraform/encoders/bigquery_connection.go.erb
examples:
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_connection_cloud_resource'
    external_providers: ["random", "time"]
    region_override: 'US'
    primary_resource_id: 'connection'
    primary_resource_name: "fmt.Sprintf(\"tf-test-my-connection%s\",
      context[\"random_suffix\"\
      ])"
    vars:
      connection_id: 'my-connection'
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_connection_basic'
    external_providers: ["random", "time"]
    primary_resource_id:
      'connection'
      # Random provider
    skip_vcr: true
    vars:
      database_instance_name: 'my-database-instance'
      username: 'user'
      deletion_protection: 'true'
    test_vars_overrides:
      deletion_protection: 'false'
    oics_vars_overrides:
      deletion_protection: 'false'
    ignore_read_extra:
      - 'cloud_sql.0.credential'  # password removed
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_connection_full'
    external_providers: ["random", "time"]
    primary_resource_id:
      'connection'
      # Random provider
    skip_vcr: true
    vars:
      database_instance_name: 'my-database-instance'
      username: 'user'
      connection_id: 'my-connection'
      deletion_protection: 'true'
    test_vars_overrides:
      deletion_protection: 'false'
    oics_vars_overrides:
      deletion_protection: 'false'
    ignore_read_extra:
      - 'cloud_sql.0.credential'  # password removed
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_connection_aws'
    external_providers: ["random", "time"]
    primary_resource_id: 'connection'
    vars:
      connection_id: 'my-connection'
      iam_role_id: 'arn:aws:iam::999999999999:role/omnirole'
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_connection_azure'
    external_providers: ["random", "time"]
    primary_resource_id: 'connection'
    vars:
      connection_id: 'my-connection'
      customer_tenant_id: 'customer-tenant-id'
      federated_application_client_id: 'b43eeeee-eeee-eeee-eeee-a480155501ce'
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_connection_cloudspanner'
    external_providers: ["random", "time"]
    primary_resource_id: 'connection'
    vars:
      connection_id: 'my-connection'
      database: 'projects/project/instances/instance/databases/database'
      database_role: 'database_role'
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_connection_cloudspanner_databoost'
    external_providers: ["random", "time"]
    primary_resource_id: 'connection'
    vars:
      connection_id: 'my-connection'
      database: 'projects/project/instances/instance/databases/database'
  - !ruby/object:Provider::Terraform::Examples
    name: "bigquery_connection_spark"
    region_override: "US"
    primary_resource_id: "connection"
    vars:
      connection_id: "my-connection"
  - !ruby/object:Provider::Terraform::Examples
    name: 'bigquery_connection_kms'
    primary_resource_id:
      'bq-connection-cmek'
    vars:
      database_instance_name: 'my-database-instance'
      username: 'user'
      deletion_protection: 'true'
      kms_key_name: 'projects/project/locations/us-central1/keyRings/us-central1/cryptoKeys/bq-key'
    test_vars_overrides:
      deletion_protection: 'false'
      kms_key_name: 'acctest.BootstrapKMSKey(t).CryptoKey.Name'
      policyChanged:
        "acctest.BootstrapPSARole(t, \"bq-\", \"bigquery-encryption\",
        \"roles/cloudkms.cryptoKeyEncrypterDecrypter\"\
        )"
    oics_vars_overrides:
      deletion_protection: 'false'
    ignore_read_extra:
      - 'cloud_sql.0.credential'  # password removed
properties:
  - !ruby/object:Api::Type::String
    name: name
    description: |-
      The resource name of the connection in the form of:
      "projects/{project_id}/locations/{location_id}/connections/{connectionId}"
    output: true
  - !ruby/object:Api::Type::String
    name: connection_id
    description: |
      Optional connection id that should be assigned to the created connection.
    required: false
    immutable: true
    default_from_api: true
    custom_flatten: 'templates/terraform/custom_flatten/id_from_name.erb'
  - !ruby/object:Api::Type::String
    name: 'location'
    required: false
    immutable: true
    url_param_only: true
    description: |-
      The geographic location where the connection should reside.
      Cloud SQL instance must be in the same location as the connection
      with following exceptions: Cloud SQL us-central1 maps to BigQuery US, Cloud SQL europe-west1 maps to BigQuery EU.
      Examples: US, EU, asia-northeast1, us-central1, europe-west1.
      Spanner Connections same as spanner region
      AWS allowed regions are aws-us-east-1
      Azure allowed regions are azure-eastus2
  - !ruby/object:Api::Type::String
    name: 'friendlyName'
    description: A descriptive name for the connection
  - !ruby/object:Api::Type::String
    name: 'description'
    description: A descriptive description for the connection
  - !ruby/object:Api::Type::Boolean
    name: 'hasCredential'
    output: true
    description: |
      True if the connection has credential assigned.
  - !ruby/object:Api::Type::String
    name: 'kmsKeyName'
    description: |
      Optional. The Cloud KMS key that is used for encryption.

      Example: projects/[kms_project_id]/locations/[region]/keyRings/[key_region]/cryptoKeys/[key]
  - !ruby/object:Api::Type::NestedObject
    name: 'cloudSql'
    description: Connection properties specific to the Cloud SQL.
    exactly_one_of:
      - cloud_sql
      - aws
      - azure
      - cloud_spanner
      - cloud_resource
      - spark
    properties:
      - !ruby/object:Api::Type::String
        name: 'instanceId'
        description:
          Cloud SQL instance ID in the form project:location:instance.
        required: true
      - !ruby/object:Api::Type::String
        name: 'database'
        description: Database name.
        required: true
      - !ruby/object:Api::Type::NestedObject
        name: credential
        description: Cloud SQL properties.
        required: true
        custom_flatten: 'templates/terraform/custom_flatten/bigquery_connection_flatten.go.erb'
        properties:
          - !ruby/object:Api::Type::String
            name: username
            description: Username for database.
            required: true
          - !ruby/object:Api::Type::String
            name: password
            description: Password for database.
            required: true
            sensitive: true
      - !ruby/object:Api::Type::Enum
        name: 'type'
        description: Type of the Cloud SQL database.
        required: true
        values:
          - :DATABASE_TYPE_UNSPECIFIED
          - :POSTGRES
          - :MYSQL
      - !ruby/object:Api::Type::String
        name: 'serviceAccountId'
        description:
          When the connection is used in the context of an operation in
          BigQuery, this service account will serve as the identity being used
          for connecting to the CloudSQL instance specified in this connection.
        output: true
  - !ruby/object:Api::Type::NestedObject
    name: aws
    description: Connection properties specific to Amazon Web Services.
    exactly_one_of:
      - cloud_sql
      - aws
      - azure
      - cloud_spanner
      - cloud_resource
      - spark
    update_mask_fields:
      - 'aws.access_role.iam_role_id'
    properties:
      - !ruby/object:Api::Type::NestedObject
        name: accessRole
        description:
          Authentication using Google owned service account to assume into
          customer's AWS IAM Role.
        required: true
        properties:
          - !ruby/object:Api::Type::String
            name: iamRoleId
            description:
              The userâ€™s AWS IAM Role that trusts the Google-owned AWS IAM user
              Connection.
            required: true
          - !ruby/object:Api::Type::String
            name: identity
            description:
              A unique Google-owned and Google-generated identity for the
              Connection. This identity will be used to access the user's AWS
              IAM Role.
            output: true
  - !ruby/object:Api::Type::NestedObject
    name: azure
    description: Container for connection properties specific to Azure.
    exactly_one_of:
      - cloud_sql
      - aws
      - azure
      - cloud_spanner
      - cloud_resource
      - spark
    update_mask_fields:
      - 'azure.customer_tenant_id'
      - 'azure.federated_application_client_id'
    properties:
      - !ruby/object:Api::Type::String
        name: 'application'
        description: The name of the Azure Active Directory Application.
        output: true
      - !ruby/object:Api::Type::String
        name: 'clientId'
        output: true
        description: The client id of the Azure Active Directory Application.
      - !ruby/object:Api::Type::String
        name: 'objectId'
        output: true
        description: The object id of the Azure Active Directory Application.
      - !ruby/object:Api::Type::String
        name: 'customerTenantId'
        description: The id of customer's directory that host the data.
        required: true
      - !ruby/object:Api::Type::String
        name: 'federatedApplicationClientId'
        description:
          The Azure Application (client) ID where the federated credentials will
          be hosted.
      - !ruby/object:Api::Type::String
        name: 'redirectUri'
        output: true
        description:
          The URL user will be redirected to after granting consent during
          connection setup.
      - !ruby/object:Api::Type::String
        name: 'identity'
        description:
          A unique Google-owned and Google-generated identity for the
          Connection. This identity will be used to access the user's Azure
          Active Directory Application.
        output: true
  - !ruby/object:Api::Type::NestedObject
    name: cloudSpanner
    description: Connection properties specific to Cloud Spanner
    exactly_one_of:
      - cloud_sql
      - aws
      - azure
      - cloud_spanner
      - cloud_resource
      - spark
    properties:
      - !ruby/object:Api::Type::String
        name: 'database'
        description:
          Cloud Spanner database in the form `project/instance/database'.
        required: true
      - !ruby/object:Api::Type::Boolean
        name: 'useParallelism'
        description:
          If parallelism should be used when reading from Cloud Spanner.
      - !ruby/object:Api::Type::Integer
        name: 'maxParallelism'
        description:
          Allows setting max parallelism per query when executing on Spanner independent compute
          resources. If unspecified, default values of parallelism are chosen that are dependent on
          the Cloud Spanner instance configuration. `useParallelism` and `useDataBoost` must be set
          when setting max parallelism.
        required_with:
          - cloudSpanner.0.useDataBoost
          - cloudSpanner.0.useParallelism
      - !ruby/object:Api::Type::Boolean
        name: 'useDataBoost'
        description:
          If set, the request will be executed via Spanner independent compute resources.
          `use_parallelism` must be set when using data boost.
        required_with:
          - cloudSpanner.0.useParallelism
      - !ruby/object:Api::Type::String
        name: 'databaseRole'
        description:
          Cloud Spanner database role for fine-grained access control. The Cloud Spanner admin
          should have provisioned the database role with appropriate permissions, such as `SELECT`
          and `INSERT`. Other users should only use roles provided by their Cloud Spanner admins.
          The database role name must start with a letter, and can only contain letters, numbers,
          and underscores. For more details, see https://cloud.google.com/spanner/docs/fgac-about.
        validation: !ruby/object:Provider::Terraform::Validation
          regex: '^[a-zA-Z][a-zA-Z0-9_]*$'
      - !ruby/object:Api::Type::Boolean
        name: 'useServerlessAnalytics'
        description:
          If the serverless analytics service should be used to read data from
          Cloud Spanner. `useParallelism` must be set when using serverless
          analytics.
        deprecation_message: >-
          `useServerlessAnalytics` is deprecated and will be removed in a future major release. Use
          `useDataBoost` instead.
  - !ruby/object:Api::Type::NestedObject
    name: cloudResource
    description:
      Container for connection properties for delegation of access to GCP
      resources.
    exactly_one_of:
      - cloud_sql
      - aws
      - azure
      - cloud_spanner
      - cloud_resource
      - spark
    send_empty_value: true
    properties:
      - !ruby/object:Api::Type::String
        name: 'serviceAccountId'
        description:
          The account ID of the service created for the purpose of this
          connection.
        output: true
  - !ruby/object:Api::Type::NestedObject
    name: spark
    description: Container for connection properties to execute stored procedures for Apache Spark.
      resources.
    exactly_one_of:
      - cloud_sql
      - aws
      - azure
      - cloud_spanner
      - cloud_resource
      - spark
    send_empty_value: true
    properties:
      - !ruby/object:Api::Type::String
        name: 'serviceAccountId'
        description: The account ID of the service created for the purpose of this
          connection.
        output: true
      - !ruby/object:Api::Type::NestedObject
        name: metastoreServiceConfig
        description: Dataproc Metastore Service configuration for the connection.
        properties:
          - !ruby/object:Api::Type::String
            name: metastoreService
            description: Resource name of an existing Dataproc Metastore service in the form of projects/[projectId]/locations/[region]/services/[serviceId].
      - !ruby/object:Api::Type::NestedObject
        name: sparkHistoryServerConfig
        description: Spark History Server configuration for the connection.
        properties:
          - !ruby/object:Api::Type::String
            name: dataprocCluster
            description: Resource name of an existing Dataproc Cluster to act as a Spark History Server for the connection if the form of projects/[projectId]/regions/[region]/clusters/[cluster_name].
