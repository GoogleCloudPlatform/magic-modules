# Copyright 2019 Google Inc.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

--- !ruby/object:Api::Product
name: VertexAI
display_name: Vertex AI
versions:
  - !ruby/object:Api::Product::Version
    name: ga
    base_url: https://{{region}}-aiplatform.googleapis.com/v1/
  - !ruby/object:Api::Product::Version
    name: beta
    base_url: https://{{region}}-aiplatform.googleapis.com/v1beta1/
scopes:
  - https://www.googleapis.com/auth/cloud-platform
objects:
# Vertex AI Datasets
  - !ruby/object:Api::Resource
    name: Dataset
    base_url: projects/{{project}}/locations/{{region}}/datasets
    self_link: '{{name}}'
    update_verb: :PATCH
    update_mask: true
    references: !ruby/object:Api::Resource::ReferenceLinks
      guides:
        'Official Documentation':
          'https://cloud.google.com/vertex-ai/docs'
      api: 'https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.datasets'
    async: !ruby/object:Api::OpAsync
      actions:
        - create
        - delete
      operation: !ruby/object:Api::OpAsync::Operation
        path: 'name'
        base_url: '{{op_id}}'
        wait_ms: 1000
      result: !ruby/object:Api::OpAsync::Result
        path: 'response'
        resource_inside_response: true
      status: !ruby/object:Api::OpAsync::Status
        path: 'done'
        complete: True
        allowed:
          - True
          - False
      error: !ruby/object:Api::OpAsync::Error
        path: 'error'
        message: 'message'
    description: |-
      A collection of DataItems and Annotations on them.
    parameters:
      - !ruby/object:Api::Type::String
        name: region
        description: The region of the dataset. eg us-central1
        url_param_only: true
        input: true
    properties:
      - !ruby/object:Api::Type::String
        name: 'name'
        description: The resource name of the Dataset. This value is set by Google.
        output: true
      - !ruby/object:Api::Type::String
        name: 'displayName'
        required: true
        description: |
          The user-defined name of the Dataset. The name can be up to 128 characters long and can be consist of any UTF-8 characters.
      - !ruby/object:Api::Type::String
        name: 'createTime'
        output: true
        description: |
          The timestamp of when the dataset was created in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
      - !ruby/object:Api::Type::String
        name: 'updateTime'
        output: true
        description: |
          The timestamp of when the dataset was last updated in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
      - !ruby/object:Api::Type::KeyValuePairs
        name: 'labels'
        description: |
          A set of key/value label pairs to assign to this Workflow.
      - !ruby/object:Api::Type::NestedObject
        name: 'encryptionSpec'
        input: true
        description: |
          Customer-managed encryption key spec for a Dataset. If set, this Dataset and all sub-resources of this Dataset will be secured by this key.
        properties:
          - !ruby/object:Api::Type::String
            name: 'kmsKeyName'
            description: |
              Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
              Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
            input: true
      - !ruby/object:Api::Type::String
        name: 'metadataSchemaUri'
        required: true
        input: true
        description: |
          Points to a YAML file stored on Google Cloud Storage describing additional information about the Dataset. The schema is defined as an OpenAPI 3.0.2 Schema Object. The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/metadata/.

# Vertex AI Endpoints
  - !ruby/object:Api::Resource
    name: Endpoint
    base_url: projects/{{project}}/locations/{{location}}/endpoints
    create_url: projects/{{project}}/locations/{{location}}/endpoints
    self_link: 'projects/{{project}}/locations/{{location}}/endpoints/{{name}}'
    update_verb: :PATCH
    update_mask: true
    references: !ruby/object:Api::Resource::ReferenceLinks
      guides:
        'Official Documentation':
          'https://cloud.google.com/vertex-ai/docs'
      api: 'https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.endpoints'
    async: !ruby/object:Api::OpAsync
      actions:
        - create
        - delete
      operation: !ruby/object:Api::OpAsync::Operation
        path: 'name'
        base_url: '{{op_id}}'
        wait_ms: 1000
      result: !ruby/object:Api::OpAsync::Result
        path: 'response'
        resource_inside_response: true
      status: !ruby/object:Api::OpAsync::Status
        path: 'done'
        complete: True
        allowed:
          - True
          - False
      error: !ruby/object:Api::OpAsync::Error
        path: 'error'
        message: 'message'
    description: "Models are deployed into it, and afterwards Endpoint is called to obtain predictions and explanations."
    parameters:
      - !ruby/object:Api::Type::String
        name: location
        description: The location for the resource
        url_param_only: true
        required: true
        input: true
    properties:
      - !ruby/object:Api::Type::String
        name: name
        description: Output only. The resource name of the Endpoint.
        output: true
      - !ruby/object:Api::Type::String
        name: displayName
        description: Required. The display name of the Endpoint. The name can be up to 128 characters long and can consist of any UTF-8 characters.
        required: true
      - !ruby/object:Api::Type::String
        name: description
        description: The description of the Endpoint.
      - !ruby/object:Api::Type::Array
        name: deployedModels
        description: Output only. The models deployed in this Endpoint. To add or remove DeployedModels use EndpointService.DeployModel and EndpointService.UndeployModel respectively.
        output: true
        item_type: !ruby/object:Api::Type::NestedObject
          name: deployedModel
          description: Output only. The models deployed in this Endpoint. To add or remove DeployedModels use EndpointService.DeployModel and EndpointService.UndeployModel respectively.
          properties:
              - !ruby/object:Api::Type::NestedObject
                name: dedicatedResources
                description: A description of resources that are dedicated to the DeployedModel, and that need a higher degree of manual configuration.
                output: true
                properties:
                  - !ruby/object:Api::Type::NestedObject
                    name: machineSpec
                    description: The specification of a single machine used by the prediction.
                    output: true
                    properties:
                      - !ruby/object:Api::Type::String
                        name: machineType
                        description: 'The type of the machine. See the [list of machine types supported for prediction](https://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types) See the [list of machine types supported for custom training](https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types). For DeployedModel this field is optional, and the default value is `n1-standard-2`. For BatchPredictionJob or as part of WorkerPoolSpec this field is required. TODO(rsurowka): Try to better unify the required vs optional.'
                        output: true
                      - !ruby/object:Api::Type::String
                        name: acceleratorType
                        description: The type of accelerator(s) that may be attached to the machine as per accelerator_count. See possible values [here](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec#AcceleratorType).
                        output: true
                      - !ruby/object:Api::Type::Integer
                        name: acceleratorCount
                        description: The number of accelerators to attach to the machine.
                        output: true
                  - !ruby/object:Api::Type::Integer
                    name: minReplicaCount
                    description: The minimum number of machine replicas this DeployedModel will be always deployed on. This value must be greater than or equal to 1. If traffic against the DeployedModel increases, it may dynamically be deployed onto more replicas, and as traffic decreases, some of these extra replicas may be freed.
                    output: true
                  - !ruby/object:Api::Type::Integer
                    name: maxReplicaCount
                    description: The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, will use min_replica_count as the default value. The value of this field impacts the charge against Vertex CPU and GPU quotas. Specifically, you will be charged for max_replica_count * number of cores in the selected machine type) and (max_replica_count * number of GPUs per replica in the selected machine type).
                    output: true
                  - !ruby/object:Api::Type::Array
                    name: autoscalingMetricSpecs
                    description: The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
                    output: true
                    item_type: !ruby/object:Api::Type::NestedObject
                      name: autoscalingMetricSpec
                      description: The metric specifications that overrides a resource utilization metric (CPU utilization, accelerator's duty cycle, and so on) target value (default to 60 if not set). At most one entry is allowed per metric. If machine_spec.accelerator_count is above 0, the autoscaling will be based on both CPU utilization and accelerator's duty cycle metrics and scale up when either metrics exceeds its target value while scale down if both metrics are under their target value. The default target value is 60 for both metrics. If machine_spec.accelerator_count is 0, the autoscaling will be based on CPU utilization metric only with default target value 60 if not explicitly set. For example, in the case of Online Prediction, if you want to override target CPU utilization to 80, you should set autoscaling_metric_specs.metric_name to `aiplatform.googleapis.com/prediction/online/cpu/utilization` and autoscaling_metric_specs.target to `80`.
                      properties:
                          - !ruby/object:Api::Type::String
                            name: metricName
                            description: 'The resource metric name. Supported metrics: * For Online Prediction: * `aiplatform.googleapis.com/prediction/online/accelerator/duty_cycle` * `aiplatform.googleapis.com/prediction/online/cpu/utilization`'
                            output: true
                          - !ruby/object:Api::Type::Integer
                            name: target
                            description: The target resource utilization in percentage (1% - 100%) for the given metric; once the real usage deviates from the target by a certain percentage, the machine replicas change. The default value is 60 (representing 60%) if not provided.
                            output: true
              - !ruby/object:Api::Type::NestedObject
                name: automaticResources
                description: A description of resources that to large degree are decided by Vertex AI, and require only a modest additional configuration.
                output: true
                properties:
                  - !ruby/object:Api::Type::Integer
                    name: minReplicaCount
                    description: The minimum number of replicas this DeployedModel will be always deployed on. If traffic against it increases, it may dynamically be deployed onto more replicas up to max_replica_count, and as traffic decreases, some of these extra replicas may be freed. If the requested value is too large, the deployment will error.
                    output: true
                  - !ruby/object:Api::Type::Integer
                    name: maxReplicaCount
                    description: The maximum number of replicas this DeployedModel may be deployed on when the traffic against it increases. If the requested value is too large, the deployment will error, but if deployment succeeds then the ability to scale the model to that many replicas is guaranteed (barring service outages). If traffic against the DeployedModel increases beyond what its replicas at maximum may handle, a portion of the traffic will be dropped. If this value is not provided, a no upper bound for scaling under heavy traffic will be assume, though Vertex AI may be unable to scale beyond certain replica number.
                    output: true
              - !ruby/object:Api::Type::String
                name: id
                description: The ID of the DeployedModel. If not provided upon deployment, Vertex AI will generate a value for this ID. This value should be 1-10 characters, and valid characters are /[0-9]/.
                output: true
              - !ruby/object:Api::Type::String
                name: model
                description: The name of the Model that this is the deployment of. Note that the Model may be in a different location than the DeployedModel's Endpoint.
                output: true
              - !ruby/object:Api::Type::String
                name: modelVersionId
                description: Output only. The version ID of the model that is deployed.
                output: true
              - !ruby/object:Api::Type::String
                name: displayName
                description: The display name of the DeployedModel. If not provided upon creation, the Model's display_name is used.
                output: true
              - !ruby/object:Api::Type::String
                name: createTime
                description: Output only. Timestamp when the DeployedModel was created.
                output: true
              - !ruby/object:Api::Type::String
                name: serviceAccount
                description: The service account that the DeployedModel's container runs as. Specify the email address of the service account. If this service account is not specified, the container runs as a service account that doesn't have access to the resource project. Users deploying the Model must have the `iam.serviceAccounts.actAs` permission on this service account.
                output: true
              - !ruby/object:Api::Type::Boolean
                name: enableAccessLogging
                description: These logs are like standard server access logs, containing information like timestamp and latency for each prediction request. Note that Stackdriver logs may incur a cost, especially if your project receives prediction requests at a high queries per second rate (QPS). Estimate your costs before enabling this option.
                output: true
              - !ruby/object:Api::Type::NestedObject
                name: privateEndpoints
                description: Output only. Provide paths for users to send predict/explain/health requests directly to the deployed model services running on Cloud via private services access. This field is populated if network is configured.
                output: true
                properties:
                  - !ruby/object:Api::Type::String
                    name: predictHttpUri
                    description: Output only. Http(s) path to send prediction requests.
                    output: true
                  - !ruby/object:Api::Type::String
                    name: explainHttpUri
                    description: Output only. Http(s) path to send explain requests.
                    output: true
                  - !ruby/object:Api::Type::String
                    name: healthHttpUri
                    description: Output only. Http(s) path to send health check requests.
                    output: true
                  - !ruby/object:Api::Type::String
                    name: serviceAttachment
                    description: Output only. The name of the service attachment resource. Populated if private service connect is enabled.
                    output: true
              - !ruby/object:Api::Type::String
                name: sharedResources
                description: 'The resource name of the shared DeploymentResourcePool to deploy on. Format: projects/{project}/locations/{location}/deploymentResourcePools/{deployment_resource_pool}'
                output: true
              - !ruby/object:Api::Type::Boolean
                name: enableContainerLogging
                description: If true, the container of the DeployedModel instances will send `stderr` and `stdout` streams to Stackdriver Logging. Only supported for custom-trained Models and AutoML Tabular Models.
                output: true
      - !ruby/object:Api::Type::String
        name: etag
        description: Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
        output: true
      - !ruby/object:Api::Type::KeyValuePairs
        name: labels
        description: The labels with user-defined metadata to organize your Endpoints. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
      - !ruby/object:Api::Type::String
        name: createTime
        description: Output only. Timestamp when this Endpoint was created.
        output: true
      - !ruby/object:Api::Type::String
        name: updateTime
        description: Output only. Timestamp when this Endpoint was last updated.
        output: true
      - !ruby/object:Api::Type::NestedObject
        name: encryptionSpec
        description: Customer-managed encryption key spec for an Endpoint. If set, this Endpoint and all sub-resources of this Endpoint will be secured by this key.
        input: true
        properties:
          - !ruby/object:Api::Type::String
            name: kmsKeyName
            description: 'Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.'
            required: true
            input: true
      - !ruby/object:Api::Type::String
        name: network
        description: 'The full name of the Google Compute Engine [network](https://cloud.google.com//compute/docs/networks-and-firewalls#networks) to which the Endpoint should be peered. Private services access must already be configured for the network. If left unspecified, the Endpoint is not peered with any network. Only one of the fields, network or enable_private_service_connect, can be set. [Format](https://cloud.google.com/compute/docs/reference/rest/v1/networks/insert): `projects/{project}/global/networks/{network}`. Where `{project}` is a project number, as in `12345`, and `{network}` is network name.'
        input: true
      - !ruby/object:Api::Type::String
        name: modelDeploymentMonitoringJob
        description: 'Output only. Resource name of the Model Monitoring job associated with this Endpoint if monitoring is enabled by CreateModelDeploymentMonitoringJob. Format: `projects/{project}/locations/{location}/modelDeploymentMonitoringJobs/{model_deployment_monitoring_job}`'
        output: true

# Vertex AI Featurestores
  - !ruby/object:Api::Resource
    name: Featurestore
    base_url: projects/{{project}}/locations/{{region}}/featurestores
    create_url: projects/{{project}}/locations/{{region}}/featurestores?featurestoreId={{name}}
    self_link: 'projects/{{project}}/locations/{{region}}/featurestores/{{name}}'
    min_version: beta
    update_verb: :PATCH
    update_mask: true
    references: !ruby/object:Api::Resource::ReferenceLinks
      guides:
        'Official Documentation':
          'https://cloud.google.com/vertex-ai/docs'
      api: 'https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores'
    async: !ruby/object:Api::OpAsync
      operation: !ruby/object:Api::OpAsync::Operation
        path: 'name'
        base_url: '{{op_id}}'
        wait_ms: 1000
      result: !ruby/object:Api::OpAsync::Result
        path: 'response'
        resource_inside_response: true
      status: !ruby/object:Api::OpAsync::Status
        path: 'done'
        complete: True
        allowed:
          - True
          - False
      error: !ruby/object:Api::OpAsync::Error
        path: 'error'
        message: 'message'
    description: |-
      A collection of DataItems and Annotations on them.
    parameters:
      - !ruby/object:Api::Type::String
        name: region
        description: The region of the dataset. eg us-central1
        url_param_only: true
        input: true
    properties:
      - !ruby/object:Api::Type::String
        name: 'name'
        description: The name of the Featurestore. This value may be up to 60 characters, and valid characters are [a-z0-9_]. The first character cannot be a number.
        input: true
        url_param_only: true
        pattern: projects/{{project}}/locations/{{region}}/featurestores/{{name}}
      - !ruby/object:Api::Type::String
        name: 'etag'
        description: Used to perform consistent read-modify-write updates.
        output: true
      - !ruby/object:Api::Type::String
        name: 'createTime'
        output: true
        description: |
          The timestamp of when the featurestore was created in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
      - !ruby/object:Api::Type::String
        name: 'updateTime'
        output: true
        description: |
          The timestamp of when the featurestore was last updated in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
      - !ruby/object:Api::Type::KeyValuePairs
        name: 'labels'
        description: |
          A set of key/value label pairs to assign to this Featurestore.
      - !ruby/object:Api::Type::NestedObject
        name: 'onlineServingConfig'
        description: |
           Config for online serving resources.
        properties:
          - !ruby/object:Api::Type::Integer
            name: 'fixedNodeCount'
            required: true
            description: |
              The number of nodes for each cluster. The number of nodes will not scale automatically but can be scaled manually by providing different values when updating.
      - !ruby/object:Api::Type::NestedObject
        name: 'encryptionSpec'
        description: |
           If set, both of the online and offline data storage will be secured by this key.
        properties:
          - !ruby/object:Api::Type::String
            name: 'kmsKeyName'
            required: true
            description: |
              The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the compute resource is created.

# Vertex AI Featurestore Entity Type
  - !ruby/object:Api::Resource
    name: FeaturestoreEntitytype
    base_url: '{{featurestore}}/entityTypes'
    create_url: '{{featurestore}}/entityTypes?entityTypeId={{name}}'
    self_link: '{{featurestore}}/entityTypes/{{name}}'
    min_version: beta
    update_verb: :PATCH
    update_mask: true
    references: !ruby/object:Api::Resource::ReferenceLinks
      guides:
        'Official Documentation':
          'https://cloud.google.com/vertex-ai/docs'
      api: 'https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes'
    async: !ruby/object:Api::OpAsync
      actions:
        - create
        - delete
      operation: !ruby/object:Api::OpAsync::Operation
        path: 'name'
        base_url: '{{op_id}}'
        wait_ms: 1000
      result: !ruby/object:Api::OpAsync::Result
        path: 'response'
        resource_inside_response: true
      status: !ruby/object:Api::OpAsync::Status
        path: 'done'
        complete: True
        allowed:
          - True
          - False
      error: !ruby/object:Api::OpAsync::Error
        path: 'error'
        message: 'message'
      include_project: true
    description: |-
      An entity type is a type of object in a system that needs to be modeled and have stored information about. For example, driver is an entity type, and driver0 is an instance of an entity type driver.
    parameters:
      - !ruby/object:Api::Type::String
        name: featurestore
        description: The name of the Featurestore to use, in the format projects/{project}/locations/{location}/featurestores/{featurestore}.
        url_param_only: true
        input: true
        required: true
    properties:
      - !ruby/object:Api::Type::String
        name: 'name'
        description: The name of the EntityType. This value may be up to 60 characters, and valid characters are [a-z0-9_]. The first character cannot be a number.
        input: true
        url_param_only: true
        pattern: '{featurestore}}/entityTypes/{{name}}'
      - !ruby/object:Api::Type::String
        name: 'etag'
        description: Used to perform consistent read-modify-write updates.
        output: true
      - !ruby/object:Api::Type::String
        name: 'createTime'
        output: true
        description: |
          The timestamp of when the featurestore was created in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
      - !ruby/object:Api::Type::String
        name: 'updateTime'
        output: true
        description: |
          The timestamp of when the featurestore was last updated in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
      - !ruby/object:Api::Type::KeyValuePairs
        name: 'labels'
        description: |
          A set of key/value label pairs to assign to this EntityType.
      - !ruby/object:Api::Type::NestedObject
        name: 'monitoringConfig'
        description: |
          The default monitoring configuration for all Features under this EntityType.

          If this is populated with [FeaturestoreMonitoringConfig.monitoring_interval] specified, snapshot analysis monitoring is enabled. Otherwise, snapshot analysis monitoring is disabled.
        properties:
          - !ruby/object:Api::Type::NestedObject
            name: 'snapshotAnalysis'
            description: |
              Configuration of how features in Featurestore are monitored.
            properties:
              - !ruby/object:Api::Type::Boolean
                name: 'disabled'
                default_value: false
                description: |
                  The monitoring schedule for snapshot analysis. For EntityType-level config: unset / disabled = true indicates disabled by default for Features under it; otherwise by default enable snapshot analysis monitoring with monitoringInterval for Features under it.
              - !ruby/object:Api::Type::String
                name: 'monitoringInterval'
                description: |
                  Configuration of the snapshot analysis based monitoring pipeline running interval. The value is rolled up to full day.

                  A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".

# Vertex AI Featurestore Entity Type Feature
  - !ruby/object:Api::Resource
    name: FeaturestoreEntitytypeFeature
    base_url: '{{entitytype}}/features'
    create_url: '{{entitytype}}/features?featureId={{name}}'
    self_link: '{{entitytype}}/features/{{name}}'
    min_version: beta
    update_verb: :PATCH
    update_mask: true
    references: !ruby/object:Api::Resource::ReferenceLinks
      guides:
        'Official Documentation':
          'https://cloud.google.com/vertex-ai/docs'
      api: 'https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes.features'
    async: !ruby/object:Api::OpAsync
      actions:
        - create
        - delete
      operation: !ruby/object:Api::OpAsync::Operation
        path: 'name'
        base_url: '{{op_id}}'
        wait_ms: 1000
      result: !ruby/object:Api::OpAsync::Result
        path: 'response'
        resource_inside_response: true
      status: !ruby/object:Api::OpAsync::Status
        path: 'done'
        complete: True
        allowed:
          - True
          - False
      error: !ruby/object:Api::OpAsync::Error
        path: 'error'
        message: 'message'
      include_project: true
    description: |-
      Feature Metadata information that describes an attribute of an entity type. For example, apple is an entity type, and color is a feature that describes apple.
    parameters:
      - !ruby/object:Api::Type::String
        name: entitytype
        description: The name of the Featurestore to use, in the format projects/{project}/locations/{location}/featurestores/{featurestore}/entityTypes/{entitytype}.
        url_param_only: true
        input: true
        required: true
    properties:
      - !ruby/object:Api::Type::String
        name: 'name'
        description: The name of the feature. The feature can be up to 64 characters long and can consist only of ASCII Latin letters A-Z and a-z, underscore(_), and ASCII digits 0-9 starting with a letter. The value will be unique given an entity type.
        input: true
        url_param_only: true
        pattern: '{{entitytype}}/features/{{name}}'
      - !ruby/object:Api::Type::String
        name: 'etag'
        description: Used to perform consistent read-modify-write updates.
        output: true
      - !ruby/object:Api::Type::String
        name: 'createTime'
        output: true
        description: |
          The timestamp of when the entity type was created in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
      - !ruby/object:Api::Type::String
        name: 'updateTime'
        output: true
        description: |
           The timestamp when the entity type was most recently updated in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
      - !ruby/object:Api::Type::KeyValuePairs
        name: 'labels'
        description: |
          A set of key/value label pairs to assign to the feature.
      - !ruby/object:Api::Type::String
        name: 'description'
        description: Description of the feature.
      - !ruby/object:Api::Type::String
        name: 'valueType'
        description: |
          Type of Feature value. Immutable. https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes.features#ValueType
        required: true

# Vertex ML Metadata
  - !ruby/object:Api::Resource
    name: MetadataStore
    base_url: projects/{{project}}/locations/{{region}}/metadataStores
    self_link: 'projects/{{project}}/locations/{{region}}/metadataStores/{{name}}'
    create_url: projects/{{project}}/locations/{{region}}/metadataStores?metadataStoreId={{name}}
    min_version: beta
    input: true
    references: !ruby/object:Api::Resource::ReferenceLinks
      guides:
        'Official Documentation':
          'https://cloud.google.com/vertex-ai/docs'
      api: 'https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.metadataStores'
    async: !ruby/object:Api::OpAsync
      operation: !ruby/object:Api::OpAsync::Operation
        path: 'name'
        base_url: '{{op_id}}'
        wait_ms: 1000
      result: !ruby/object:Api::OpAsync::Result
        path: 'response'
        resource_inside_response: true
      status: !ruby/object:Api::OpAsync::Status
        path: 'done'
        complete: True
        allowed:
          - True
          - False
      error: !ruby/object:Api::OpAsync::Error
        path: 'error'
        message: 'message'
    description: |-
      Instance of a metadata store. Contains a set of metadata that can be queried.
    parameters:
      - !ruby/object:Api::Type::String
        name: region
        description: The region of the Metadata Store. eg us-central1
        url_param_only: true
        input: true
    properties:
      - !ruby/object:Api::Type::String
        name: 'name'
        description: The name of the MetadataStore. This value may be up to 60 characters, and valid characters are [a-z0-9_]. The first character cannot be a number.
        input: true
        url_param_only: true
        pattern: projects/{{project}}/locations/{{region}}/metadataStores/{{name}}
      - !ruby/object:Api::Type::String
        name: 'description'
        description: Description of the MetadataStore.
        input: true
      - !ruby/object:Api::Type::String
        name: 'createTime'
        output: true
        description: |
          The timestamp of when the MetadataStore was created in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
      - !ruby/object:Api::Type::String
        name: 'updateTime'
        output: true
        description: |
          The timestamp of when the MetadataStore was last updated in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
      - !ruby/object:Api::Type::NestedObject
        name: 'encryptionSpec'
        input: true
        description: |
          Customer-managed encryption key spec for a MetadataStore. If set, this MetadataStore and all sub-resources of this MetadataStore will be secured by this key.
        properties:
          - !ruby/object:Api::Type::String
            name: 'kmsKeyName'
            description: |
              Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource.
              Has the form: projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key. The key needs to be in the same region as where the resource is created.
            input: true
      - !ruby/object:Api::Type::NestedObject
        name: 'state'
        output: true
        description: |
          State information of the MetadataStore.
        properties:
          - !ruby/object:Api::Type::String
            name: 'diskUtilizationBytes'
            description: |
              The disk utilization of the MetadataStore in bytes.
            output: true

# Vertex AI Models
  - !ruby/object:Api::Resource
    name: Model
    base_url: projects/{{project}}/locations/{{location}}/models
    create_url: projects/{{project}}/locations/{{location}}/models:upload
    self_link: 'projects/{{project}}/locations/{{location}}/models/{{name}}'
    update_verb: :PATCH
    update_mask: true
    references: !ruby/object:Api::Resource::ReferenceLinks
      guides:
        'Official Documentation':
          'https://cloud.google.com/vertex-ai/docs'
      api: 'https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models'
    async: !ruby/object:Api::OpAsync
      operation: !ruby/object:Api::OpAsync::Operation
        path: 'name'
        base_url: '{{op_id}}'
        wait_ms: 1000
      result: !ruby/object:Api::OpAsync::Result
        path: 'response'
        resource_inside_response: true
      status: !ruby/object:Api::OpAsync::Status
        path: 'done'
        complete: True
        allowed:
          - True
          - False
      error: !ruby/object:Api::OpAsync::Error
        path: 'error'
        message: 'message'
    description: "A trained machine learning Model."
    parameters:
      - !ruby/object:Api::Type::String
        name: location
        description: The location for the resource
        url_param_only: true
        required: true
        input: true
    properties:
      - !ruby/object:Api::Type::String
        name: name
        description: The resource name of the Model.
        output: true
      - !ruby/object:Api::Type::String
        name: versionId
        description: Output only. Immutable. The version ID of the model. A new version is committed when a new model version is uploaded or trained under an existing model id. It is an auto-incrementing decimal number in string representation.
        output: true
      - !ruby/object:Api::Type::Array
        name: versionAliases
        description: User provided version aliases so that a model version can be referenced via alias (i.e. projects/{project}/locations/{location}/models/{model_id}@{version_alias} instead of auto-generated version id (i.e. projects/{project}/locations/{location}/models/{model_id}@{version_id}). The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.
        input: true
        item_type: Api::Type::String
      - !ruby/object:Api::Type::String
        name: versionCreateTime
        description: Output only. Timestamp when this version was created.
        output: true
      - !ruby/object:Api::Type::String
        name: versionUpdateTime
        description: Output only. Timestamp when this version was most recently updated.
        output: true
      - !ruby/object:Api::Type::String
        name: displayName
        description: Required. The display name of the Model. The name can be up to 128 characters long and can be consist of any UTF-8 characters.
        required: true
      - !ruby/object:Api::Type::String
        name: description
        description: The description of the Model.
      - !ruby/object:Api::Type::String
        name: versionDescription
        description: The description of this version.
        input: true
      - !ruby/object:Api::Type::Array
        name: supportedExportFormats
        description: Output only. The formats in which this Model may be exported. If empty, this Model is not available for export.
        output: true
        item_type: !ruby/object:Api::Type::NestedObject
          name: supportedExportFormat
          description: Output only. The formats in which this Model may be exported. If empty, this Model is not available for export.
          properties:
              - !ruby/object:Api::Type::String
                name: id
                description: 'Output only. The ID of the export format. The possible format IDs are: * `tflite` Used for Android mobile devices. * `edgetpu-tflite` Used for [Edge TPU](https://cloud.google.com/edge-tpu/) devices. * `tf-saved-model` A tensorflow model in SavedModel format. * `tf-js` A [TensorFlow.js](https://www.tensorflow.org/js) model that can be used in the browser and in Node.js using JavaScript. * `core-ml` Used for iOS mobile devices. * `custom-trained` A Model that was uploaded or trained by custom code.'
                output: true
              - !ruby/object:Api::Type::Array
                name: exportableContents
                description: Output only. The content of this Model that may be exported.
                output: true
                item_type: Api::Type::Enum
      - !ruby/object:Api::Type::String
        name: trainingPipeline
        description: Output only. The resource name of the TrainingPipeline that uploaded this Model, if any.
        output: true
      - !ruby/object:Api::Type::NestedObject
        name: originalModelInfo
        description: Output only. If this Model is a copy of another Model, this contains info about the original.
        output: true
        properties:
          - !ruby/object:Api::Type::String
            name: model
            description: 'Output only. The resource name of the Model this Model is a copy of, including the revision. Format: `projects/{project}/locations/{location}/models/{model_id}@{version_id}`'
            output: true
      - !ruby/object:Api::Type::NestedObject
        name: containerSpec
        description: The specification of the container that is to be used when deploying this Model. The specification is ingested upon ModelService.UploadModel, and all binaries it contains are copied and stored internally by Vertex AI. Not present for AutoML Models.
        required: true
        input: true
        properties:
          - !ruby/object:Api::Type::String
            name: imageUri
            description: Required. Immutable. URI of the Docker image to be used as the custom container for serving predictions. This URI must identify an image in Artifact Registry or Container Registry. Learn more about the [container publishing requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#publishing), including permissions requirements for the Vertex AI Service Agent. The container image is ingested upon ModelService.UploadModel, stored internally, and this original path is afterwards not used. To learn about the requirements for the Docker image itself, see [Custom container requirements](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#). You can use the URI to one of Vertex AI's [pre-built container images for prediction](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) in this field.
            required: true
            input: true
          - !ruby/object:Api::Type::Array
            name: command
            description: 'Immutable. Specifies the command that runs when the container starts. This overrides the container''s [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`''s "exec" form, not its "shell" form. If you do not specify this field, then the container''s `ENTRYPOINT` runs, in conjunction with the args field or the container''s [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container''s `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container''s `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: `$(VARIABLE_NAME)` Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: `$$(VARIABLE_NAME)` This field corresponds to the `command` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).'
            input: true
            item_type: Api::Type::String
          - !ruby/object:Api::Type::Array
            name: args
            description: 'Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container''s [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`''s "default parameters" form. If you don''t specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container''s `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don''t specify this field and don''t specify the `command` field, then the container''s [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the Docker documentation about [how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: `$(VARIABLE_NAME)` Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: `$$(VARIABLE_NAME)` This field corresponds to the `args` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).'
            input: true
            item_type: Api::Type::String
          - !ruby/object:Api::Type::Array
            name: env
            description: 'Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ```json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ] ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).'
            input: true
            item_type: !ruby/object:Api::Type::NestedObject
              name: env
              description: 'Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ```json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ] ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).'
              properties:
                  - !ruby/object:Api::Type::String
                    name: name
                    description: Required. Name of the environment variable. Must be a valid C identifier.
                    required: true
                    input: true
                  - !ruby/object:Api::Type::String
                    name: value
                    description: 'Required. Variables that reference a $(VAR_NAME) are expanded using the previous defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. The $(VAR_NAME) syntax can be escaped with a double $$, ie: $$(VAR_NAME). Escaped references will never be expanded, regardless of whether the variable exists or not.'
                    required: true
                    input: true
          - !ruby/object:Api::Type::Array
            name: ports
            description: 'Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ```json [ { "containerPort": 8080 } ] ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).'
            input: true
            item_type: !ruby/object:Api::Type::NestedObject
              name: port
              description: 'Immutable. List of ports to expose from the container. Vertex AI sends any prediction requests that it receives to the first port on this list. Vertex AI also sends [liveness and health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#liveness) to this port. If you do not specify this field, it defaults to following value: ```json [ { "containerPort": 8080 } ] ``` Vertex AI does not use ports other than the first one listed. This field corresponds to the `ports` field of the Kubernetes Containers [v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#container-v1-core).'
              properties:
                  - !ruby/object:Api::Type::Integer
                    name: containerPort
                    description: The number of the port to expose on the pod's IP address. Must be a valid port number, between 1 and 65535 inclusive.
                    input: true
          - !ruby/object:Api::Type::String
            name: predictRoute
            description: 'Immutable. HTTP path on the container to send prediction requests to. Vertex AI forwards requests sent using projects.locations.endpoints.predict to this path on the container''s IP address and port. Vertex AI then returns the container''s response in the API response. For example, if you set this field to `/foo`, then when Vertex AI receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of this `ModelContainerSpec`''s ports field. If you don''t specify this field, it defaults to the following value when you deploy this Model to an Endpoint: `/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict` The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)'
            input: true
          - !ruby/object:Api::Type::String
            name: healthRoute
            description: 'Immutable. HTTP path on the container to send health checks to. Vertex AI intermittently sends GET requests to this path on the container''s IP address and port to check that the container is healthy. Read more about [health checks](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#health). For example, if you set this field to `/bar`, then Vertex AI intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of this `ModelContainerSpec`''s ports field. If you don''t specify this field, it defaults to the following value when you deploy this Model to an Endpoint: `/v1/endpoints/ENDPOINT/deployedModels/DEPLOYED_MODEL:predict` The placeholders in this value are replaced as follows: * ENDPOINT: The last segment (following `endpoints/`)of the Endpoint.name][] field of the Endpoint where this Model has been deployed. (Vertex AI makes this value available to your container code as the [`AIP_ENDPOINT_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).) * DEPLOYED_MODEL: DeployedModel.id of the `DeployedModel`. (Vertex AI makes this value available to your container code as the [`AIP_DEPLOYED_MODEL_ID` environment variable](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements#aip-variables).)'
            input: true
      - !ruby/object:Api::Type::String
        name: artifactUri
        description: Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not present for AutoML Models.
        input: true
      - !ruby/object:Api::Type::Array
        name: supportedDeploymentResourcesTypes
        description: Output only. When this Model is deployed, its prediction resources are described by the `prediction_resources` field of the Endpoint.deployed_models object. Because not all Models support all resource configuration types, the configuration types this Model supports are listed here. If no configuration types are listed, the Model cannot be deployed to an Endpoint and does not support online predictions (PredictionService.Predict or PredictionService.Explain). Such a Model can serve predictions by using a BatchPredictionJob, if it has at least one entry each in supported_input_storage_formats and supported_output_storage_formats.
        output: true
        item_type: Api::Type::Enum
      - !ruby/object:Api::Type::Array
        name: supportedInputStorageFormats
        description: 'Output only. The formats this Model supports in BatchPredictionJob.input_config. If PredictSchemata.instance_schema_uri exists, the instances should be given as per that schema. The possible formats are: * `jsonl` The JSON Lines format, where each instance is a single line. Uses GcsSource. * `csv` The CSV format, where each instance is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsSource. * `tf-record` The TFRecord format, where each instance is a single record in tfrecord syntax. Uses GcsSource. * `tf-record-gzip` Similar to `tf-record`, but the file is gzipped. Uses GcsSource. * `bigquery` Each instance is a single row in BigQuery. Uses BigQuerySource. * `file-list` Each line of the file is the location of an instance to process, uses `gcs_source` field of the InputConfig object. If this Model doesn''t support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain. TODO(rsurowka): Give a link describing how OpenAPI schema instances are expressed in JSONL and BigQuery. TODO(rsurowka): Should we provide a schema for TFRecord? Or maybe say that at least for now TFRecord input is not supported via schemata (that would also simplify giving them back as part of predictions). TODO(rsurowka): Define CSV format (decide how much we want to support). E.g. no nesting? Or no arrays, or no nested arrays? E.g. https://json-csv.com/ seems to be able to do pretty advanced conversions, but we may decide to make it relatively simple for now.'
        output: true
        item_type: Api::Type::String
      - !ruby/object:Api::Type::Array
        name: supportedOutputStorageFormats
        description: 'Output only. The formats this Model supports in BatchPredictionJob.output_config. If both PredictSchemata.instance_schema_uri and PredictSchemata.prediction_schema_uri exist, the predictions are returned together with their instances. In other words, the prediction has the original instance data first, followed by the actual prediction content (as per the schema). The possible formats are: * `jsonl` The JSON Lines format, where each prediction is a single line. Uses GcsDestination. * `csv` The CSV format, where each prediction is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsDestination. * `bigquery` Each prediction is a single row in a BigQuery table, uses BigQueryDestination . If this Model doesn''t support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain. TODO(rsurowka): Analogous TODOs as for instances field above.'
        output: true
        item_type: Api::Type::String
      - !ruby/object:Api::Type::String
        name: createTime
        description: Output only. Timestamp when this Model was uploaded into Vertex AI.
        output: true
      - !ruby/object:Api::Type::String
        name: updateTime
        description: Output only. Timestamp when this Model was most recently updated.
        output: true
      - !ruby/object:Api::Type::Array
        name: deployedModels
        description: Output only. The pointers to DeployedModels created from this Model. Note that Model could have been deployed to Endpoints in different Locations.
        output: true
        item_type: !ruby/object:Api::Type::NestedObject
          name: deployedModel
          description: Output only. The pointers to DeployedModels created from this Model. Note that Model could have been deployed to Endpoints in different Locations.
          properties:
              - !ruby/object:Api::Type::String
                name: endpoint
                description: Immutable. A resource name of an Endpoint.
                input: true
              - !ruby/object:Api::Type::String
                name: deployedModelId
                description: Immutable. An ID of a DeployedModel in the above Endpoint.
                input: true
      - !ruby/object:Api::Type::String
        name: etag
        description: Used to perform consistent read-modify-write updates. If not set, a blind "overwrite" update happens.
        output: true
      - !ruby/object:Api::Type::KeyValuePairs
        name: labels
        description: The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.
      - !ruby/object:Api::Type::NestedObject
        name: encryptionSpec
        description: Customer-managed encryption key spec for a Model. If set, this Model and all sub-resources of this Model will be secured by this key.
        input: true
        properties:
          - !ruby/object:Api::Type::String
            name: kmsKeyName
            description: 'Required. The Cloud KMS resource identifier of the customer managed encryption key used to protect a resource. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`. The key needs to be in the same region as where the compute resource is created.'
            required: true
            input: true

