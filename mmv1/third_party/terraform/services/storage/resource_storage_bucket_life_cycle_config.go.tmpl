package storage

import (
	"bytes"
	"fmt"
	"log"
	"strings"
	"time"

	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"

	"github.com/hashicorp/terraform-provider-google/google/tpgresource"
	transport_tpg "github.com/hashicorp/terraform-provider-google/google/transport"

	"google.golang.org/api/googleapi"
	"google.golang.org/api/storage/v1"
)

func ResourceStorageBucketLifeCycleConfig() *schema.Resource {
	return &schema.Resource{
		Create: resourceStorageBucketLifeCycleConfigCreate,
		Read:   resourceStorageBucketLifeCycleConfigRead,
		Update: resourceStorageBucketLifeCycleConfigUpdate,
		Delete: resourceStorageBucketLifeCycleConfigDelete,

		Importer: &schema.ResourceImporter{
			State: resourceStorageBucketLifeCycleConfigImport,
		},

		Timeouts: &schema.ResourceTimeout{
			Create: schema.DefaultTimeout(20 * time.Minute),
			Update: schema.DefaultTimeout(20 * time.Minute),
			Delete: schema.DefaultTimeout(20 * time.Minute),
		},

		Schema: map[string]*schema.Schema{
			"bucket": {
				Type:        schema.TypeString,
				Required:    true,
				ForceNew:    true,
				Description: `The name of the bucket that contains the objects.`,
			},
			"lifecycle_rule": {
				Type:     schema.TypeList,
				Required: true,
				MinItems: 1,
				MaxItems: 100,
				Elem: &schema.Resource{
					Schema: map[string]*schema.Schema{
						"action": {
							Type:     schema.TypeSet,
							Required: true,
							MinItems: 1,
							MaxItems: 1,
							Set:      resourceGCSBucketLifecycleRuleActionHash,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"type": {
										Type:        schema.TypeString,
										Required:    true,
										Description: `The type of the action of this Lifecycle Rule. Supported values include: Delete, SetStorageClass and AbortIncompleteMultipartUpload.`,
									},
									"storage_class": {
										Type:        schema.TypeString,
										Optional:    true,
										Description: `The target Storage Class of objects affected by this Lifecycle Rule. Supported values include: MULTI_REGIONAL, REGIONAL, NEARLINE, COLDLINE, ARCHIVE.`,
									},
								},
							},
							Description: `The Lifecycle Rule's action configuration. A single block of this type is supported.`,
						},
						"condition": {
							Type:     schema.TypeSet,
							Required: true,
							MinItems: 1,
							MaxItems: 1,
							Set:      resourceGCSBucketLifecycleRuleConditionHash,
							Elem: &schema.Resource{
								Schema: map[string]*schema.Schema{
									"age": {
										Type:        schema.TypeInt,
										Optional:    true,
										Description: `Minimum age of an object in days to satisfy this condition.`,
									},
									"created_before": {
										Type:        schema.TypeString,
										Optional:    true,
										Description: `Creation date of an object in RFC 3339 (e.g. 2017-06-13) to satisfy this condition.`,
									},
									"custom_time_before": {
										Type:        schema.TypeString,
										Optional:    true,
										Description: `Creation date of an object in RFC 3339 (e.g. 2017-06-13) to satisfy this condition.`,
									},
									"days_since_custom_time": {
										Type:        schema.TypeInt,
										Optional:    true,
										Description: `Number of days elapsed since the user-specified timestamp set on an object.`,
									},
									"days_since_noncurrent_time": {
										Type:     schema.TypeInt,
										Optional: true,
										Description: `Number of days elapsed since the noncurrent timestamp of an object. This
										condition is relevant only for versioned objects.`,
									},
									"noncurrent_time_before": {
										Type:        schema.TypeString,
										Optional:    true,
										Description: `Creation date of an object in RFC 3339 (e.g. 2017-06-13) to satisfy this condition.`,
									},
									"with_state": {
										Type:         schema.TypeString,
										Computed:     true,
										Optional:     true,
										ValidateFunc: validation.StringInSlice([]string{"LIVE", "ARCHIVED", "ANY", ""}, false),
										Description:  `Match to live and/or archived objects. Unversioned buckets have only live objects. Supported values include: "LIVE", "ARCHIVED", "ANY".`,
									},
									"matches_storage_class": {
										Type:        schema.TypeList,
										Optional:    true,
										Elem:        &schema.Schema{Type: schema.TypeString},
										Description: `Storage Class of objects to satisfy this condition. Supported values include: MULTI_REGIONAL, REGIONAL, NEARLINE, COLDLINE, ARCHIVE, STANDARD, DURABLE_REDUCED_AVAILABILITY.`,
									},
									"num_newer_versions": {
										Type:        schema.TypeInt,
										Optional:    true,
										Description: `Relevant only for versioned objects. The number of newer versions of an object to satisfy this condition.`,
									},
									"matches_prefix": {
										Type:        schema.TypeList,
										Optional:    true,
										Elem:        &schema.Schema{Type: schema.TypeString},
										Description: `One or more matching name prefixes to satisfy this condition.`,
									},
									"matches_suffix": {
										Type:        schema.TypeList,
										Optional:    true,
										Elem:        &schema.Schema{Type: schema.TypeString},
										Description: `One or more matching name suffixes to satisfy this condition.`,
									},
									"send_age_if_zero": {
										Type:        schema.TypeBool,
										Optional:    true,
										Description: `While set true, age value will be sent in the request even for zero value of the field. This field is only useful for setting 0 value to the age field. It can be used alone or together with age.`,
									},
									"send_days_since_noncurrent_time_if_zero": {
										Type:        schema.TypeBool,
										Optional:    true,
										Description: `While set true, days_since_noncurrent_time value will be sent in the request even for zero value of the field. This field is only useful for setting 0 value to the days_since_noncurrent_time field. It can be used alone or together with days_since_noncurrent_time.`,
									},
									"send_days_since_custom_time_if_zero": {
										Type:        schema.TypeBool,
										Optional:    true,
										Description: `While set true, days_since_custom_time value will be sent in the request even for zero value of the field. This field is only useful for setting 0 value to the days_since_custom_time field. It can be used alone or together with days_since_custom_time.`,
									},
									"send_num_newer_versions_if_zero": {
										Type:        schema.TypeBool,
										Optional:    true,
										Description: `While set true, num_newer_versions value will be sent in the request even for zero value of the field. This field is only useful for setting 0 value to the num_newer_versions field. It can be used alone or together with num_newer_versions.`,
									},
								},
							},
							Description: `The Lifecycle Rule's condition configuration.`,
						},
					},
				},
				Description: `The bucket's Lifecycle Rules configuration.`,
			},
			"create_time": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The timestamp at which this bucket was created.`,
			},
			"update_time": {
				Type:        schema.TypeString,
				Computed:    true,
				Description: `The timestamp at which this bucket was most recently updated.`,
			},

			"self_link": {
				Type:     schema.TypeString,
				Computed: true,
			},
		},
		UseJSONNumber: true,
	}
}

func resourceStorageBucketLifeCycleConfigCreate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	bucket := d.Get("bucket").(string)

	sb := &storage.Bucket{
		Name: bucket,
	}

	lifecycle, err := expandStorageBucketLifecycleRules(d.Get("lifecycle_rule"))
	if err != nil {
		return err
	}
	sb.Lifecycle = lifecycle

	log.Printf("[DEBUG] Creating new BucketLifeCycleConfig: %#v", sb)

	var res *storage.Bucket

	err = transport_tpg.Retry(transport_tpg.RetryOptions{
		RetryFunc: func() error {
			patchCall := config.NewStorageClient(userAgent).Buckets.Patch(bucket, sb)
			res, err = patchCall.Do()
			return err
		},
		Timeout:              d.Timeout(schema.TimeoutCreate),
		ErrorRetryPredicates: []transport_tpg.RetryErrorPredicateFunc{transport_tpg.Is429RetryableQuotaError},
	})

	if err != nil {
		fmt.Printf("Error creating bucket lifecycle policy %s: %v", bucket, err)
		return err
	}

	log.Printf("[DEBUG] Finished creating BucketLifeCycleConfig %q: %#v", d.Id(), res)
	d.SetId(res.Id)
	return resourceStorageBucketLifeCycleConfigRead(d, meta)
}

func resourceStorageBucketLifeCycleConfigRead(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	// Get the bucket and lifecycle
	bucket := d.Get("bucket").(string)

	res, err := config.NewStorageClient(userAgent).Buckets.Get(bucket).Do()

	if err != nil {
		return transport_tpg.HandleNotFoundError(err, d, fmt.Sprintf("Storage Bucket %q", d.Get("bucket").(string)))
	}
	log.Printf("[DEBUG] Read bucket %v at location %v\n\n", res.Name, res.SelfLink)

	if err := d.Set("create_time", flattenStorageBucketLifeCycleConfigCreateTime(res.TimeCreated, d, config)); err != nil {
		return fmt.Errorf("Error reading BucketLifeCycleConfig: %s", err)
	}
	if err := d.Set("update_time", flattenStorageBucketLifeCycleConfigUpdateTime(res.Updated, d, config)); err != nil {
		return fmt.Errorf("Error reading BucketLifeCycleConfig: %s", err)
	}
	if err := d.Set("lifecycle_rule", flattenStorageBucketLifecycle(d, res.Lifecycle)); err != nil {
		return fmt.Errorf("Error reading BucketLifeCycleConfig: %s", err)
	}
	if err := d.Set("self_link", res.SelfLink); err != nil {
		return fmt.Errorf("Error reading BucketLifeCycleConfig: %s", err)
	}

	return nil
}

func resourceStorageBucketLifeCycleConfigUpdate(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	bucket := d.Get("bucket").(string)

	sb := &storage.Bucket{}

	if detectLifecycleChange(d) {
		lifecycle, err := expandStorageBucketLifecycleRules(d.Get("lifecycle_rule"))
		if err != nil {
			return err
		}
		sb.Lifecycle = lifecycle
	}

	log.Printf("[DEBUG] Updating BucketLifeCycleConfig %q: %#v", d.Id(), sb)

	res, err := config.NewStorageClient(userAgent).Buckets.Patch(bucket, sb).Do()

	if err != nil {
		return fmt.Errorf("Error updating BucketLifeCycleConfig %q: %s", d.Id(), err)
	} else {
		log.Printf("[DEBUG] Finished updating BucketLifeCycleConfig %q: %#v", d.Id(), res)
	}

	return resourceStorageBucketLifeCycleConfigRead(d, meta)
}

func resourceStorageBucketLifeCycleConfigDelete(d *schema.ResourceData, meta interface{}) error {
	config := meta.(*transport_tpg.Config)
	userAgent, err := tpgresource.GenerateUserAgentString(d, config.UserAgent)
	if err != nil {
		return err
	}

	bucket := d.Get("bucket").(string)

	sb := &storage.Bucket{}
	sb.Lifecycle = &storage.BucketLifecycle{ForceSendFields: []string{"Rule"}}

	log.Printf("[DEBUG] Deleting BucketLifeCycleConfig %q: %#v", d.Id(), sb)

	_, err = config.NewStorageClient(userAgent).Buckets.Patch(bucket, sb).Do()

	if err != nil {
		return fmt.Errorf("Error deleting BucketLifeCycleConfig %q: %s", d.Id(), err)
	}
	d.SetId("")
	return nil
}

func resourceStorageBucketLifeCycleConfigImport(d *schema.ResourceData, meta interface{}) ([]*schema.ResourceData, error) {
	parts := strings.Split(d.Id(), "/")
	if len(parts) == 1 {
		if err := d.Set("bucket", parts[0]); err != nil {
			return nil, fmt.Errorf("Error setting bucket: %s", err)
		}
	} else if len(parts) > 1 {
		if err := d.Set("project", parts[0]); err != nil {
			return nil, fmt.Errorf("Error setting project: %s", err)
		}
		if err := d.Set("bucket", parts[1]); err != nil {
			return nil, fmt.Errorf("Error setting bucket: %s", err)
		}
	}
	return []*schema.ResourceData{d}, nil
}

func flattenStorageBucketLifeCycleConfigCreateTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenStorageBucketLifeCycleConfigUpdateTime(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func expandStorageBucketLifecycleRules(v interface{}) (*storage.BucketLifecycle, error) {
	if v == nil {
		return &storage.BucketLifecycle{
			ForceSendFields: []string{"Rule"},
		}, nil
	}
	lifecycleRules := v.([]interface{})
	transformedRules := make([]*storage.BucketLifecycleRule, 0, len(lifecycleRules))

	for _, v := range lifecycleRules {
		rule, err := expandBucketLifecycleRule(v)
		if err != nil {
			return nil, err
		}
		transformedRules = append(transformedRules, rule)
	}

	if len(transformedRules) == 0 {
		return &storage.BucketLifecycle{
			ForceSendFields: []string{"Rule"},
		}, nil
	}

	return &storage.BucketLifecycle{
		Rule: transformedRules,
	}, nil
}

func expandBucketLifecycleRule(v interface{}) (*storage.BucketLifecycleRule, error) {
	if v == nil {
		return nil, nil
	}

	rule := v.(map[string]interface{})
	transformed := &storage.BucketLifecycleRule{}

	if v, ok := rule["action"]; ok {
		action, err := expandBucketLifecycleRuleAction(v)
		if err != nil {
			return nil, err
		}
		transformed.Action = action
	} else {
		return nil, fmt.Errorf("exactly one action is required for lifecycle_rule")
	}

	if v, ok := rule["condition"]; ok {
		cond, err := expandBucketLifecycleRuleCondition(v)
		if err != nil {
			return nil, err
		}
		transformed.Condition = cond
	}

	return transformed, nil
}

func expandBucketLifecycleRuleAction(v interface{}) (*storage.BucketLifecycleRuleAction, error) {
	if v == nil {
		return nil, fmt.Errorf("exactly one action is required for lifecycle_rule")
	}

	actions := v.(*schema.Set).List()
	if len(actions) != 1 {
		return nil, fmt.Errorf("exactly one action is required for lifecycle_rule")
	}

	action := actions[0].(map[string]interface{})
	transformed := &storage.BucketLifecycleRuleAction{}

	if v, ok := action["type"]; ok {
		transformed.Type = v.(string)
	}

	if v, ok := action["storage_class"]; ok {
		transformed.StorageClass = v.(string)
	}

	return transformed, nil
}

func expandBucketLifecycleRuleCondition(v interface{}) (*storage.BucketLifecycleRuleCondition, error) {
	if v == nil {
		return nil, nil
	}
	conditions := v.(*schema.Set).List()
	if len(conditions) != 1 {
		return nil, fmt.Errorf("One and only one condition can be provided per lifecycle_rule")
	}

	condition := conditions[0].(map[string]interface{})
	transformed := &storage.BucketLifecycleRuleCondition{}
	if v, ok := condition["age"]; ok {
		age := int64(v.(int))
		if u, ok := condition["send_age_if_zero"]; age > 0 || (ok && u.(bool)) {
			transformed.Age = &age
		}
	}

	if v, ok := condition["created_before"]; ok {
		transformed.CreatedBefore = v.(string)
	}

	withStateV, withStateOk := condition["with_state"]
	// Because TF schema, withStateOk currently will always be true,
	// do the check just in case.
	if withStateOk {
		switch withStateV.(string) {
		case "LIVE":
			transformed.IsLive = googleapi.Bool(true)
		case "ARCHIVED":
			transformed.IsLive = googleapi.Bool(false)
		case "ANY", "":
			// This is unnecessary, but set explicitly to nil for readability.
			transformed.IsLive = nil
		default:
			return nil, fmt.Errorf("unexpected value %q for condition.with_state", withStateV.(string))
		}
	}

	if v, ok := condition["matches_storage_class"]; ok {
		classes := v.([]interface{})
		transformedClasses := make([]string, 0, len(classes))

		for _, v := range classes {
			transformedClasses = append(transformedClasses, v.(string))
		}
		transformed.MatchesStorageClass = transformedClasses
	}

	if v, ok := condition["num_newer_versions"]; ok {
		transformed.NumNewerVersions = int64(v.(int))
		if u, ok := condition["send_num_newer_versions_if_zero"]; ok && u.(bool) {
			transformed.ForceSendFields = append(transformed.ForceSendFields, "NumNewerVersions")
		}
	}

	if v, ok := condition["custom_time_before"]; ok {
		transformed.CustomTimeBefore = v.(string)
	}

	if v, ok := condition["days_since_custom_time"]; ok {
		transformed.DaysSinceCustomTime = int64(v.(int))
		if u, ok := condition["send_days_since_custom_time_if_zero"]; ok && u.(bool) {
			transformed.ForceSendFields = append(transformed.ForceSendFields, "DaysSinceCustomTime")
		}
	}

	if v, ok := condition["days_since_noncurrent_time"]; ok {
		transformed.DaysSinceNoncurrentTime = int64(v.(int))
		if u, ok := condition["send_days_since_noncurrent_time_if_zero"]; ok && u.(bool) {
			transformed.ForceSendFields = append(transformed.ForceSendFields, "DaysSinceNoncurrentTime")
		}
	}

	if v, ok := condition["noncurrent_time_before"]; ok {
		transformed.NoncurrentTimeBefore = v.(string)
	}

	if v, ok := condition["matches_prefix"]; ok {
		prefixes := v.([]interface{})
		transformedPrefixes := make([]string, 0, len(prefixes))

		for _, v := range prefixes {
			transformedPrefixes = append(transformedPrefixes, v.(string))
		}
		transformed.MatchesPrefix = transformedPrefixes
	}
	if v, ok := condition["matches_suffix"]; ok {
		suffixes := v.([]interface{})
		transformedSuffixes := make([]string, 0, len(suffixes))

		for _, v := range suffixes {
			transformedSuffixes = append(transformedSuffixes, v.(string))
		}
		transformed.MatchesSuffix = transformedSuffixes
	}

	return transformed, nil
}

func flattenStorageBucketLifecycle(d *schema.ResourceData, lifecycle *storage.BucketLifecycle) []map[string]interface{} {
	if lifecycle == nil || lifecycle.Rule == nil {
		return []map[string]interface{}{}
	}

	rules := make([]map[string]interface{}, 0, len(lifecycle.Rule))

	for index, rule := range lifecycle.Rule {
		rules = append(rules, map[string]interface{}{
			"action":    schema.NewSet(resourceLifecycleRuleActionHash, []interface{}{flattenLifecycleRuleAction(rule.Action)}),
			"condition": schema.NewSet(resourceLifecycleRuleConditionHash, []interface{}{flattenLifecycleRuleCondition(index, d, rule.Condition)}),
		})
	}

	return rules
}

func flattenLifecycleRuleAction(action *storage.BucketLifecycleRuleAction) map[string]interface{} {
	return map[string]interface{}{
		"type":          action.Type,
		"storage_class": action.StorageClass,
	}
}

func flattenLifecycleRuleCondition(index int, d *schema.ResourceData, condition *storage.BucketLifecycleRuleCondition) map[string]interface{} {
	ruleCondition := map[string]interface{}{
		"created_before":             condition.CreatedBefore,
		"matches_storage_class":      tpgresource.ConvertStringArrToInterface(condition.MatchesStorageClass),
		"num_newer_versions":         int(condition.NumNewerVersions),
		"custom_time_before":         condition.CustomTimeBefore,
		"days_since_custom_time":     int(condition.DaysSinceCustomTime),
		"days_since_noncurrent_time": int(condition.DaysSinceNoncurrentTime),
		"noncurrent_time_before":     condition.NoncurrentTimeBefore,
		"matches_prefix":             tpgresource.ConvertStringArrToInterface(condition.MatchesPrefix),
		"matches_suffix":             tpgresource.ConvertStringArrToInterface(condition.MatchesSuffix),
	}
	if condition.Age != nil {
		ruleCondition["age"] = int(*condition.Age)
	}
	if condition.IsLive == nil {
		ruleCondition["with_state"] = "ANY"
	} else {
		if *condition.IsLive {
			ruleCondition["with_state"] = "LIVE"
		} else {
			ruleCondition["with_state"] = "ARCHIVED"
		}
	}
	// Setting the lifecycle condition virtual fields from the state file if they
	// are already present otherwise setting them to individual default values.
	if v, ok := d.GetOk(fmt.Sprintf("lifecycle_rule.%d.condition", index)); ok {
		state_condition := v.(*schema.Set).List()[0].(map[string]interface{})
		ruleCondition["send_days_since_noncurrent_time_if_zero"] = state_condition["send_days_since_noncurrent_time_if_zero"].(bool)
		ruleCondition["send_days_since_custom_time_if_zero"] = state_condition["send_days_since_custom_time_if_zero"].(bool)
		ruleCondition["send_num_newer_versions_if_zero"] = state_condition["send_num_newer_versions_if_zero"].(bool)
		ruleCondition["send_age_if_zero"] = state_condition["send_age_if_zero"].(bool)
	} else {
		ruleCondition["send_age_if_zero"] = false
		ruleCondition["send_days_since_noncurrent_time_if_zero"] = false
		ruleCondition["send_days_since_custom_time_if_zero"] = false
		ruleCondition["send_num_newer_versions_if_zero"] = false
	}

	return ruleCondition
}

func resourceLifecycleRuleActionHash(v interface{}) int {
	if v == nil {
		return 0
	}

	var buf bytes.Buffer
	m := v.(map[string]interface{})

	buf.WriteString(fmt.Sprintf("%s-", m["type"].(string)))

	if v, ok := m["storage_class"]; ok {
		buf.WriteString(fmt.Sprintf("%s-", v.(string)))
	}

	return tpgresource.Hashcode(buf.String())
}

func resourceLifecycleRuleConditionHash(v interface{}) int {
	if v == nil {
		return 0
	}

	var buf bytes.Buffer
	m := v.(map[string]interface{})

	if v, ok := m["age"]; ok {
		buf.WriteString(fmt.Sprintf("%d-", v.(int)))
	}

	if v, ok := m["days_since_custom_time"]; ok {
		buf.WriteString(fmt.Sprintf("%d-", v.(int)))
	}

	if v, ok := m["days_since_noncurrent_time"]; ok {
		buf.WriteString(fmt.Sprintf("%d-", v.(int)))
	}

	if v, ok := m["created_before"]; ok {
		buf.WriteString(fmt.Sprintf("%s-", v.(string)))
	}

	if v, ok := m["custom_time_before"]; ok {
		buf.WriteString(fmt.Sprintf("%s-", v.(string)))
	}

	if v, ok := m["noncurrent_time_before"]; ok {
		buf.WriteString(fmt.Sprintf("%s-", v.(string)))
	}

	withStateV, withStateOk := m["with_state"]
	if withStateOk {
		switch withStateV.(string) {
		case "LIVE":
			buf.WriteString(fmt.Sprintf("%t-", true))
		case "ARCHIVED":
			buf.WriteString(fmt.Sprintf("%t-", false))
		}
	}

	if v, ok := m["matches_storage_class"]; ok {
		matches_storage_classes := v.([]interface{})
		for _, matches_storage_class := range matches_storage_classes {
			buf.WriteString(fmt.Sprintf("%s-", matches_storage_class))
		}
	}

	if v, ok := m["num_newer_versions"]; ok {
		buf.WriteString(fmt.Sprintf("%d-", v.(int)))
	}

	if v, ok := m["send_age_if_zero"]; ok {
		buf.WriteString(fmt.Sprintf("%t-", v.(bool)))
	}

	if v, ok := m["send_days_since_noncurrent_time_if_zero"]; ok {
		buf.WriteString(fmt.Sprintf("%t-", v.(bool)))
	}

	if v, ok := m["send_days_since_custom_time_if_zero"]; ok {
		buf.WriteString(fmt.Sprintf("%t-", v.(bool)))
	}

	if v, ok := m["send_num_newer_versions_if_zero"]; ok {
		buf.WriteString(fmt.Sprintf("%t-", v.(bool)))
	}

	if v, ok := m["matches_prefix"]; ok {
		matches_prefixes := v.([]interface{})
		for _, matches_prefix := range matches_prefixes {
			buf.WriteString(fmt.Sprintf("%s-", matches_prefix))
		}
	}
	if v, ok := m["matches_suffix"]; ok {
		matches_suffixes := v.([]interface{})
		for _, matches_suffix := range matches_suffixes {
			buf.WriteString(fmt.Sprintf("%s-", matches_suffix))
		}
	}

	return tpgresource.Hashcode(buf.String())
}
