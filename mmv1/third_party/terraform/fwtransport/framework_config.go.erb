<% autogen_exception -%>
package fwtransport

import (
	"context"
	"fmt"
	"net/http"
	"os"
	"strconv"
	"time"

	"golang.org/x/oauth2"
	googleoauth "golang.org/x/oauth2/google"

	"google.golang.org/api/option"
	"google.golang.org/api/transport"
	"google.golang.org/grpc"

	"github.com/hashicorp/go-cleanhttp"
	"github.com/hashicorp/terraform-plugin-framework/attr"
	"github.com/hashicorp/terraform-plugin-framework/diag"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-log/tflog"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/logging"

	"github.com/hashicorp/terraform-provider-google/google/fwmodels"
	transport_tpg "github.com/hashicorp/terraform-provider-google/google/transport"
	"github.com/hashicorp/terraform-provider-google/google/verify"

	grpc_logrus "github.com/grpc-ecosystem/go-grpc-middleware/logging/logrus"
	"github.com/sirupsen/logrus"
)

type FrameworkProviderConfig struct {
	BillingProject             types.String
	Client                     *http.Client
	Context                    context.Context
	gRPCLoggingOptions         []option.ClientOption
	PollInterval               time.Duration
	Project                    types.String
	Region                     types.String
	Zone                       types.String
	RequestBatcherIam          *transport_tpg.RequestBatcher
	RequestBatcherServiceUsage *transport_tpg.RequestBatcher
	Scopes                     types.List
	TokenSource                oauth2.TokenSource
	UserAgent                  string
	UserProjectOverride        types.Bool

	// paths for client setup
	<% products.each do |product| -%>
	<%= product[:definitions].name -%>BasePath string
	<% end -%>
}

// LoadAndValidateFramework handles the bulk of configuring the provider
// it is pulled out so that we can manually call this from our testing provider as well
func (p *FrameworkProviderConfig) LoadAndValidateFramework(ctx context.Context, data *fwmodels.ProviderModel, tfVersion string, diags *diag.Diagnostics, providerversion string) {
	

	// Make the plugin framwork code behave like the SDK by ignoring zero values. This means re-setting zero values to null.
	// This is added to fix https://github.com/hashicorp/terraform-provider-google/issues/14255 in a v4.x.x release
	// TODO(SarahFrench) remove as part of https://github.com/hashicorp/terraform-provider-google/issues/14447 in 5.0.0
	p.HandleZeroValues(ctx, data, diags)
	if diags.HasError() {
		return
	}

	// Set defaults if needed
	p.HandleDefaults(ctx, data, diags)
	if diags.HasError() {
		return
	}

	p.Context = ctx

	// Handle User Agent string
	p.UserAgent = CompileUserAgentString(ctx, "terraform-provider-google<%= "-" + version unless version == 'ga'  -%>", tfVersion, providerversion)
	// opt in extension for adding to the User-Agent header
	if ext := os.Getenv("GOOGLE_TERRAFORM_USERAGENT_EXTENSION"); ext != "" {
		ua := p.UserAgent
		p.UserAgent = fmt.Sprintf("%s %s", ua, ext)
	}

	// Set up client configuration
	p.SetupClient(ctx, *data, diags)
	if diags.HasError() {
		return
	}

	// gRPC Logging setup
	p.SetupGrpcLogging()

	// Handle Batching Config
	batchingConfig := GetBatchingConfig(ctx, data.Batching, diags)
	if diags.HasError() {
		return
	}

	// Setup Base Paths for clients
	// Generated products
	<% products.map.each do |product| -%>
	p.<%= product[:definitions].name -%>BasePath = data.<%= product[:definitions].name -%>CustomEndpoint.ValueString()
	<% end -%>

	p.Context = ctx
	p.BillingProject = data.BillingProject
	p.Project = data.Project
	p.Region = data.Region
	p.Scopes = data.Scopes
	p.Zone = data.Zone
	p.UserProjectOverride = data.UserProjectOverride
	p.PollInterval = 10 * time.Second
	p.RequestBatcherServiceUsage = transport_tpg.NewRequestBatcher("Service Usage", ctx, batchingConfig)
	p.RequestBatcherIam = transport_tpg.NewRequestBatcher("IAM", ctx, batchingConfig)
}

// HandleZeroValues will make the plugin framework act like the SDK; zero value, particularly empty strings, are converted to null.
// This causes the plugin framework to treat the field as unset, just like how the SDK ignores empty strings.
func (p *FrameworkProviderConfig) HandleZeroValues(ctx context.Context, data *fwmodels.ProviderModel, diags *diag.Diagnostics) {

	// Change empty strings to null values
	if data.AccessToken.Equal(types.StringValue("")) {
		data.AccessToken = types.StringNull()
	}
	if data.BillingProject.Equal(types.StringValue("")) {
		data.BillingProject = types.StringNull()
	}
	if data.Credentials.Equal(types.StringValue("")) {
		data.Credentials = types.StringNull()
	}
	if data.ImpersonateServiceAccount.Equal(types.StringValue("")) {
		data.ImpersonateServiceAccount = types.StringNull()
	}
	if data.Project.Equal(types.StringValue("")) {
		data.Project = types.StringNull()
	}
	if data.Region.Equal(types.StringValue("")) {
		data.Region = types.StringNull()
	}
	if data.RequestReason.Equal(types.StringValue("")) {
		data.RequestReason = types.StringNull()
	}
	if data.RequestTimeout.Equal(types.StringValue("")) {
		data.RequestTimeout = types.StringNull()
	}
	if data.Zone.Equal(types.StringValue("")) {
		data.Zone = types.StringNull()
	}

	// Change lists that aren't null or unknown with length of zero to null lists
	if !data.Scopes.IsNull() && !data.Scopes.IsUnknown() && (len(data.Scopes.Elements()) == 0) {
		data.Scopes = types.ListNull(types.StringType)
	}
	if !data.ImpersonateServiceAccountDelegates.IsNull() && !data.ImpersonateServiceAccountDelegates.IsUnknown() && (len(data.ImpersonateServiceAccountDelegates.Elements()) == 0) {
		data.ImpersonateServiceAccountDelegates = types.ListNull(types.StringType)
	}

	// Batching implementation will change in future, but this code will be removed in 5.0.0 so may be unaffected
	if !data.Batching.IsNull() && !data.Batching.IsUnknown() && (len(data.Batching.Elements()) > 0) {
		var pbConfigs []fwmodels.ProviderBatching
		d := data.Batching.ElementsAs(ctx, &pbConfigs, true)
		diags.Append(d...)
		if diags.HasError() {
			return
		}
		if pbConfigs[0].SendAfter.Equal(types.StringValue("")) {
			pbConfigs[0].SendAfter = types.StringNull() // Convert empty string to null
		}
		b, _ := types.ObjectValue(
			map[string]attr.Type{
				"enable_batching": types.BoolType,
				"send_after":      types.StringType,
			},
			map[string]attr.Value{
				"enable_batching": pbConfigs[0].EnableBatching,
				"send_after":      pbConfigs[0].SendAfter,
			},
		)
		newBatching, d := types.ListValue(types.ObjectType{}.WithAttributeTypes(fwmodels.ProviderBatchingAttributes), []attr.Value{b})
		diags.Append(d...)
		if diags.HasError() {
			return
		}
		data.Batching = newBatching
	}
}

// HandleDefaults will handle all the defaults necessary in the provider
func (p *FrameworkProviderConfig) HandleDefaults(ctx context.Context, data *fwmodels.ProviderModel, diags *diag.Diagnostics) {
	if (data.AccessToken.IsNull() || data.AccessToken.IsUnknown()) && (data.Credentials.IsNull() || data.Credentials.IsUnknown()) {
		credentials := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_CREDENTIALS",
			"GOOGLE_CLOUD_KEYFILE_JSON",
			"GCLOUD_KEYFILE_JSON",
		}, nil)

		if credentials != nil {
			data.Credentials = types.StringValue(credentials.(string))
		}

		accessToken := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_OAUTH_ACCESS_TOKEN",
		}, nil)

		if accessToken != nil {
			data.AccessToken = types.StringValue(accessToken.(string))
		}
	}

	if (data.ImpersonateServiceAccount.IsNull() || data.ImpersonateServiceAccount.IsUnknown()) && os.Getenv("GOOGLE_IMPERSONATE_SERVICE_ACCOUNT") != "" {
		data.ImpersonateServiceAccount = types.StringValue(os.Getenv("GOOGLE_IMPERSONATE_SERVICE_ACCOUNT"))
	}

	if data.Project.IsNull() || data.Project.IsUnknown() {
		project := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_PROJECT",
			"GOOGLE_CLOUD_PROJECT",
			"GCLOUD_PROJECT",
			"CLOUDSDK_CORE_PROJECT",
		}, nil)
		if project != nil {
			data.Project = types.StringValue(project.(string))
		}
	}

	if data.BillingProject.IsNull() && os.Getenv("GOOGLE_BILLING_PROJECT") != "" {
		data.BillingProject = types.StringValue(os.Getenv("GOOGLE_BILLING_PROJECT"))
	}

	if data.Region.IsNull() || data.Region.IsUnknown() {
		region := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_REGION",
			"GCLOUD_REGION",
			"CLOUDSDK_COMPUTE_REGION",
		}, nil)

		if region != nil {
			data.Region = types.StringValue(region.(string))
		}
	}

	if data.Zone.IsNull() || data.Zone.IsUnknown() {
		zone := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_ZONE",
			"GCLOUD_ZONE",
			"CLOUDSDK_COMPUTE_ZONE",
		}, nil)

		if zone != nil {
			data.Zone = types.StringValue(zone.(string))
		}
	}

	if len(data.Scopes.Elements()) == 0 {
		var d diag.Diagnostics
		data.Scopes, d = types.ListValueFrom(ctx, types.StringType, transport_tpg.DefaultClientScopes)
		diags.Append(d...)
		if diags.HasError() {
			return
		}
	}

	if !data.Batching.IsNull() && !data.Batching.IsUnknown() {
		var pbConfigs []fwmodels.ProviderBatching
		d := data.Batching.ElementsAs(ctx, &pbConfigs, true)
		diags.Append(d...)
		if diags.HasError() {
			return
		}

		if pbConfigs[0].SendAfter.IsNull() || pbConfigs[0].SendAfter.IsUnknown() {
			pbConfigs[0].SendAfter = types.StringValue("10s")
		}

		if pbConfigs[0].EnableBatching.IsNull() || pbConfigs[0].EnableBatching.IsUnknown() {
			pbConfigs[0].EnableBatching = types.BoolValue(true)
		}

		data.Batching, d = types.ListValueFrom(ctx, types.ObjectType{}.WithAttributeTypes(fwmodels.ProviderBatchingAttributes), pbConfigs)
	}

	if (data.UserProjectOverride.IsNull() || data.UserProjectOverride.IsUnknown()) && os.Getenv("USER_PROJECT_OVERRIDE") != "" {
		override, err := strconv.ParseBool(os.Getenv("USER_PROJECT_OVERRIDE"))
		if err != nil {
			diags.AddError(
				"error parsing environment variable `USER_PROJECT_OVERRIDE` into bool", err.Error())
		}
		data.UserProjectOverride = types.BoolValue(override)
	}

	if (data.RequestReason.IsNull() || data.RequestReason.IsUnknown()) && os.Getenv("CLOUDSDK_CORE_REQUEST_REASON") != "" {
		data.RequestReason = types.StringValue(os.Getenv("CLOUDSDK_CORE_REQUEST_REASON"))
	}

	if data.RequestTimeout.IsNull() || data.RequestTimeout.IsUnknown() {
		data.RequestTimeout = types.StringValue("120s")
	}

	// Generated Products
<% products.each do |product| -%>
	if data.<%= product[:definitions].name -%>CustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_<%= product[:definitions].name.underscore.upcase -%>_CUSTOM_ENDPOINT",
		}, transport_tpg.DefaultBasePaths[transport_tpg.<%= product[:definitions].name -%>BasePathKey])
		if customEndpoint != nil {
			data.<%= product[:definitions].name -%>CustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}
<% end -%>

	// Handwritten Products / Versioned / Atypical Entries
	if data.CloudBillingCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_CLOUD_BILLING_CUSTOM_ENDPOINT",
		}, transport_tpg.DefaultBasePaths["cloud_billing_custom_endpoint"])
		if customEndpoint != nil {
			data.CloudBillingCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.ComposerCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_COMPOSER_CUSTOM_ENDPOINT",
		}, transport_tpg.DefaultBasePaths[transport_tpg.ComposerBasePathKey])
		if customEndpoint != nil {
			data.ComposerCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.ContainerCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_CONTAINER_CUSTOM_ENDPOINT",
		}, transport_tpg.DefaultBasePaths[transport_tpg.ContainerBasePathKey])
		if customEndpoint != nil {
			data.ContainerCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.DataflowCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_DATAFLOW_CUSTOM_ENDPOINT",
		}, transport_tpg.DefaultBasePaths[transport_tpg.DataflowBasePathKey])
		if customEndpoint != nil {
			data.DataflowCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.IamCredentialsCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_IAM_CREDENTIALS_CUSTOM_ENDPOINT",
		}, transport_tpg.DefaultBasePaths[transport_tpg.IamCredentialsBasePathKey])
		if customEndpoint != nil {
			data.IamCredentialsCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.ResourceManagerV3CustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_RESOURCE_MANAGER_V3_CUSTOM_ENDPOINT",
		}, transport_tpg.DefaultBasePaths[transport_tpg.ResourceManagerV3BasePathKey])
		if customEndpoint != nil {
			data.ResourceManagerV3CustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

<% unless version == 'ga' -%>
	if data.RuntimeConfigCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_RUNTIMECONFIG_CUSTOM_ENDPOINT",
		}, transport_tpg.DefaultBasePaths[transport_tpg.RuntimeConfigBasePathKey])
		if customEndpoint != nil {
			data.RuntimeConfigCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}
<% end -%>

	if data.IAMCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_IAM_CUSTOM_ENDPOINT",
		}, transport_tpg.DefaultBasePaths[transport_tpg.IAMBasePathKey])
		if customEndpoint != nil {
			data.IAMCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.ServiceNetworkingCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_SERVICE_NETWORKING_CUSTOM_ENDPOINT",
		}, transport_tpg.DefaultBasePaths[transport_tpg.ServiceNetworkingBasePathKey])
		if customEndpoint != nil {
			data.ServiceNetworkingCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.TagsLocationCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_TAGS_LOCATION_CUSTOM_ENDPOINT",
		}, transport_tpg.DefaultBasePaths[transport_tpg.TagsLocationBasePathKey])
		if customEndpoint != nil {
			data.TagsLocationCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	// dcl
	if data.ContainerAwsCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_CONTAINERAWS_CUSTOM_ENDPOINT",
		}, transport_tpg.DefaultBasePaths[transport_tpg.ContainerAwsBasePathKey])
		if customEndpoint != nil {
			data.ContainerAwsCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.ContainerAzureCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_CONTAINERAZURE_CUSTOM_ENDPOINT",
		}, transport_tpg.DefaultBasePaths[transport_tpg.ContainerAzureBasePathKey])
		if customEndpoint != nil {
			data.ContainerAzureCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	// DCL generated defaults
	if data.ApikeysCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_APIKEYS_CUSTOM_ENDPOINT",
		}, "")
		if customEndpoint != nil {
			data.ApikeysCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.AssuredWorkloadsCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_ASSURED_WORKLOADS_CUSTOM_ENDPOINT",
		}, "")
		if customEndpoint != nil {
			data.AssuredWorkloadsCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.CloudBuildWorkerPoolCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_CLOUD_BUILD_WORKER_POOL_CUSTOM_ENDPOINT",
		}, "")
		if customEndpoint != nil {
			data.CloudBuildWorkerPoolCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.CloudDeployCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_CLOUDDEPLOY_CUSTOM_ENDPOINT",
		}, "")
		if customEndpoint != nil {
			data.CloudDeployCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.CloudResourceManagerCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_CLOUD_RESOURCE_MANAGER_CUSTOM_ENDPOINT",
		}, "")
		if customEndpoint != nil {
			data.CloudResourceManagerCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.DataplexCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_DATAPLEX_CUSTOM_ENDPOINT",
		}, "")
		if customEndpoint != nil {
			data.DataplexCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.EventarcCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_EVENTARC_CUSTOM_ENDPOINT",
		}, "")
		if customEndpoint != nil {
			data.EventarcCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.FirebaserulesCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_FIREBASERULES_CUSTOM_ENDPOINT",
		}, "")
		if customEndpoint != nil {
			data.FirebaserulesCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.NetworkConnectivityCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_NETWORK_CONNECTIVITY_CUSTOM_ENDPOINT",
		}, "")
		if customEndpoint != nil {
			data.NetworkConnectivityCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}

	if data.RecaptchaEnterpriseCustomEndpoint.IsNull() {
		customEndpoint := transport_tpg.MultiEnvDefault([]string{
			"GOOGLE_RECAPTCHA_ENTERPRISE_CUSTOM_ENDPOINT",
		}, "")
		if customEndpoint != nil {
			data.RecaptchaEnterpriseCustomEndpoint = types.StringValue(customEndpoint.(string))
		}
	}
}

func (p *FrameworkProviderConfig) SetupClient(ctx context.Context, data fwmodels.ProviderModel, diags *diag.Diagnostics) {
	tokenSource := GetTokenSource(ctx, data, false, diags)
	if diags.HasError() {
		return
	}

	cleanCtx := context.WithValue(ctx, oauth2.HTTPClient, cleanhttp.DefaultClient())

	// 1. MTLS TRANSPORT/CLIENT - sets up proper auth headers
	client, _, err := transport.NewHTTPClient(cleanCtx, option.WithTokenSource(tokenSource))
	if err != nil {
		diags.AddError("error creating new http client", err.Error())
		return
	}

	// Userinfo is fetched before request logging is enabled to reduce additional noise.
	p.logGoogleIdentities(ctx, data, diags)
	if diags.HasError() {
		return
	}

	// 2. Logging Transport - ensure we log HTTP requests to GCP APIs.
	loggingTransport := logging.NewTransport("Google", client.Transport)

	// 3. Retry Transport - retries common temporary errors
	// Keep order for wrapping logging so we log each retried request as well.
	// This value should be used if needed to create shallow copies with additional retry predicates.
	// See ClientWithAdditionalRetries
	retryTransport := transport_tpg.NewTransportWithDefaultRetries(loggingTransport)

	// 4. Header Transport - outer wrapper to inject additional headers we want to apply
	// before making requests
	headerTransport := transport_tpg.NewTransportWithHeaders(retryTransport)
	if !data.RequestReason.IsNull() {
		headerTransport.Set("X-Goog-Request-Reason", data.RequestReason.ValueString())
	}

	// Ensure $userProject is set for all HTTP requests using the client if specified by the provider config
	// See https://cloud.google.com/apis/docs/system-parameters
	if data.UserProjectOverride.ValueBool() && !data.BillingProject.IsNull() {
		headerTransport.Set("X-Goog-User-Project", data.BillingProject.ValueString())
	}

	// Set final transport value.
	client.Transport = headerTransport

	// This timeout is a timeout per HTTP request, not per logical operation.
	timeout, err := time.ParseDuration(data.RequestTimeout.ValueString())
	if err != nil {
		diags.AddError("error parsing request timeout", err.Error())
	}
	client.Timeout = timeout

	p.TokenSource = tokenSource
	p.Client = client
}

func (p *FrameworkProviderConfig) SetupGrpcLogging() {
	logger := logrus.StandardLogger()

	logrus.SetLevel(logrus.DebugLevel)
	logrus.SetFormatter(&transport_tpg.Formatter{
		TimestampFormat: "2006/01/02 15:04:05",
		LogFormat:       "%time% [%lvl%] %msg% \n",
	})

	alwaysLoggingDeciderClient := func(ctx context.Context, fullMethodName string) bool { return true }
	grpc_logrus.ReplaceGrpcLogger(logrus.NewEntry(logger))

	p.gRPCLoggingOptions = append(
		p.gRPCLoggingOptions, option.WithGRPCDialOption(grpc.WithUnaryInterceptor(
			grpc_logrus.PayloadUnaryClientInterceptor(logrus.NewEntry(logger), alwaysLoggingDeciderClient))),
		option.WithGRPCDialOption(grpc.WithStreamInterceptor(
			grpc_logrus.PayloadStreamClientInterceptor(logrus.NewEntry(logger), alwaysLoggingDeciderClient))),
	)
}

func (p *FrameworkProviderConfig) logGoogleIdentities(ctx context.Context, data fwmodels.ProviderModel, diags *diag.Diagnostics) {
	// GetCurrentUserEmailFramework doesn't pass an error back from logGoogleIdentities, so we want
	// a separate diagnostics here
	var d diag.Diagnostics

	if data.ImpersonateServiceAccount.IsNull() || data.ImpersonateServiceAccount.IsUnknown() {

		tokenSource := GetTokenSource(ctx, data, true, diags)
		if diags.HasError() {
			return
		}

		p.Client = oauth2.NewClient(ctx, tokenSource) // p.Client isn't initialised fully when this code is called.

		email := GetCurrentUserEmailFramework(p, p.UserAgent, &d)
		if d.HasError() {
			tflog.Info(ctx, "error retrieving userinfo for your provider credentials. have you enabled the 'https://www.googleapis.com/auth/userinfo.email' scope?")
		}

		tflog.Info(ctx, fmt.Sprintf("Terraform is using this identity: %s", email))
		return
	}

	// Drop Impersonated ClientOption from OAuth2 TokenSource to infer original identity
	tokenSource := GetTokenSource(ctx, data, true, diags)
	if diags.HasError() {
		return
	}

	p.Client = oauth2.NewClient(ctx, tokenSource) // p.Client isn't initialised fully when this code is called.
	email := GetCurrentUserEmailFramework(p, p.UserAgent, &d)
	if d.HasError() {
		tflog.Info(ctx, "error retrieving userinfo for your provider credentials. have you enabled the 'https://www.googleapis.com/auth/userinfo.email' scope?")
	}

	tflog.Info(ctx, fmt.Sprintf("Terraform is configured with service account impersonation, original identity: %s, impersonated identity: %s", email, data.ImpersonateServiceAccount.ValueString()))

	// Add the Impersonated ClientOption back in to the OAuth2 TokenSource
	tokenSource = GetTokenSource(ctx, data, false, diags)
	if diags.HasError() {
		return
	}

	p.Client = oauth2.NewClient(ctx, tokenSource) // p.Client isn't initialised fully when this code is called.

	return
}

// Configuration helpers

// GetTokenSource gets token source based on the Google Credentials configured.
// If initialCredentialsOnly is true, don't follow the impersonation settings and return the initial set of creds.
func GetTokenSource(ctx context.Context, data fwmodels.ProviderModel, initialCredentialsOnly bool, diags *diag.Diagnostics) oauth2.TokenSource {
	creds := GetCredentials(ctx, data, initialCredentialsOnly, diags)

	return creds.TokenSource
}

// GetCredentials gets credentials with a given scope (clientScopes).
// If initialCredentialsOnly is true, don't follow the impersonation
// settings and return the initial set of creds instead.
func GetCredentials(ctx context.Context, data fwmodels.ProviderModel, initialCredentialsOnly bool, diags *diag.Diagnostics) googleoauth.Credentials {
	var clientScopes []string
	var delegates []string

	if !data.Scopes.IsNull() && !data.Scopes.IsUnknown() {
		d := data.Scopes.ElementsAs(ctx, &clientScopes, false)
		diags.Append(d...)
		if diags.HasError() {
			return googleoauth.Credentials{}
		}
	}

	if !data.ImpersonateServiceAccountDelegates.IsNull() && !data.ImpersonateServiceAccountDelegates.IsUnknown() {
		d := data.ImpersonateServiceAccountDelegates.ElementsAs(ctx, &delegates, false)
		diags.Append(d...)
		if diags.HasError() {
			return googleoauth.Credentials{}
		}
	}

	if !data.AccessToken.IsNull() && !data.AccessToken.IsUnknown() {
		contents, _, err := verify.PathOrContents(data.AccessToken.ValueString())
		if err != nil {
			diags.AddError("error loading access token", err.Error())
			return googleoauth.Credentials{}
		}

		token := &oauth2.Token{AccessToken: contents}
		if !data.ImpersonateServiceAccount.IsNull() && !initialCredentialsOnly {
			opts := []option.ClientOption{option.WithTokenSource(oauth2.StaticTokenSource(token)), option.ImpersonateCredentials(data.ImpersonateServiceAccount.ValueString(), delegates...), option.WithScopes(clientScopes...)}
			creds, err := transport.Creds(context.TODO(), opts...)
			if err != nil {
				diags.AddError("error impersonating credentials", err.Error())
				return googleoauth.Credentials{}
			}
			return *creds
		}

		tflog.Info(ctx, "Authenticating using configured Google JSON 'access_token'...")
		tflog.Info(ctx, fmt.Sprintf("  -- Scopes: %s", clientScopes))
		return googleoauth.Credentials{
			TokenSource: transport_tpg.StaticTokenSource{oauth2.StaticTokenSource(token)},
		}
	}

	if !data.Credentials.IsNull() && !data.Credentials.IsUnknown() {
		contents, _, err := verify.PathOrContents(data.Credentials.ValueString())
		if err != nil {
			diags.AddError(fmt.Sprintf("error loading credentials: %s", err), err.Error())
			return googleoauth.Credentials{}
		}

		if !data.ImpersonateServiceAccount.IsNull() && !initialCredentialsOnly {
			opts := []option.ClientOption{option.WithCredentialsJSON([]byte(contents)), option.ImpersonateCredentials(data.ImpersonateServiceAccount.ValueString(), delegates...), option.WithScopes(clientScopes...)}
			creds, err := transport.Creds(context.TODO(), opts...)
			if err != nil {
				diags.AddError("error impersonating credentials", err.Error())
				return googleoauth.Credentials{}
			}
			return *creds
		}

		creds, err := transport.Creds(ctx, option.WithCredentialsJSON([]byte(contents)), option.WithScopes(clientScopes...))
		if err != nil {
			diags.AddError("unable to parse credentials", err.Error())
			return googleoauth.Credentials{}
		}

		tflog.Info(ctx, "Authenticating using configured Google JSON 'credentials'...")
		tflog.Info(ctx, fmt.Sprintf("  -- Scopes: %s", clientScopes))
		return *creds
	}

	if !data.ImpersonateServiceAccount.IsNull() && !initialCredentialsOnly {
		opts := option.ImpersonateCredentials(data.ImpersonateServiceAccount.ValueString(), delegates...)
		creds, err := transport.Creds(context.TODO(), opts, option.WithScopes(clientScopes...))
		if err != nil {
			diags.AddError("error impersonating credentials", err.Error())
			return googleoauth.Credentials{}
		}

		return *creds
	}

	tflog.Info(ctx, "Authenticating using DefaultClient...")
	tflog.Info(ctx, fmt.Sprintf("  -- Scopes: %s", clientScopes))
	creds, err := transport.Creds(context.Background(), option.WithScopes(clientScopes...))
	if err != nil {
		diags.AddError(fmt.Sprintf("Attempted to load application default credentials since neither `credentials` nor `access_token` was set in the provider block.  "+
			"No credentials loaded. To use your gcloud credentials, run 'gcloud auth application-default login'"), err.Error())
		return googleoauth.Credentials{}
	}

	return *creds
}

// GetBatchingConfig returns the batching config object given the
// provider configuration set for batching
func GetBatchingConfig(ctx context.Context, data types.List, diags *diag.Diagnostics) *transport_tpg.BatchingConfig {
	bc := &transport_tpg.BatchingConfig{
		SendAfter:      time.Second * transport_tpg.DefaultBatchSendIntervalSec,
		EnableBatching: true,
	}

	// Handle if entire batching block is null/unknown
	if data.IsNull() || data.IsUnknown() {
		return bc
	}

	var pbConfigs []fwmodels.ProviderBatching
	d := data.ElementsAs(ctx, &pbConfigs, true)
	diags.Append(d...)
	if diags.HasError() {
		return bc
	}

	sendAfter, err := time.ParseDuration(pbConfigs[0].SendAfter.ValueString())
	if err != nil {
		diags.AddError("error parsing send after time duration", err.Error())
		return bc
	}

	bc.SendAfter = sendAfter

	if !pbConfigs[0].EnableBatching.IsNull() {
		bc.EnableBatching = pbConfigs[0].EnableBatching.ValueBool()
	}

	return bc
}
