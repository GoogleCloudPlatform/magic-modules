<% autogen_exception -%>
package google
<% unless version == 'ga' -%>

import (
	"fmt"
	"regexp"
	"strings"
	"testing"
	"time"

	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/resource"
	"github.com/hashicorp/terraform-plugin-sdk/v2/terraform"

<% if version == "ga" -%>
	"google.golang.org/api/compute/v1"
<% else -%>
	compute "google.golang.org/api/compute/v0.beta"
<% end -%>
)

func TestAccDataflowFlexTemplateJob_basic(t *testing.T) {
	// This resource uses custom retry logic that cannot be sped up without
	// modifying the actual resource
	skipIfVcr(t)
	t.Parallel()

	randStr := randString(t, 10)
	job := "tf-test-dataflow-job-" + randStr

	vcrTest(t, resource.TestCase{
		PreCheck:     func() { testAccPreCheck(t) },
		Providers:    testAccProviders,
		CheckDestroy: testAccCheckDataflowJobDestroyProducer(t),
		Steps: []resource.TestStep{
			{
				Config: testAccDataflowFlexTemplateJob_basic(job, "mytopic"),
				Check: resource.ComposeTestCheckFunc(
					testAccDataflowJobExists(t, "google_dataflow_flex_template_job.job"),
				),
			},
		},
	})
}

func TestAccDataflowFlexTemplateJob_streamUpdate(t *testing.T) {
	// This resource uses custom retry logic that cannot be sped up without
	// modifying the actual resource
	skipIfVcr(t)
	t.Parallel()

	randStr := randString(t, 10)
	job := "tf-test-dataflow-job-" + randStr

	vcrTest(t, resource.TestCase{
		PreCheck:     func() { testAccPreCheck(t) },
		Providers:    testAccProviders,
		CheckDestroy: testAccCheckDataflowJobDestroyProducer(t),
		Steps: []resource.TestStep{
			{
				Config: testAccDataflowFlexTemplateJob_basic(job, "mytopic"),
				Check: resource.ComposeTestCheckFunc(
					testAccDataflowJobExists(t, "google_dataflow_flex_template_job.job"),
				),
			},
			{
				Config: testAccDataflowFlexTemplateJob_basic(job, "mytopic2"),
				Check: resource.ComposeTestCheckFunc(
					testAccDataflowJobHasOption(t, "google_dataflow_flex_template_job.job", "topic", "projects/myproject/topics/mytopic2"),
				),
			},
		},
	})
}

func TestAccDataflowFlexTemplateJob_streamUpdateFail(t *testing.T) {
	// This resource uses custom retry logic that cannot be sped up without
	// modifying the actual resource
	skipIfVcr(t)
	t.Parallel()

	randStr := randString(t, 10)
	job := "tf-test-dataflow-job-" + randStr

	vcrTest(t, resource.TestCase{
		PreCheck:     func() { testAccPreCheck(t) },
		Providers:    testAccProviders,
		CheckDestroy: testAccCheckDataflowJobDestroyProducer(t),
		Steps: []resource.TestStep{
			{
				Config: testAccDataflowFlexTemplateJob_basic(job, "mytopic"),
				Check: resource.ComposeTestCheckFunc(
					testAccDataflowJobExists(t, "google_dataflow_flex_template_job.job"),
				),
			},
			{
				Config: testAccDataflowFlexTemplateJob_basic(job, ""),
				Check: resource.ComposeTestCheckFunc(
					testAccDataflowJobHasOption(t, "google_dataflow_flex_template_job.job", "topic", "projects/myproject/topics/mytopic"),
				),
				ExpectError: regexp.MustCompile(`Error waiting for Job with job ID "[^"]+" to be updated: the job with ID "[^"]+" has terminated with state "JOB_STATE_FAILED" instead of expected state "JOB_STATE_RUNNING"`),
			},
		},
	})
}


func TestAccDataflowFlexTemplateJob_withServiceAccount(t *testing.T) {
	// Dataflow responses include serialized java classes and bash commands
	// This makes body comparison infeasible
	skipIfVcr(t)
	t.Parallel()

	randStr := randString(t, 10)
	job := "tf-test-dataflow-job-" + randStr
	accountId := "tf-test-dataflow-sa" + randStr

	vcrTest(t, resource.TestCase{
		PreCheck:     func() { testAccPreCheck(t) },
		Providers:    testAccProviders,
		CheckDestroy: testAccCheckDataflowJobDestroyProducer(t),
		Steps: []resource.TestStep{
			{
				Config: testAccDataflowFlexTemplateJob_serviceAccount(job, accountId),
				Check: resource.ComposeTestCheckFunc(
					testAccDataflowJobExists(t, "google_dataflow_flex_template_job.job"),
					testAccDataflowFlexTemplateJobHasServiceAccount(t, "google_dataflow_flex_template_job.job", accountId),
				),
			},
		},
	})
}

func TestAccDataflowFlexTemplateJob_withNetwork(t *testing.T) {
	// Dataflow responses include serialized java classes and bash commands
	// This makes body comparison infeasible
	skipIfVcr(t)
	t.Parallel()

	randStr := randString(t, 10)
	job := "tf-test-dataflow-job-" + randStr
	network := "tf-test-dataflow-net" + randStr

	vcrTest(t, resource.TestCase{
		PreCheck:     func() { testAccPreCheck(t) },
		Providers:    testAccProviders,
		CheckDestroy: testAccCheckDataflowJobDestroyProducer(t),
		Steps: []resource.TestStep{
			{
				Config: testAccDataflowFlexTemplateJob_network(job, network),
				Check: resource.ComposeTestCheckFunc(
					testAccDataflowJobExists(t, "google_dataflow_flex_template_job.job"),
					testAccDataflowFlexTemplateJobHasNetwork(t, "google_dataflow_flex_template_job.job", network),
				),
			},
		},
	})
}

func TestAccDataflowFlexTemplateJob_withSubNetwork(t *testing.T) {
	// Dataflow responses include serialized java classes and bash commands
	// This makes body comparison infeasible
	skipIfVcr(t)
	t.Parallel()

	randStr := randString(t, 10)
	job := "tf-test-dataflow-job-" + randStr
	network := "tf-test-dataflow-net" + randStr
	subnetwork := "tf-test-dataflow-subnetwork" + randStr

	vcrTest(t, resource.TestCase{
		PreCheck:     func() { testAccPreCheck(t) },
		Providers:    testAccProviders,
		CheckDestroy: testAccCheckDataflowJobDestroyProducer(t),
		Steps: []resource.TestStep{
			{
				Config: testAccDataflowFlexTemplateJob_subnetwork(job, network, subnetwork),
				Check: resource.ComposeTestCheckFunc(
					testAccDataflowJobExists(t, "google_dataflow_flex_template_job.job"),
					testAccDataflowFlexTemplateJobHasSubNetwork(t, "google_dataflow_flex_template_job.job", subnetwork),
				),
			},
		},
	})
}

func TestAccDataflowFlexTemplateJob_withIpConfig(t *testing.T) {
	// Dataflow responses include serialized java classes and bash commands
	// This makes body comparison infeasible
	skipIfVcr(t)
	t.Parallel()

	randStr := randString(t, 10)
	job := "tf-test-dataflow-job-" + randStr

	vcrTest(t, resource.TestCase{
		PreCheck:     func() { testAccPreCheck(t) },
		Providers:    testAccProviders,
		CheckDestroy: testAccCheckDataflowJobDestroyProducer(t),
		Steps: []resource.TestStep{
			{
				Config: testAccDataflowFlexTemplateJob_ipConfig(job),
				Check: resource.ComposeTestCheckFunc(
					testAccDataflowJobExists(t, "google_dataflow_flex_template_job.job"),
				),
			},
		},
	})
}

func TestAccDataflowFlexTemplateJob_withLabels(t *testing.T) {
	// Dataflow responses include serialized java classes and bash commands
	// This makes body comparison infeasible
	skipIfVcr(t)
	t.Parallel()

	randStr := randString(t, 10)
	job := "tf-test-dataflow-job-" + randStr
	key := "my-label"
	value := "my-value"

	vcrTest(t, resource.TestCase{
		PreCheck:     func() { testAccPreCheck(t) },
		Providers:    testAccProviders,
		CheckDestroy: testAccCheckDataflowJobDestroyProducer(t),
		Steps: []resource.TestStep{
			{
				Config: testAccDataflowFlexTemplateJob_labels(job, key, value),
				Check: resource.ComposeTestCheckFunc(
					testAccDataflowJobExists(t, "google_dataflow_flex_template_job.job"),
					testAccDataflowFlexTemplateJobHasLabels(t, "google_dataflow_flex_template_job.job", key),
				),
			},
		},
	})
}

func TestAccDataflowFlexTemplateJob_withKmsKey(t *testing.T) {
	// Dataflow responses include serialized java classes and bash commands
	// This makes body comparison infeasible
	skipIfVcr(t)
	t.Parallel()

	randStr := randString(t, 10)
	job := "tf-test-dataflow-job-" + randStr
	key_ring := "tf-test-dataflow-kms-ring-" + randStr
	crypto_key := "tf-test-dataflow-kms-key-" + randStr

	vcrTest(t, resource.TestCase{
		PreCheck:     func() { testAccPreCheck(t) },
		Providers:    testAccProviders,
		CheckDestroy: testAccCheckDataflowJobDestroyProducer(t),
		Steps: []resource.TestStep{
			{
				Config: testAccDataflowFlexTemplateJob_kms(job, key_ring, crypto_key),
				Check: resource.ComposeTestCheckFunc(
					testAccDataflowJobExists(t, "google_dataflow_flex_template_job.job"),
				),
			},
		},
	})
}


func TestAccDataflowFlexTemplateJob_withAdditionalExperiments(t *testing.T) {
	// Dataflow responses include serialized java classes and bash commands
	// This makes body comparison infeasible
	skipIfVcr(t)
	t.Parallel()

	randStr := randString(t, 10)
	job := "tf-test-dataflow-job-" + randStr
	additionalExperiments := []string{"enable_stackdriver_agent_metrics", "shuffle_mode=service"}

	vcrTest(t, resource.TestCase{
		PreCheck:     func() { testAccPreCheck(t) },
		Providers:    testAccProviders,
		CheckDestroy: testAccCheckDataflowJobDestroyProducer(t),
		Steps: []resource.TestStep{
			{
				Config: testAccDataflowFlexTemplateJob_additionalExperiments(job, additionalExperiments),
				Check: resource.ComposeTestCheckFunc(
					testAccDataflowJobExists(t, "google_dataflow_flex_template_job.job"),
					testAccDataflowFlexTemplateJobHasAdditionalExperiments(t, "google_dataflow_flex_template_job.job", additionalExperiments),
				),
			},
		},
	})
}

func testAccDataflowFlexTemplateJobHasServiceAccount(t *testing.T, res, expectedId string) resource.TestCheckFunc {
	return func(s *terraform.State) error {
		instanceTmpl, err := testAccDataflowFlexTemplateGetGeneratedInstanceTemplate(t, s, res)
		if err != nil {
			return fmt.Errorf("Error getting dataflow job instance template: %s", err)
		}
		accounts := instanceTmpl.Properties.ServiceAccounts
		if len(accounts) != 1 {
			return fmt.Errorf("Found multiple service accounts (%d) for dataflow job %q, expected 1", len(accounts), res)
		}
		actualId := strings.Split(accounts[0].Email, "@")[0]
		if expectedId != actualId {
			return fmt.Errorf("service account mismatch, expected account ID = %q, actual email = %q", expectedId, accounts[0].Email)
		}
		return nil
	}
}

func testAccDataflowFlexTemplateJobHasNetwork(t *testing.T, res, expected string) resource.TestCheckFunc {
	return func(s *terraform.State) error {
		instanceTmpl, err := testAccDataflowFlexTemplateGetGeneratedInstanceTemplate(t, s, res)
		if err != nil {
			return fmt.Errorf("Error getting dataflow job instance template: %s", err)
		}
		if len(instanceTmpl.Properties.NetworkInterfaces) == 0 {
			return fmt.Errorf("no network interfaces in template properties: %+v", instanceTmpl.Properties)
		}
		actual := instanceTmpl.Properties.NetworkInterfaces[0].Network
		if GetResourceNameFromSelfLink(actual) != GetResourceNameFromSelfLink(expected) {
			return fmt.Errorf("network mismatch: %s != %s", actual, expected)
		}
		return nil
	}
}

func testAccDataflowFlexTemplateJobHasSubNetwork(t *testing.T, res, expected string) resource.TestCheckFunc {
	return func(s *terraform.State) error {
		instanceTmpl, err := testAccDataflowFlexTemplateGetGeneratedInstanceTemplate(t, s, res)
		if err != nil {
			return fmt.Errorf("Error getting dataflow job instance template: %s", err)
		}
		if len(instanceTmpl.Properties.NetworkInterfaces) == 0 {
			return fmt.Errorf("no network interfaces in template properties: %+v", instanceTmpl.Properties)
		}
		actual := instanceTmpl.Properties.NetworkInterfaces[0].Subnetwork
		if GetResourceNameFromSelfLink(actual) != GetResourceNameFromSelfLink(expected) {
			return fmt.Errorf("subnetwork mismatch: %s != %s", actual, expected)
		}
		return nil
	}
}

func testAccDataflowFlexTemplateJobHasAdditionalExperiments(t *testing.T, res string, experiments []string) resource.TestCheckFunc {
	return func(s *terraform.State) error {
		rs, ok := s.RootModule().Resources[res]
		if !ok {
			return fmt.Errorf("resource %q not found in state", res)
		}

		if rs.Primary.ID == "" {
			return fmt.Errorf("No ID is set")
		}
		config := googleProviderConfig(t)

		job, err := config.NewDataflowClient(config.userAgent).Projects.Jobs.Get(config.Project, rs.Primary.ID).View("JOB_VIEW_ALL").Do()
		if err != nil {
			return fmt.Errorf("dataflow job does not exist")
		}

		for _, expectedExperiment := range experiments {
			var contains = false
			for _, actualExperiment := range job.Environment.Experiments {
				if actualExperiment == expectedExperiment {
					contains = true
				}
			}
			if contains != true {
				return fmt.Errorf("Expected experiment '%s' not found in experiments", expectedExperiment)
			}
		}

		return nil
	}
}

func testAccDataflowFlexTemplateGetGeneratedInstanceTemplate(t *testing.T, s *terraform.State, res string) (*compute.InstanceTemplate, error) {
	rs, ok := s.RootModule().Resources[res]
	if !ok {
		return nil, fmt.Errorf("resource %q not in state", res)
	}
	if rs.Primary.ID == "" {
		return nil, fmt.Errorf("resource %q does not have an ID set", res)
	}
	filter := fmt.Sprintf("properties.labels.dataflow_job_id = %s", rs.Primary.ID)

	config := googleProviderConfig(t)

	var instanceTemplate *compute.InstanceTemplate

	err := resource.Retry(1*time.Minute, func() *resource.RetryError {
		instanceTemplates, rerr := config.NewComputeClient(config.userAgent).InstanceTemplates.
			List(config.Project).
			Filter(filter).
			MaxResults(2).
			Fields("items/properties").Do()
		if rerr != nil {
			return resource.NonRetryableError(rerr)
		}
		if len(instanceTemplates.Items) == 0 {
			return resource.RetryableError(fmt.Errorf("no instance template found for dataflow job %q", rs.Primary.ID))
		}
		if len(instanceTemplates.Items) > 1 {
			return resource.NonRetryableError(fmt.Errorf("Wrong number of matching instance templates for dataflow job: %s, %d", rs.Primary.ID, len(instanceTemplates.Items)))
		}
		instanceTemplate = instanceTemplates.Items[0]
		if instanceTemplate == nil || instanceTemplate.Properties == nil {
			return resource.NonRetryableError(fmt.Errorf("invalid instance template has no properties"))
		}
		return nil
	})
	if err != nil {
		return nil, err
	}
	return instanceTemplate, nil
}

// note: this config creates a job that doesn't actually do anything, but still runs
func testAccDataflowFlexTemplateJob_basic(job, topicName string) string {
	topicField := ""
	if topicName != "" {
		topicField = fmt.Sprintf("topic = \"projects/myproject/topics/%s\"", topicName)
	}
	return fmt.Sprintf(`
data "google_storage_bucket_object" "flex_template" {
  name   = "latest/flex/Streaming_Data_Generator"
  bucket = "dataflow-templates"
}
resource "google_dataflow_flex_template_job" "job" {
  name = "%s"
  container_spec_gcs_path = "gs://${data.google_storage_bucket_object.flex_template.bucket}/${data.google_storage_bucket_object.flex_template.name}"
  on_delete = "cancel"
  parameters = {
    schemaLocation = "gs://mybucket/schema.json"
    qps = "1"
    %s
  }
  labels = {
   "my_labels" = "value"
  }
}
`, job, topicField)
}

// note: this config creates a job that doesn't actually do anything, but still runs
func testAccDataflowFlexTemplateJob_serviceAccount(job, accountId string) string {
	return fmt.Sprintf(`
data "google_project" "project" {}

resource "google_service_account" "dataflow-sa" {
  account_id   = "%s"
  display_name = "DataFlow Service Account"
}
resource "google_project_iam_member" "dataflow-worker" {
  project = data.google_project.project.project_id
  role   = "roles/dataflow.worker"
  member = "serviceAccount:${google_service_account.dataflow-sa.email}"
}
data "google_storage_bucket_object" "flex_template" {
  name   = "latest/flex/Streaming_Data_Generator"
  bucket = "dataflow-templates"
}
resource "google_dataflow_flex_template_job" "job" {
  name = "%s"
  container_spec_gcs_path = "gs://${data.google_storage_bucket_object.flex_template.bucket}/${data.google_storage_bucket_object.flex_template.name}"
  on_delete = "cancel"
  parameters = {
    schemaLocation = "gs://mybucket/schema.json"
    qps = "1"
    topic = "projects/myproject/topics/mytopic"
  }
  labels = {
   "my_labels" = "value"
  }
  service_account_email = google_service_account.dataflow-sa.email

}
`, accountId, job)
}

// note: this config creates a job that doesn't actually do anything, but still runs
func testAccDataflowFlexTemplateJob_network(job, network string) string {
	return fmt.Sprintf(`
data "google_project" "project" {}

resource "google_compute_network" "net" {
  name                    = "%s"
  auto_create_subnetworks = true
}

data "google_storage_bucket_object" "flex_template" {
  name   = "latest/flex/Streaming_Data_Generator"
  bucket = "dataflow-templates"
}
resource "google_dataflow_flex_template_job" "job" {
  name = "%s"
  container_spec_gcs_path = "gs://${data.google_storage_bucket_object.flex_template.bucket}/${data.google_storage_bucket_object.flex_template.name}"
  on_delete = "cancel"
  parameters = {
    schemaLocation = "gs://mybucket/schema.json"
    qps = "1"
    topic = "projects/myproject/topics/mytopic"
  }
  labels = {
   "my_labels" = "value"
  }
  network           = google_compute_network.net.name

}
`, network, job)
}

// note: this config creates a job that doesn't actually do anything, but still runs
func testAccDataflowFlexTemplateJob_subnetwork(job, network, subnetwork string) string {
	return fmt.Sprintf(`
data "google_project" "project" {}

resource "google_compute_network" "net" {
  name                    = "%s"
  auto_create_subnetworks = false
}

resource "google_compute_subnetwork" "subnet" {
  name          = "%s"
  ip_cidr_range = "10.2.0.0/16"
  network       = google_compute_network.net.self_link
}

data "google_storage_bucket_object" "flex_template" {
  name   = "latest/flex/Streaming_Data_Generator"
  bucket = "dataflow-templates"
}
resource "google_dataflow_flex_template_job" "job" {
  name = "%s"
  container_spec_gcs_path = "gs://${data.google_storage_bucket_object.flex_template.bucket}/${data.google_storage_bucket_object.flex_template.name}"
  on_delete = "cancel"
  parameters = {
    schemaLocation = "gs://mybucket/schema.json"
    qps = "1"
    topic = "projects/myproject/topics/mytopic"
  }
  labels = {
   "my_labels" = "value"
  }
  subnetwork        = google_compute_subnetwork.subnet.self_link

}
`, network, subnetwork, job)
}

// note: this config creates a job that doesn't actually do anything, but still runs
func testAccDataflowFlexTemplateJob_ipConfig(job string) string {
	return fmt.Sprintf(`
data "google_project" "project" {}

data "google_storage_bucket_object" "flex_template" {
  name   = "latest/flex/Streaming_Data_Generator"
  bucket = "dataflow-templates"
}
resource "google_dataflow_flex_template_job" "job" {
  name = "%s"
  container_spec_gcs_path = "gs://${data.google_storage_bucket_object.flex_template.bucket}/${data.google_storage_bucket_object.flex_template.name}"
  on_delete = "cancel"
  parameters = {
    schemaLocation = "gs://mybucket/schema.json"
    qps = "1"
    topic = "projects/myproject/topics/mytopic"
  }
  labels = {
   "my_labels" = "value"
  }
  ip_configuration = "WORKER_IP_PRIVATE"

}
`, job)
}

// note: this config creates a job that doesn't actually do anything, but still runs
func testAccDataflowFlexTemplateJob_kms(job, key_ring, crypto_key string) string {
	return fmt.Sprintf(`
data "google_project" "project" {}

resource "google_project_iam_member" "kms-project-dataflow-binding" {
  project = data.google_project.project.project_id
  role    = "roles/cloudkms.cryptoKeyEncrypterDecrypter"
  member  = "serviceAccount:service-${data.google_project.project.number}@dataflow-service-producer-prod.iam.gserviceaccount.com"
}

resource "google_project_iam_member" "kms-project-compute-binding" {
  project = data.google_project.project.project_id
  role    = "roles/cloudkms.cryptoKeyEncrypterDecrypter"
  member  = "serviceAccount:service-${data.google_project.project.number}@compute-system.iam.gserviceaccount.com"
}

resource "google_kms_key_ring" "keyring" {
  name     = "%s"
  location = "global"
}

resource "google_kms_crypto_key" "crypto_key" {
  name            = "%s"
  key_ring        = google_kms_key_ring.keyring.id
  rotation_period = "100000s"
}

data "google_storage_bucket_object" "flex_template" {
  name   = "latest/flex/Streaming_Data_Generator"
  bucket = "dataflow-templates"
}
resource "google_dataflow_flex_template_job" "job" {
  name = "%s"
  container_spec_gcs_path = "gs://${data.google_storage_bucket_object.flex_template.bucket}/${data.google_storage_bucket_object.flex_template.name}"
  on_delete = "cancel"
  parameters = {
    schemaLocation = "gs://mybucket/schema.json"
    qps = "1"
    topic = "projects/myproject/topics/mytopic"
  }
  labels = {
   "my_labels" = "value"
  }
  kms_key_name		= google_kms_crypto_key.crypto_key.id

}
`, key_ring, crypto_key, job)
}

// note: this config creates a job that doesn't actually do anything, but still runs
func testAccDataflowFlexTemplateJob_labels(job, key, value string) string {
	return fmt.Sprintf(`
data "google_project" "project" {}

data "google_storage_bucket_object" "flex_template" {
  name   = "latest/flex/Streaming_Data_Generator"
  bucket = "dataflow-templates"
}
resource "google_dataflow_flex_template_job" "job" {
  name = "%s"
  container_spec_gcs_path = "gs://${data.google_storage_bucket_object.flex_template.bucket}/${data.google_storage_bucket_object.flex_template.name}"
  on_delete = "cancel"
  parameters = {
    schemaLocation = "gs://mybucket/schema.json"
    qps = "1"
    topic = "projects/myproject/topics/mytopic"
  }
  labels = {
   "%s" = "%s"
  }

}
`, job, key, value)
}

// note: this config creates a job that doesn't actually do anything, but still runs
func testAccDataflowFlexTemplateJob_additionalExperiments(job string, experiments []string) string {
	return fmt.Sprintf(`
data "google_project" "project" {}

data "google_storage_bucket_object" "flex_template" {
  name   = "latest/flex/Streaming_Data_Generator"
  bucket = "dataflow-templates"
}
resource "google_dataflow_flex_template_job" "job" {
  name = "%s"
  container_spec_gcs_path = "gs://${data.google_storage_bucket_object.flex_template.bucket}/${data.google_storage_bucket_object.flex_template.name}"
  on_delete = "cancel"
  parameters = {
    schemaLocation = "gs://mybucket/schema.json"
    qps = "1"
    topic = "projects/myproject/topics/mytopic"
  }
  labels = {
   "my_labels" = "value"
  }
  additional_experiments = ["%s"]

}
`, job, strings.Join(experiments, `", "`))
}

func testAccDataflowJobHasOption(t *testing.T, res, option, expectedValue string) resource.TestCheckFunc {
	return func(s *terraform.State) error {
		rs, ok := s.RootModule().Resources[res]
		if !ok {
			return fmt.Errorf("resource %q not found in state", res)
		}

		if rs.Primary.ID == "" {
			return fmt.Errorf("No ID is set")
		}
		config := googleProviderConfig(t)

		job, err := config.NewDataflowClient(config.userAgent).Projects.Jobs.Get(config.Project, rs.Primary.ID).View("JOB_VIEW_ALL").Do()
		if err != nil {
			return fmt.Errorf("dataflow job does not exist")
		}

		sdkPipelineOptions, err := ConvertToMap(job.Environment.SdkPipelineOptions)
		if err != nil {
			return fmt.Errorf("error from ConvertToMap: %s", err)
		}
		optionsMap := sdkPipelineOptions["options"].(map[string]interface{})

		if optionsMap[option] != expectedValue {
			return fmt.Errorf("Option %s do not match. Got %s while expecting %s", option, optionsMap[option], expectedValue)
		}

		return nil
	}
}

func testAccDataflowFlexTemplateJobHasLabels(t *testing.T, res, key string) resource.TestCheckFunc {
	return func(s *terraform.State) error {
		rs, ok := s.RootModule().Resources[res]
		if !ok {
			return fmt.Errorf("resource %q not found in state", res)
		}

		if rs.Primary.ID == "" {
			return fmt.Errorf("No ID is set")
		}
		config := googleProviderConfig(t)

		job, err := config.NewDataflowClient(config.userAgent).Projects.Jobs.Get(config.Project, rs.Primary.ID).Do()
		if err != nil {
			return fmt.Errorf("dataflow job does not exist")
		}

		if job.Labels[key] != rs.Primary.Attributes["labels."+key] {
			return fmt.Errorf("Labels do not match what is stored in state.")
		}

		return nil
	}
}

<% end -%>
