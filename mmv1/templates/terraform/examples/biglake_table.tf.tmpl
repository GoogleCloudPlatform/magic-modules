resource "google_biglake_catalog" "catalog" {
    name = "{{index $.Vars "catalog"}}"
    location = "US"
}

resource "google_storage_bucket" "bucket" {
  name                        = "{{index $.Vars "bucket"}}"
  location                    = "US"
  force_destroy               = true
  uniform_bucket_level_access = true
}

resource "google_storage_bucket_object" "metadata_folder" {
  name    = "metadata/"
  content = " "
  bucket  = google_storage_bucket.bucket.name
}


resource "google_storage_bucket_object" "data_folder" {
  name    = "data/"
  content = " "
  bucket  = google_storage_bucket.bucket.name
}

resource "google_biglake_database" "database" {
    name = "{{index $.Vars "database"}}"
    catalog = google_biglake_catalog.catalog.id
    type = "HIVE"
    hive_options {
        location_uri = "gs://${google_storage_bucket.bucket.name}/${google_storage_bucket_object.metadata_folder.name}"
        parameters = {
          "owner" = "Alex"
        }
    }
}

resource "google_biglake_table" "{{$.PrimaryResourceId}}" {
    name = "{{index $.Vars "name"}}"
    database = google_biglake_database.database.id
    type = "HIVE"
    hive_options {
      table_type = "MANAGED_TABLE"
      storage_descriptor {
        location_uri = "gs://${google_storage_bucket.bucket.name}/${google_storage_bucket_object.data_folder.name}"
        input_format  = "org.apache.hadoop.mapred.SequenceFileInputFormat"
        output_format = "org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat"
      }
      # Some Example Parameters.
      parameters = {
        "spark.sql.create.version" = "3.1.3"
        "spark.sql.sources.schema.numParts" = "1"
        "transient_lastDdlTime" = "1680894197"
        "spark.sql.partitionProvider" = "catalog"
        "owner" = "John Doe"
        "spark.sql.sources.schema.part.0"= "{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"age\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}}]}"
        "spark.sql.sources.provider" = "iceberg"
        "provider" = "iceberg"
      }
  }
}
