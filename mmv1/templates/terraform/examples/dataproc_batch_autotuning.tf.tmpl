resource "google_dataproc_batch" "{{$.PrimaryResourceId}}" {

    batch_id      = "tf-test-batch%{random_suffix}"
    location      = "us-central1"
    labels        = {"batch_test": "terraform"}

    runtime_config {
      version       = "2.2"
      properties    = { "spark.dynamicAllocation.enabled": "false", "spark.executor.instances": "2" }
      cohort        = "tf-dataproc-batch-example"
      autotuning_config {
        scenarios = ["SCALING", "MEMORY"]
      }
    }

    environment_config {
      execution_config {
        subnetwork_uri = "{{index $.Vars "subnetwork_name"}}"
        ttl            = "3600s"
      }
    }

    spark_batch {
      main_class    = "org.apache.spark.examples.SparkPi"
      args          = ["10"]
      jar_file_uris = ["file:///usr/lib/spark/examples/jars/spark-examples.jar"]
    }
}

