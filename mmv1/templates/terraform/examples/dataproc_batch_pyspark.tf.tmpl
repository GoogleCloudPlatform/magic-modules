resource "google_dataproc_batch" "{{$.PrimaryResourceId}}" {
    batch_id      = "tf-test-batch%{random_suffix}"
    location      = "us-central1"

    runtime_config {
      properties    = { "spark.dynamicAllocation.enabled": "false", "spark.executor.instances": "2" }
    }

    environment_config {
      execution_config {
        subnetwork_uri = "{{index $.Vars "subnetwork_name"}}"
      }
    }

    pyspark_batch {
      main_python_file_uri = "https://storage.googleapis.com/terraform-batches/test_util.py"
      args                 = ["10"]
      jar_file_uris        = ["file:///usr/lib/spark/examples/jars/spark-examples.jar"]
      python_file_uris     = ["gs://dataproc-examples/pyspark/hello-world/hello-world.py"]
      archive_uris         = [
        "https://storage.googleapis.com/terraform-batches/animals.txt.tar.gz#unpacked",
        "https://storage.googleapis.com/terraform-batches/animals.txt.jar",
        "https://storage.googleapis.com/terraform-batches/animals.txt"
      ]
      file_uris            = ["https://storage.googleapis.com/terraform-batches/people.txt"]
    }
}

